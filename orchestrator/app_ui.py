"""
Streamlit UI for Cold Email Campaign Management.

Provides a web interface for:
- CSV upload & contact preview
- Product/language/CTA selection
- Email generation, review, and preview
- Campaign send & status dashboard

Run with: streamlit run orchestrator/app_ui.py
"""
import sys
import os
import re
import csv
import io
import logging
import time
from datetime import datetime
from pathlib import Path

import streamlit as st

# Add orchestrator to path so imports work when run from project root
sys.path.insert(0, str(Path(__file__).resolve().parent))

import json

from config import OUTPUT_DIR, DATA_DIR, PROJECT_ROOT, HUNTER_API_KEY, FINDYMAIL_API_KEY
import db

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

_TARGET_FEEDBACK_PATH = DATA_DIR / "target_feedback_log.md"


def _append_target_feedback(feedback: str, product_summary: str = ""):
    """Append target-finding feedback to persistent log file."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
    entry = f"\n- [{timestamp}] "
    if product_summary:
        entry += f"({product_summary}) "
    entry += feedback.strip()
    with open(_TARGET_FEEDBACK_PATH, "a", encoding="utf-8") as f:
        f.write(entry + "\n")


def _rewrite_feedback_log(entries: list[str]):
    """Rewrite the feedback log with the given entries (for delete/clear)."""
    header = "# íƒ€ê²Ÿ ë°œêµ´ í”¼ë“œë°± ë¡œê·¸\n\nì´ íŒŒì¼ì— ëˆ„ì ëœ í”¼ë“œë°±ì€ AI íƒ€ê²Ÿ ì¶”ì²œ ì‹œ í•­ìƒ ë°˜ì˜ë©ë‹ˆë‹¤.\n"
    body = "\n".join(entries) + "\n" if entries else ""
    with open(_TARGET_FEEDBACK_PATH, "w", encoding="utf-8") as f:
        f.write(header + body)


def _get_feedback_hash() -> str:
    """Return a short hash of the current feedback log content."""
    import hashlib
    try:
        content = _TARGET_FEEDBACK_PATH.read_text(encoding="utf-8").strip()
    except FileNotFoundError:
        content = ""
    return hashlib.md5(content.encode()).hexdigest()[:12]


class AgentProgressTracker:
    """Tracks agent progress via tool call callbacks and renders st.progress()."""

    # Tool-name â†’ stage label mappings per agent type
    STAGE_MAP = {
        "agent1": {
            "search_queries": ("ğŸ“‹ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±", 0.10),
            "search_web": ("ğŸ” ì›¹ ê²€ìƒ‰", None),
            "search_for_targets": ("ğŸ“Š ê²°ê³¼ ìˆ˜ì§‘", 0.70),
            "save_results": ("ğŸ’¾ ê²°ê³¼ ì €ì¥", 0.90),
        },
        "agent2": {
            "read_file": ("ğŸ“– ë°ì´í„° ë¡œë”©", 0.03),
            "search_web": ("ğŸ” ì›¹ ê²€ìƒ‰", None),
            "fetch_webpage": ("ğŸŒ í˜ì´ì§€ ë¶„ì„", None),
            "findymail_search": ("ğŸ“§ Findymail ê²€ìƒ‰", None),
            "findymail_linkedin": ("ğŸ”— LinkedIn ì´ë©”ì¼", None),
            "hunter_domain_search": ("ğŸ¢ Hunter íšŒì‚¬ ì¡°íšŒ", None),
            "hunter_find_email": ("ğŸ¹ Hunter ê°œë³„ ê²€ìƒ‰", None),
            "hunter_verify_email": ("âœ… ì´ë©”ì¼ ê²€ì¦", None),
            "whois_lookup": ("ğŸŒ WHOIS ì¡°íšŒ", None),
            "add_contacts": ("ğŸ’¾ ì—°ë½ì²˜ ì €ì¥", None),
            "save_contacts": ("ğŸ’¾ ê²°ê³¼ ì €ì¥", 0.95),
        },
        "agent3": {
            "read_file": ("ğŸ“– ë°ì´í„° ë¡œë”©", 0.03),
            "load_prospects": ("ğŸ“‹ ì—°ë½ì²˜ ë¡œë”©", 0.08),
            "search_web": ("ğŸ” íšŒì‚¬ ë¦¬ì„œì¹˜", None),
            "fetch_webpage": ("ğŸŒ í˜ì´ì§€ ë¶„ì„", None),
            "save_draft_email": ("âœ‰ï¸ ì´ë©”ì¼ ì‘ì„±", None),
            "finalize_campaign": ("ğŸ“¦ ìº í˜ì¸ ì •ë¦¬", 0.92),
            "upload_to_sheets": ("ğŸ“Š ì‹œíŠ¸ ì—…ë¡œë“œ", 0.96),
            "send_gmass_campaign": ("ğŸš€ ë°œì†¡", 0.99),
        },
    }

    def __init__(self, agent_type: str, total_items: int = 0):
        self.agent_type = agent_type
        self.total_items = total_items  # companies or contacts
        self.tool_calls = 0
        self.item_count = 0  # tracks save_draft_email / per-company tools
        self.start_time = time.time()
        self.stage_map = self.STAGE_MAP.get(agent_type, {})
        self._progress_bar = st.progress(0)
        self._status = st.empty()
        self._log_area = st.empty()
        self._tool_log: list[str] = []
        self._current_progress = 0.0

        # File-based logging
        from pathlib import Path
        log_dir = Path(__file__).resolve().parent.parent / "output"
        log_dir.mkdir(exist_ok=True)
        self._log_file = log_dir / f"{agent_type}_{time.strftime('%y%m%d_%H%M%S')}.log"
        self._log_fh = open(self._log_file, "w", encoding="utf-8")
        self._log_fh.write(f"=== {agent_type} started at {time.strftime('%Y-%m-%d %H:%M:%S')} ===\n")
        self._log_fh.flush()

    def on_tool_call(self, name: str, input_data: dict):
        self.tool_calls += 1
        stage_info = self.stage_map.get(name)
        label = stage_info[0] if stage_info else f"ğŸ”§ {name}"
        fixed_pct = stage_info[1] if stage_info else None

        # Track per-item progress for agents 2 & 3
        if name == "save_draft_email":
            self.item_count += 1
        if name in ("findymail_search", "hunter_find_email", "findymail_linkedin"):
            self.item_count += 1
        if name == "hunter_domain_search":
            self.item_count += 1  # 1 call = 1 company covered

        # Calculate progress
        if fixed_pct is not None:
            pct = fixed_pct
        elif self.total_items > 0:
            # Estimate based on items processed
            if self.agent_type == "agent2":
                pct = min(0.05 + (self.item_count / self.total_items) * 0.88, 0.93)
            elif self.agent_type == "agent3":
                pct = min(0.10 + (self.item_count / self.total_items) * 0.80, 0.90)
            else:
                pct = min(0.05 + self.tool_calls * 0.04, 0.88)
        else:
            pct = min(0.05 + self.tool_calls * 0.04, 0.88)

        self._current_progress = max(self._current_progress, pct)
        self._progress_bar.progress(self._current_progress)

        # Status text
        detail = (
            input_data.get("query")
            or input_data.get("company")
            or input_data.get("name")
            or input_data.get("domain")
            or input_data.get("contact_name")
            or input_data.get("url", "")[:60]
            or input_data.get("filename")
            or str(input_data)[:50]
        )
        elapsed = int(time.time() - self.start_time)
        items_text = ""
        if self.total_items > 0 and self.item_count > 0:
            items_text = f" ({self.item_count}/{self.total_items})"
        self._status.info(f"â± {elapsed}ì´ˆ | {label}{items_text} â€” {detail}")

        # Tool log
        log_line = f"[{elapsed:>3}s] {label}: {detail}"
        self._tool_log.append(log_line)
        self._write_log(log_line)
        self._log_area.code("\n".join(self._tool_log[-12:]), language=None)

    def on_tool_result(self, name: str, result_preview: str):
        log_line = f"       âœ“ {name} â†’ {result_preview[:150]}"
        self._tool_log.append(log_line)
        self._write_log(log_line)
        self._log_area.code("\n".join(self._tool_log[-12:]), language=None)

    def on_text(self, text: str):
        if text.strip():
            log_line = f"  ğŸ’¬ {text[:200]}"
            self._tool_log.append(log_line)
            self._write_log(log_line)
            self._log_area.code("\n".join(self._tool_log[-12:]), language=None)

    def _write_log(self, line: str):
        """Write to log file."""
        try:
            self._log_fh.write(line + "\n")
            self._log_fh.flush()
        except Exception:
            pass

    def complete(self, message: str):
        elapsed = int(time.time() - self.start_time)
        self._progress_bar.progress(1.0)
        self._status.success(f"âœ… {message} (â± {elapsed}ì´ˆ, ë„êµ¬ {self.tool_calls}íšŒ)")
        self._write_log(f"=== COMPLETED: {message} ({elapsed}s, {self.tool_calls} tool calls) ===")
        try:
            self._log_fh.close()
        except Exception:
            pass

    def fail(self, error: str):
        elapsed = int(time.time() - self.start_time)
        self._progress_bar.progress(self._current_progress)
        self._status.error(f"âŒ {error} (â± {elapsed}ì´ˆ)")
        self._write_log(f"=== FAILED: {error} ({elapsed}s) ===")
        try:
            self._log_fh.close()
        except Exception:
            pass

    @property
    def log_file_path(self) -> str:
        return str(self._log_file)

    @property
    def tool_log(self) -> list[str]:
        return list(self._tool_log)


def _render_company_card(company: dict, verification: dict | None, verdict: dict | None = None):
    """Render a company card with optional verification data and cross-check verdict."""
    name = company["name"]
    reason = company.get("reason", "")

    # Status icon based on verdict (if available) or verification
    if verdict:
        v_status = verdict.get("verdict", "unverified")
        icon = {"confirmed": "+", "partial": "~", "unverified": "?", "wrong": "X"}.get(v_status, "?")
        label = {"confirmed": "í™•ì¸ë¨", "partial": "ì¼ë¶€ í™•ì¸", "unverified": "ë¯¸ê²€ì¦", "wrong": "ë¶ˆì¼ì¹˜"}.get(v_status, "?")
        header = f"[{icon}] **{name}** â€” {reason}  `{label}`"
    elif verification:
        status = verification.get("status", "no_data")
        icon = {"verified": "+", "partial": "~", "no_data": "-"}.get(status, "?")
        label = {"verified": "ê²€ì¦ë¨", "partial": "ì¼ë¶€ í™•ì¸", "no_data": "ë°ì´í„° ì—†ìŒ"}.get(status, "?")
        header = f"[{icon}] **{name}** â€” {reason}  `{label}`"
    else:
        header = f"**{name}** â€” {reason}"

    with st.expander(header, expanded=False):
        # AI's claimed evidence
        st.markdown(f"**AI ê·¼ê±°:** {company.get('evidence', reason)}")

        # Tier classification reason
        _tier_reason = company.get("tier_reason", "")
        if _tier_reason:
            st.markdown(f"**Tier ì‚°ì •:** {_tier_reason}")

        # Cross-check verdict (the key new feature)
        if verdict and verdict.get("explanation"):
            v_status = verdict.get("verdict", "unverified")
            color = {"confirmed": "green", "partial": "orange", "unverified": "gray", "wrong": "red"}.get(v_status, "gray")
            emoji = {"confirmed": "âœ…", "partial": "âš ï¸", "unverified": "â“", "wrong": "âŒ"}.get(v_status, "â“")
            st.markdown(f"{emoji} **êµì°¨ê²€ì¦:** {verdict['explanation']}")

        # Verification data
        if verification:
            st.divider()

            with st.expander("ì™¸ë¶€ ê²€ì¦ ë°ì´í„° ìƒì„¸", expanded=False):
                # Web search results
                web_results = verification.get("web_results", [])
                if web_results:
                    st.markdown("**ì›¹ ê²€ìƒ‰:**")
                    for wr in web_results[:3]:
                        st.markdown(f"- [{wr['title'][:60]}]({wr['url']})  \n"
                                    f"  {wr['snippet'][:150]}")

                # ClinicalTrials + PubMed â€” only shown for pharma/biotech
                if verification.get("is_pharma"):
                    trials_n = verification.get("trials_found", 0)
                    pubs_n = verification.get("publications_found", 0)

                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.metric("ClinicalTrials.gov", f"{trials_n}ê±´")
                        conditions = verification.get("trial_conditions", [])
                        if conditions:
                            st.caption(f"ì ì‘ì¦: {', '.join(conditions[:6])}")
                    with col_b:
                        st.metric("PubMed ë…¼ë¬¸", f"{pubs_n}ê±´")
                        topics = verification.get("pub_topics", [])
                        if topics:
                            st.caption(topics[0][:80])

                    trial_details = verification.get("trial_details", [])
                    if trial_details:
                        for td in trial_details:
                            st.markdown(
                                f"- **{td['nct_id']}** ({td['status']}) â€” "
                                f"{td['title']} | {', '.join(td['conditions'][:3])}"
                            )

                if not web_results and not verification.get("is_pharma"):
                    st.warning("ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


def _render_researcher_card(researcher: dict, verdict: dict | None = None):
    """Render a researcher card with institution and research details."""
    name = researcher.get("name", "")
    institution = researcher.get("institution", "")
    dept = researcher.get("department", "")
    title = researcher.get("title", "")
    reason = researcher.get("reason", "")

    # Status icon based on verdict
    if verdict:
        v_status = verdict.get("verdict", "unverified")
        icon = {"confirmed": "+", "partial": "~", "unverified": "?", "wrong": "X"}.get(v_status, "?")
        label = {"confirmed": "í™•ì¸ë¨", "partial": "ì¼ë¶€ í™•ì¸", "unverified": "ë¯¸ê²€ì¦", "wrong": "ë¶ˆì¼ì¹˜"}.get(v_status, "?")
    else:
        icon = None

    header_parts = [f"**{name}**"]
    if title:
        header_parts.append(title)
    if institution:
        sub = institution
        if dept:
            sub += f" ({dept})"
        header_parts.append(sub)
    header = " â€” ".join(header_parts)
    if icon:
        header += f"  [{icon} {label}]"
    if reason:
        header += f"  \n{reason}"

    with st.expander(header, expanded=False):
        # Cross-check verdict
        if verdict and verdict.get("explanation"):
            v_status = verdict.get("verdict", "unverified")
            emoji = {"confirmed": "âœ…", "partial": "âš ï¸", "unverified": "â“", "wrong": "âŒ"}.get(v_status, "â“")
            st.markdown(f"{emoji} **êµì°¨ê²€ì¦:** {verdict['explanation']}")

        # Verification data summary
        verification = researcher.get("verification", {})
        if verification:
            vparts = []
            pubs_found = verification.get("publications_found", 0)
            if pubs_found:
                vparts.append(f"PubMed {pubs_found}ê±´")
            trials_found = verification.get("trials_found", 0)
            if trials_found:
                vparts.append(f"ì„ìƒì‹œí—˜ PI {trials_found}ê±´")
            web_n = len(verification.get("web_results", []))
            if web_n:
                vparts.append(f"ì›¹ ê²°ê³¼ {web_n}ê±´")
            if vparts:
                st.caption(f"ì™¸ë¶€ ë°ì´í„°: {' | '.join(vparts)}")

        research_area = researcher.get("research_area", "")
        if research_area:
            st.markdown(f"**ì—°êµ¬ ë¶„ì•¼:** {research_area}")

        pubs = researcher.get("key_publications", "")
        if pubs:
            st.markdown(f"**ì£¼ìš” ì—°êµ¬:** {pubs}")

        evidence = researcher.get("evidence", "")
        if evidence:
            st.markdown(f"**ì¶”ì²œ ê·¼ê±°:** {evidence}")

        tier_reason = researcher.get("tier_reason", "")
        if tier_reason:
            st.markdown(f"**Tier ì‚°ì •:** {tier_reason}")

        clues = researcher.get("contact_clues", "")
        if clues:
            st.markdown(f"**ì—°ë½ì²˜ ë‹¨ì„œ:** {clues}")


def _auto_verify(result_text: str, feedback: str = ""):
    """Parse AI result â†’ external verification â†’ Claude cross-check."""
    import re as _re
    json_match = _re.search(r"```json\s*\n(.*?)```", result_text, _re.DOTALL)
    parsed = None
    if json_match:
        try:
            parsed = json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass
    if not parsed:
        try:
            parsed = json.loads(result_text)
        except json.JSONDecodeError:
            pass

    if parsed:
        all_companies = (parsed.get("tier1_companies", [])
                         + parsed.get("tier2_companies", []))
        if all_companies:
            n = len(all_companies)
            verify_bar = st.progress(0)
            verify_status = st.empty()

            # Step 2/3: External data collection
            verify_status.info(f"â± 2/3 â€” ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ({n}ê°œ íšŒì‚¬: ì›¹ + ClinicalTrials + PubMed)...")
            verify_bar.progress(0.1)
            from research_client import ResearchClient
            rc = ResearchClient()
            verified_companies = rc.verify_companies_batch(all_companies)
            st.session_state.ai_target_verification = verified_companies
            verify_bar.progress(0.6)

            # Step 3/3: Claude cross-check (AI evidence vs external data)
            verify_status.info("â± 3/3 â€” AI ê·¼ê±° êµì°¨ê²€ì¦ ì¤‘ (Claude ë¶„ì„)...")
            try:
                from claude_client import ClaudeClient
                claude = ClaudeClient()
                cross_check_raw = claude.cross_check_evidence(verified_companies, feedback=feedback)
                # Parse the verdict JSON (with truncation recovery)
                try:
                    verdicts = json.loads(cross_check_raw)
                except json.JSONDecodeError:
                    # Truncated JSON â€” try to recover complete entries
                    raw = cross_check_raw.strip()
                    if raw.startswith("["):
                        last_brace = raw.rfind("}")
                        if last_brace > 0:
                            raw = raw[:last_brace + 1] + "]"
                            verdicts = json.loads(raw)
                            logger.info(f"Recovered {len(verdicts)} verdicts from truncated JSON")
                        else:
                            raise
                    else:
                        raise
                # Build lookup by company name
                verdict_map = {v["company"]: v for v in verdicts if "company" in v}
                st.session_state.ai_target_verdicts = verdict_map
                verify_bar.progress(1.0)
                n_done = len(verdict_map)
                if n_done < n:
                    verify_status.warning(f"âš ï¸ {n_done}/{n}ê°œ íšŒì‚¬ ê²€ì¦ ì™„ë£Œ (ì¼ë¶€ ì˜ë¦¼)")
                else:
                    verify_status.success(f"âœ… {n}ê°œ íšŒì‚¬ ê²€ì¦ ì™„ë£Œ!")
            except Exception as e:
                logger.warning(f"Cross-check failed: {e}")
                st.session_state.ai_target_verdicts = {}
                verify_bar.progress(0.8)
                verify_status.warning(f"êµì°¨ê²€ì¦ ì‹¤íŒ¨: {e}")
        else:
            st.session_state.ai_target_verification = None
            st.session_state.ai_target_verdicts = {}
    else:
        st.session_state.ai_target_verification = None
        st.session_state.ai_target_verdicts = {}


def _auto_verify_researchers(result_text: str, feedback: str = ""):
    """Parse AI researcher result â†’ external verification â†’ Claude cross-check."""
    import re as _re
    json_match = _re.search(r"```json\s*\n(.*?)```", result_text, _re.DOTALL)
    parsed = None
    if json_match:
        try:
            parsed = json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass
    if not parsed:
        try:
            parsed = json.loads(result_text)
        except json.JSONDecodeError:
            pass

    if parsed:
        all_researchers = (parsed.get("tier1_researchers", [])
                           + parsed.get("tier2_researchers", []))
        if all_researchers:
            n = len(all_researchers)
            verify_bar = st.progress(0)
            verify_status = st.empty()

            # Step 2/3: External data collection
            verify_status.info(f"â± 2/3 â€” ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ({n}ëª… ì—°êµ¬ì: ì›¹ + PubMed + ClinicalTrials)...")
            verify_bar.progress(0.1)
            from research_client import ResearchClient
            rc = ResearchClient()
            verified_researchers = rc.verify_researchers_batch(all_researchers)
            st.session_state.ai_researcher_verification = verified_researchers
            verify_bar.progress(0.6)

            # Step 3/3: Claude cross-check
            verify_status.info("â± 3/3 â€” AI ê·¼ê±° êµì°¨ê²€ì¦ ì¤‘ (Claude ë¶„ì„)...")
            try:
                from claude_client import ClaudeClient
                claude = ClaudeClient()
                cross_check_raw = claude.cross_check_researcher_evidence(
                    verified_researchers, feedback=feedback
                )
                try:
                    verdicts = json.loads(cross_check_raw)
                except json.JSONDecodeError:
                    raw = cross_check_raw.strip()
                    if raw.startswith("["):
                        last_brace = raw.rfind("}")
                        if last_brace > 0:
                            raw = raw[:last_brace + 1] + "]"
                            verdicts = json.loads(raw)
                            logger.info(f"Recovered {len(verdicts)} researcher verdicts from truncated JSON")
                        else:
                            raise
                    else:
                        raise
                verdict_map = {v["researcher"]: v for v in verdicts if "researcher" in v}
                st.session_state.ai_researcher_verdicts = verdict_map
                verify_bar.progress(1.0)
                n_done = len(verdict_map)
                if n_done < n:
                    verify_status.warning(f"âš ï¸ {n_done}/{n}ëª… ì—°êµ¬ì ê²€ì¦ ì™„ë£Œ (ì¼ë¶€ ì˜ë¦¼)")
                else:
                    verify_status.success(f"âœ… {n}ëª… ì—°êµ¬ì ê²€ì¦ ì™„ë£Œ!")
            except Exception as e:
                logger.warning(f"Researcher cross-check failed: {e}")
                st.session_state.ai_researcher_verdicts = {}
                verify_bar.progress(0.8)
                verify_status.warning(f"êµì°¨ê²€ì¦ ì‹¤íŒ¨: {e}")
        else:
            st.session_state.ai_researcher_verification = None
            st.session_state.ai_researcher_verdicts = {}
    else:
        st.session_state.ai_researcher_verification = None
        st.session_state.ai_researcher_verdicts = {}


# â”€â”€ Initialize DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
db.init_db()

# â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Cold Email Campaign Manager",
    page_icon="ğŸ“§",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ Session State Initialization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "generated_md" not in st.session_state:
    st.session_state.generated_md = None
if "generated_csv" not in st.session_state:
    st.session_state.generated_csv = None
if "review_result" not in st.session_state:
    st.session_state.review_result = None
if "csv_data" not in st.session_state:
    st.session_state.csv_data = None
if "step" not in st.session_state:
    st.session_state.step = "input"  # input â†’ generate â†’ review â†’ preview â†’ send


# â”€â”€ Helper Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_csv_block(text: str) -> str | None:
    """Extract CSV block from Claude's markdown output."""
    pattern = r"```csv\s*\n(.*?)```"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        csv_text = match.group(1).strip()
        if csv_text.startswith("contact_name,"):
            return csv_text
    return None


def parse_csv_string(csv_string: str) -> list[dict]:
    """Parse a CSV string into a list of dicts."""
    reader = csv.DictReader(io.StringIO(csv_string))
    return list(reader)


def load_products() -> dict[int, str]:
    """Deprecated: product info now comes from campaign profile.
    Kept for backward compatibility but returns empty dict."""
    return {}


def get_all_campaigns() -> list[dict]:
    """Get all campaigns from the database."""
    conn = db.get_connection()
    rows = conn.execute("SELECT * FROM campaigns ORDER BY id DESC").fetchall()
    conn.close()
    return [dict(r) for r in rows]


def _find_sent_email_body(email_address: str) -> str:
    """Find the original email body we sent to this address from output CSVs or DB."""
    # 1. Try local DB first
    try:
        conn = db.get_connection()
        row = conn.execute(
            "SELECT subject, body FROM recipients WHERE email = ? ORDER BY created_at DESC LIMIT 1",
            (email_address,),
        ).fetchone()
        conn.close()
        if row and row["body"]:
            return f"Subject: {row['subject']}\n\n{row['body']}"
    except Exception:
        pass

    # 2. Search output CSV files (most recent first)
    try:
        csv_files = sorted(OUTPUT_DIR.glob("*final*.csv"), reverse=True)
        csv_files += sorted(OUTPUT_DIR.glob("*mailmerge*.csv"), reverse=True)
        for csv_file in csv_files:
            content = csv_file.read_text(encoding="utf-8-sig")
            rows = parse_csv_string(content)
            for row in rows:
                if row.get("email", "") == email_address:
                    subject = row.get("subject", "")
                    body = row.get("body", "").replace("<br>", "\n")
                    return f"Subject: {subject}\n\n{body}"
    except Exception:
        pass

    return ""


def build_campaign_context(profile: dict | None) -> str:
    """Build a campaign context string from an active profile for agent injection."""
    if not profile:
        return ""
    parts = ["## ìº í˜ì¸ ì»¨í…ìŠ¤íŠ¸"]
    if profile.get("product_name"):
        parts.append(f"- ì œí’ˆëª…: {profile['product_name']}")
    if profile.get("product_description"):
        parts.append(f"- ì œí’ˆ ì„¤ëª…: {profile['product_description']}")
    if profile.get("target_region"):
        parts.append(f"- íƒ€ê²Ÿ ì§€ì—­: {profile['target_region']}")
    if profile.get("language"):
        parts.append(f"- ì–¸ì–´: {profile['language']}")
    if profile.get("tone"):
        parts.append(f"- í†¤: {profile['tone']}")
    if profile.get("cta_type"):
        parts.append(f"- CTA: {profile['cta_type']}")
    if profile.get("sender_context"):
        parts.append(f"- ë°œì‹ ì: {profile['sender_context']}")
    if profile.get("extra_notes"):
        parts.append(f"- ë©”ëª¨: {profile['extra_notes']}")
    return "\n".join(parts)


# â”€â”€ Session state for reply context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "reply_context" not in st.session_state:
    st.session_state.reply_context = None
if "active_page" not in st.session_state:
    st.session_state.active_page = None
if "agent_running" not in st.session_state:
    st.session_state.agent_running = False

# â”€â”€ Sidebar: Navigation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("Cold Email Manager")

page_options = [
    "âš™ï¸ ìº í˜ì¸ ì„¤ì •",
    "ğŸ¯ íƒ€ê²Ÿ ë°œêµ´",
    "ğŸ” ì»¨íƒ ì„œì¹­",
    "ğŸ“ ì½œë“œë©”ì¼",
    "ğŸ“Š ìº í˜ì¸ í˜„í™©",
    "ğŸ’¬ ë‹µì¥ ì‘ì„±",
    "ğŸ“š ìŠ¤í‚¬ ëª©ë¡",
]

# Page redirect support â€” set session key BEFORE radio renders
if st.session_state.active_page in page_options:
    st.session_state.nav_page = st.session_state.active_page
    st.session_state.active_page = None

page = st.sidebar.radio(
    "ë©”ë‰´",
    page_options,
    key="nav_page",
    label_visibility="collapsed",
)

# â”€â”€ Agent running lock (CSS overlay via 2-phase rerun) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# On the rerun where agent_running=True, this CSS renders BEFORE the blocking
# agent.run() call, so the overlay is visible during execution.
if st.session_state.get("agent_running"):
    st.markdown("""
    <style>
    [data-testid="stSidebar"] > div:first-child {
        pointer-events: none !important;
        opacity: 0.5 !important;
    }
    </style>
    <div style="position:fixed;top:0;left:0;width:100vw;height:100vh;
        background:rgba(0,0,0,0.35);z-index:999999999;
        display:flex;align-items:center;justify-content:center;cursor:wait;">
        <div style="background:white;padding:28px 48px;border-radius:14px;
            font-size:17px;box-shadow:0 4px 24px rgba(0,0,0,0.25);text-align:center;">
            <div style="font-size:28px;margin-bottom:8px;">â³</div>
            Agent ì‹¤í–‰ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”<br>
            <span style="font-size:13px;color:#888;margin-top:4px;display:inline-block;">
            íƒ­ ì „í™˜ ì‹œ ì‘ì—…ì´ ì·¨ì†Œë©ë‹ˆë‹¤</span>
        </div>
    </div>
    """, unsafe_allow_html=True)

# â”€â”€ Sidebar: Active campaign profile indicator â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "active_profile_id" not in st.session_state:
    st.session_state.active_profile_id = None
if "active_profile" not in st.session_state:
    st.session_state.active_profile = None
if "active_sender_id" not in st.session_state:
    st.session_state.active_sender_id = None
if "active_sender" not in st.session_state:
    st.session_state.active_sender = None

# Load active profile
if st.session_state.active_profile_id:
    _ap = db.get_campaign_profile(st.session_state.active_profile_id)
    if _ap:
        st.session_state.active_profile = _ap
        st.sidebar.divider()
        st.sidebar.markdown(f"**í™œì„± í”„ë¡œí•„:** {_ap['name']}")
        st.sidebar.caption(f"{_ap.get('product_name', '')} Â· {_ap.get('language', 'ja')}")
    else:
        st.session_state.active_profile_id = None
        st.session_state.active_profile = None

# Load active sender profile
if st.session_state.active_sender_id:
    _asp = db.get_sender_profile(st.session_state.active_sender_id)
    if _asp:
        st.session_state.active_sender = _asp
        st.sidebar.caption(f"ë°œì‹ ì: {_asp.get('name_en') or _asp.get('name_ja', '')} ({_asp.get('company_en', '')})")
    else:
        st.session_state.active_sender_id = None
        st.session_state.active_sender = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PAGE: Campaign Setup (ìº í˜ì¸ ì„¤ì •)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if page == "âš™ï¸ ìº í˜ì¸ ì„¤ì •":
    st.title("ìº í˜ì¸ ì„¤ì •")
    st.caption("ì œí’ˆ/ì„œë¹„ìŠ¤, ì„¸ì¼ì¦ˆ ëª©ì , íƒ€ê²Ÿ ë“±ì„ ì •ì˜í•˜ë©´ Agent 1â†’2â†’3ì— ìë™ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.")

    # â”€â”€ Existing profiles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    profiles = db.get_campaign_profiles()

    if profiles:
        st.subheader("ì €ì¥ëœ í”„ë¡œí•„")
        for p in profiles:
            pcol1, pcol2, pcol3 = st.columns([4, 1, 1])
            with pcol1:
                is_active = st.session_state.active_profile_id == p["id"]
                label = f"{'âœ… ' if is_active else ''}{p['name']}"
                st.markdown(
                    f"**{label}**  \n"
                    f"{p.get('product_name', '')} Â· {p.get('cta_type', '')} Â· "
                    f"{p.get('target_region', '')} Â· {p.get('language', 'en')}"
                )
            with pcol2:
                if st.button("ì‚¬ìš©", key=f"use_profile_{p['id']}", disabled=is_active):
                    st.session_state.active_profile_id = p["id"]
                    st.session_state.active_profile = p
                    st.session_state._profile_just_activated = True
                    st.rerun()
            with pcol3:
                if st.button("ì‚­ì œ", key=f"del_profile_{p['id']}"):
                    db.delete_campaign_profile(p["id"])
                    if st.session_state.active_profile_id == p["id"]:
                        st.session_state.active_profile_id = None
                        st.session_state.active_profile = None
                    st.rerun()

        # Show activation feedback & next steps
        if st.session_state.get("_profile_just_activated"):
            st.session_state._profile_just_activated = False
            st.toast("í”„ë¡œí•„ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

        if st.session_state.active_profile_id:
            _ap = st.session_state.get("active_profile", {})
            st.success(f"í™œì„± í”„ë¡œí•„: **{_ap.get('name', '')}** â€” {_ap.get('product_name', '')} Â· {_ap.get('language', 'en')}")
            nc1, nc2, nc3 = st.columns(3)
            with nc1:
                if st.button("ğŸ¯ íƒ€ê²Ÿ ë°œêµ´ë¡œ ì´ë™", use_container_width=True):
                    st.session_state.active_page = "ğŸ¯ íƒ€ê²Ÿ ë°œêµ´"
                    st.rerun()
            with nc2:
                if st.button("ğŸ” ì»¨íƒ ì„œì¹­ìœ¼ë¡œ ì´ë™", use_container_width=True):
                    st.session_state.active_page = "ğŸ” ì»¨íƒ ì„œì¹­"
                    st.rerun()
            with nc3:
                if st.button("ğŸ“ ì½œë“œë©”ì¼ë¡œ ì´ë™", use_container_width=True):
                    st.session_state.active_page = "ğŸ“ ì½œë“œë©”ì¼"
                    st.rerun()

        st.divider()

    # â”€â”€ Create / Edit form â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ìƒˆ í”„ë¡œí•„ ìƒì„±")

    with st.form("campaign_profile_form", clear_on_submit=True):
        cp_name = st.text_input(
            "í”„ë¡œí•„ ì´ë¦„ *",
            placeholder="ì˜ˆ: CNS ë°”ì´ì˜¤í… ì•„ì›ƒë¦¬ì¹˜",
        )

        cp_col1, cp_col2 = st.columns(2)

        with cp_col1:
            cp_product_name = st.text_input(
                "ì œí’ˆ/ì„œë¹„ìŠ¤ ì´ë¦„",
                placeholder="ì˜ˆ: AI Drug Discovery Platform",
            )
            cp_language = st.selectbox("ì–¸ì–´", ["en", "ja", "ko"], index=0)

        with cp_col2:
            cp_target_region = st.text_input(
                "íƒ€ê²Ÿ ì§€ì—­",
                placeholder="ì˜ˆ: Japan, US, Global",
            )
            cp_cta_type = st.selectbox(
                "CTA ìœ í˜•",
                [
                    "ìë™ ì„ íƒ",
                    "ë‹´ë‹¹ì ì¶”ì²œ ìš”ì²­ (ê¸°ë³¸)",
                    "15ë¶„ ëŒ€í™” ìš”ì²­ (íƒìƒ‰í˜•)",
                    "í”¼ë“œë°±/ì˜ê²¬ ìš”ì²­ (Design Partner)",
                    "ìë£Œ/ì¸ì‚¬ì´íŠ¸ ê³µìœ  ì œì•ˆ",
                    "Zoom/Web ë¯¸íŒ… ì œì•ˆ",
                    "ì§ì ‘ ì…ë ¥",
                ],
            )
            if cp_cta_type == "ì§ì ‘ ì…ë ¥":
                cp_cta_type = st.text_input("CTA (ì§ì ‘ ì…ë ¥)", placeholder="ì˜ˆ: 3ì›” ë„ì¿„ ë°©ë¬¸ ì‹œ 30ë¶„ ë¯¸íŒ… ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸")
            cp_tone = st.selectbox(
                "í†¤",
                ["professional", "casual", "formal", "friendly"],
                index=0,
            )

        cp_product_desc = st.text_area(
            "ì œí’ˆ/ì„œë¹„ìŠ¤ ì„¤ëª… *",
            placeholder=(
                "ì˜ˆ: ìš°ë¦¬ íšŒì‚¬ëŠ” AI ê¸°ë°˜ ì‹ ì•½ ê°œë°œ í”Œë«í¼ì„ ì œê³µí•©ë‹ˆë‹¤. "
                "íƒ€ê²Ÿ ì‹ë³„ë¶€í„° ë¦¬ë“œ ìµœì í™”ê¹Œì§€ ì „ì£¼ê¸°ë¥¼ ì§€ì›í•˜ë©°, "
                "ê¸°ì¡´ ëŒ€ë¹„ ê°œë°œ ê¸°ê°„ì„ 40% ë‹¨ì¶•í•œ ì‹¤ì ì´ ìˆìŠµë‹ˆë‹¤."
            ),
            height=120,
        )

        _existing_senders = db.get_sender_profiles()
        # Auto-import sender_profile.md if no profiles exist yet
        if not _existing_senders:
            _sp_md_path = DATA_DIR / "sender_profile.md"
            if _sp_md_path.exists():
                _md_text = _sp_md_path.read_text(encoding="utf-8")
                _field_map = {
                    "ì´ë¦„ (ì˜ë¬¸)": "name_en", "ì´ë¦„ (ì¼ë³¸ì–´)": "name_ja",
                    "ì§í•¨ (ì˜ë¬¸)": "title_en", "ì§í•¨ (ì¼ë³¸ì–´)": "title_ja",
                    "íšŒì‚¬ëª… (ì˜ë¬¸)": "company_en", "íšŒì‚¬ëª… (ì¼ë³¸ì–´)": "company_ja",
                    "ì´ë©”ì¼": "email", "ì „í™”ë²ˆí˜¸": "phone",
                }
                _parsed = {}
                for _label, _key in _field_map.items():
                    _m = re.search(rf"\*\*{re.escape(_label)}\*\*:\s*(.+)", _md_text)
                    if _m:
                        _parsed[_key] = _m.group(1).strip()
                _sig_blocks = re.findall(r"## ì„œëª… \((.+?)\)\s*\n+```\n(.*?)```", _md_text, re.DOTALL)
                for _sig_label, _sig_body in _sig_blocks:
                    if "ì¼ë³¸ì–´" in _sig_label:
                        _parsed["signature_ja"] = _sig_body.strip()
                    elif "ì˜ë¬¸" in _sig_label:
                        _parsed["signature_en"] = _sig_body.strip()
                _pname = f"{_parsed.get('name_en', '')} ({_parsed.get('company_en', '')})".strip()
                if not _pname or _pname == "()":
                    _pname = "Default Profile"
                try:
                    db.save_sender_profile(
                        name=_pname,
                        name_en=_parsed.get("name_en", ""),
                        name_ja=_parsed.get("name_ja", ""),
                        title_en=_parsed.get("title_en", ""),
                        title_ja=_parsed.get("title_ja", ""),
                        company_en=_parsed.get("company_en", ""),
                        company_ja=_parsed.get("company_ja", ""),
                        email=_parsed.get("email", ""),
                        phone=_parsed.get("phone", ""),
                        signature_ja=_parsed.get("signature_ja", ""),
                        signature_en=_parsed.get("signature_en", ""),
                    )
                    _existing_senders = db.get_sender_profiles()
                except Exception:
                    pass
        _sender_options = ["ì§ì ‘ ì…ë ¥"] + [f"{s['name']} ({s.get('name_en', '')})" for s in _existing_senders]
        _sender_choice = st.selectbox("ë°œì‹ ì í”„ë¡œí•„", _sender_options)
        if _sender_choice == "ì§ì ‘ ì…ë ¥":
            cp_sender_context = st.text_area(
                "ë°œì‹ ì ì†Œê°œ (ì§ì ‘ ì…ë ¥)",
                placeholder="ì˜ˆ: RISORIUS Inc. ê³µë™ì°½ì—…ì, AI/ML ê¸°ë°˜ ì œì•½ ì†”ë£¨ì…˜ ì „ë¬¸",
                height=60,
            )
        else:
            _sender_idx = _sender_options.index(_sender_choice) - 1
            _selected_sender = _existing_senders[_sender_idx]
            cp_sender_context = f"{_selected_sender.get('name_en', '')} | {_selected_sender.get('title_en', '')} | {_selected_sender.get('company_en', '')} | {_selected_sender.get('email', '')}"
            st.caption(f"ì„ íƒë¨: {cp_sender_context}")

        cp_extra = st.text_area(
            "ì¶”ê°€ ë©”ëª¨ (ì„ íƒ)",
            placeholder="ì˜ˆ: 2ì›” ë°©ë¬¸ ì˜ˆì •, ê²½ìŸì‚¬ Xì‚¬ ëŒ€ë¹„ ì°¨ë³„ì  ê°•ì¡°",
            height=60,
        )

        submitted = st.form_submit_button("ğŸ’¾ í”„ë¡œí•„ ì €ì¥", use_container_width=True)

        if submitted:
            if not cp_name.strip():
                st.error("í”„ë¡œí•„ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            elif not cp_product_desc.strip():
                st.error("ì œí’ˆ/ì„œë¹„ìŠ¤ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                new_id = db.save_campaign_profile(
                    name=cp_name.strip(),
                    product_name=cp_product_name.strip(),
                    product_description=cp_product_desc.strip(),
                    target_region=cp_target_region.strip(),
                    language=cp_language,
                    tone=cp_tone,
                    cta_type=cp_cta_type,
                    sender_context=cp_sender_context.strip(),
                    extra_notes=cp_extra.strip(),
                )
                st.session_state.active_profile_id = new_id
                st.success(f"í”„ë¡œí•„ '{cp_name}' ì €ì¥ ì™„ë£Œ! ìë™ìœ¼ë¡œ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PAGE: Target Discovery (íƒ€ê²Ÿ ë°œêµ´)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

elif page == "ğŸ¯ íƒ€ê²Ÿ ë°œêµ´":
    st.title("íƒ€ê²Ÿ ë°œêµ´")

    target_mode = st.radio(
        "íƒ€ê²Ÿ ìœ í˜•", ["company", "researcher"],
        format_func={"company": "ğŸ¢ íšŒì‚¬ íƒ€ê²Ÿ", "researcher": "ğŸ“ ì—°êµ¬ì íƒ€ê²Ÿ"}.__getitem__,
        horizontal=True, key="target_mode", label_visibility="collapsed",
    )

    if target_mode == "company":
        st.caption("ì œí’ˆ ì„¤ëª…ì„ ì…ë ¥í•˜ë©´ AIê°€ ì í•©í•œ íšŒì‚¬ì™€ ì§ì¢…ì„ ì¶”ì²œí•˜ê³ , í”„ë¦¬ì…‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

        if "ai_target_result" not in st.session_state:
            st.session_state.ai_target_result = None
        if "ai_target_verification" not in st.session_state:
            st.session_state.ai_target_verification = None
        if "ai_target_verdicts" not in st.session_state:
            st.session_state.ai_target_verdicts = {}
        if "agent_log" not in st.session_state:
            st.session_state.agent_log = []
        if "ai_target_parsed" not in st.session_state:
            st.session_state.ai_target_parsed = None
        if "_regen_preset" not in st.session_state:
            st.session_state._regen_preset = None

        # â”€â”€ Input Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.subheader("ì œí’ˆ/ì„œë¹„ìŠ¤ ì •ë³´")

        ai_product_desc = st.text_area(
            "ì œí’ˆ/ì„œë¹„ìŠ¤ ì„¤ëª… (í•„ìˆ˜)",
            height=150,
            placeholder="ì˜ˆ: Datasetê³¼ ì—°êµ¬ ëª©ì ì„ í”„ë¡¬í”„íŠ¸ë¡œ ë„£ìœ¼ë©´ ì„ìƒì‹œí—˜ ì‹œë®¬ë ˆì´ì…˜ê³¼ ë°”ì´ì˜¤ë§ˆì»¤ ë°œêµ´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” AI co-scientist",
            key="ai_product_desc",
        )

        col1, col2 = st.columns(2)
        with col1:
            ai_target_hint = st.text_input(
                "í¬ë§ ëŒ€ìƒ/ê´€ë ¨ ì§ì¢… (ììœ  ì…ë ¥, ì„ íƒ)",
                placeholder="ì˜ˆ: ë°”ì´ì˜¤í… R&D ë‹´ë‹¹ì, CNS ì—°êµ¬ ê´€ë ¨",
                key="ai_target_hint",
            )
        with col2:
            ai_region = st.text_input(
                "ì§€ì—­ ì œí•œ (ì„ íƒ)",
                placeholder="ì˜ˆ: Japan, US, Europe ë“± (ë¹„ì›Œë‘ë©´ ì „ì²´)",
                key="ai_target_region",
            )

        # Collect companies for exclusion option (from presets + current results)
        _existing_presets = db.get_presets()
        _preset_companies = set()
        for p in _existing_presets:
            for c in (p.get("companies") or "").split(","):
                c = c.strip()
                if c:
                    _preset_companies.add(c)

        _current_companies = set()
        if st.session_state.ai_target_parsed:
            for c in st.session_state.ai_target_parsed.get("tier1_companies", []):
                _current_companies.add(c.get("name", ""))
            for c in st.session_state.ai_target_parsed.get("tier2_companies", []):
                _current_companies.add(c.get("name", ""))
            _current_companies.discard("")

        _all_excludable = _preset_companies | _current_companies

        exclude_companies_set = set()
        if _all_excludable:
            ecol1, ecol2 = st.columns(2)
            with ecol1:
                if _preset_companies:
                    if st.checkbox(
                        f"í”„ë¦¬ì…‹ íšŒì‚¬ ì œì™¸ ({len(_preset_companies)}ê°œ)",
                        help=f"ì €ì¥ëœ í”„ë¦¬ì…‹: {', '.join(list(_preset_companies)[:8])}{'...' if len(_preset_companies) > 8 else ''}",
                    ):
                        exclude_companies_set |= _preset_companies
            with ecol2:
                if _current_companies:
                    if st.checkbox(
                        f"í˜„ì¬ ê²°ê³¼ íšŒì‚¬ ì œì™¸ ({len(_current_companies)}ê°œ)",
                        help="í˜„ì¬ í™”ë©´ì— í‘œì‹œëœ íšŒì‚¬ë¥¼ ì œì™¸í•˜ê³  ìƒˆë¡œìš´ íšŒì‚¬ë§Œ ì¶”ì²œ",
                    ):
                        exclude_companies_set |= _current_companies

        if st.button("ğŸ¤– AI íƒ€ê²Ÿ ì¶”ì²œ ì‹¤í–‰", type="primary", disabled=not ai_product_desc or st.session_state.get("agent_running")):
            # Combine product desc with hint
            full_desc = ai_product_desc
            if ai_target_hint:
                full_desc += f"\n\ní¬ë§ ëŒ€ìƒ/ê´€ë ¨ ì§ì¢…: {ai_target_hint}"

            # Build exclusion list
            exclude_companies = sorted(exclude_companies_set)
            exclude_section = ""
            if exclude_companies:
                exclude_section = (
                    f"\n\nì œì™¸ ëŒ€ìƒ íšŒì‚¬ (ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ë§ ê²ƒ): "
                    f"{', '.join(exclude_companies[:30])}"
                )

            region_line = f"\nì§€ì—­ ì œí•œ: {ai_region}" if ai_region else ""

            _ctx = build_campaign_context(st.session_state.get("active_profile"))
            _ctx_section = f"\n\n{_ctx}" if _ctx else ""
            agent_request = (
                f"ì•„ë˜ ì œí’ˆì— ëŒ€í•´ íƒ€ê²Ÿ íšŒì‚¬ë¥¼ ì°¾ì•„ì¤˜.\n\n"
                f"## ì œí’ˆ ì„¤ëª…\n{full_desc}"
                f"{region_line}{exclude_section}{_ctx_section}\n\n"
                f"ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ë¡œ ì›¹ ë¦¬ì„œì¹˜ë¥¼ ìˆ˜í–‰í•œ ë’¤, "
                f"ê²°ê³¼ë¥¼ Tier 1/Tier 2ë¡œ ë¶„ë¥˜í•˜ê³  save_resultsë¡œ ì €ì¥í•´ì¤˜."
            )

            # Phase 1: save params and rerun to show overlay
            _run_profile_id = st.session_state.get("active_profile_id")
            st.session_state._pending_agent1 = {
                "request": agent_request,
                "feedback": db.get_combined_feedback_text(_run_profile_id),
            }
            st.session_state.agent_running = True
            st.rerun()

        # Phase 2: execute pending Agent 1 task (overlay is already visible)
        if st.session_state.get("_pending_agent1"):
            _task = st.session_state.pop("_pending_agent1")
            try:
                from agent import CompanyListingAgent

                tracker = AgentProgressTracker("agent1")

                agent = CompanyListingAgent(
                    extra_feedback=_task["feedback"],
                    on_tool_call=tracker.on_tool_call,
                    on_tool_result=tracker.on_tool_result,
                    on_text=tracker.on_text,
                )

                agent_output = agent.run(_task["request"])

                st.session_state.agent_log = tracker.tool_log

                # Use saved JSON result if available, otherwise try parsing agent output
                result_json = agent.result_json
                if result_json:
                    st.session_state.ai_target_result = result_json
                else:
                    st.session_state.ai_target_result = agent_output

                st.session_state.ai_target_parsed = None
                st.session_state.ai_target_verification = None
                st.session_state.ai_target_verdicts = {}

                tracker.complete("íƒ€ê²Ÿ íƒìƒ‰ ì™„ë£Œ! ê·¼ê±° ê²€ì¦ ì‹œì‘...")

                # Auto-verify immediately after agent completes
                _auto_verify(st.session_state.ai_target_result, feedback=_task["feedback"])

            except Exception as e:
                if 'tracker' in dir():
                    tracker.fail(f"AI íƒ€ê²Ÿ ì¶”ì²œ ì‹¤íŒ¨: {e}")
                else:
                    st.error(f"AI íƒ€ê²Ÿ ì¶”ì²œ ì‹¤íŒ¨: {e}")
                import traceback
                st.code(traceback.format_exc())
            finally:
                st.session_state.agent_running = False
            st.rerun()

        # â”€â”€ Results Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.session_state.ai_target_result:
            st.divider()
            result_text = st.session_state.ai_target_result

            # Parse JSON on first load, then use editable copy
            if st.session_state.ai_target_parsed is None:
                json_match = re.search(r"```json\s*\n(.*?)```", result_text, re.DOTALL)
                parsed = None
                if json_match:
                    try:
                        parsed = json.loads(json_match.group(1))
                    except json.JSONDecodeError:
                        pass
                if not parsed:
                    try:
                        parsed = json.loads(result_text)
                    except json.JSONDecodeError:
                        pass
                st.session_state.ai_target_parsed = parsed

            parsed = st.session_state.ai_target_parsed

            if parsed:
                st.subheader("ì¶”ì²œ ê²°ê³¼")
                st.success(f"**{parsed.get('product_summary', '')}**")

                # Show agent activity log
                if st.session_state.agent_log:
                    with st.expander(f"Agent í™œë™ ë¡œê·¸ ({len(st.session_state.agent_log)}ê±´)", expanded=False):
                        st.code("\n".join(st.session_state.agent_log), language=None)

                # Show analysis if present
                if parsed.get("analysis"):
                    with st.expander("ì œí’ˆ ë¶„ì„", expanded=True):
                        st.markdown(parsed["analysis"])

                tier1 = parsed.get("tier1_companies", [])
                tier2 = parsed.get("tier2_companies", [])

                # Build verification + verdict lookups
                _vmap = {}
                if st.session_state.ai_target_verification:
                    for v in st.session_state.ai_target_verification:
                        _vmap[v.get("name", "")] = v.get("verification", {})
                _verdict_map = st.session_state.get("ai_target_verdicts", {})

                _tier_tab = st.radio(
                    "ê²°ê³¼ ë³´ê¸°",
                    ["tier1", "tier2", "titles"],
                    format_func=lambda x: {
                        "tier1": f"Tier 1 ({len(tier1)}ê°œ)",
                        "tier2": f"Tier 2 ({len(tier2)}ê°œ)",
                        "titles": "ì¶”ì²œ ì§ì¢…",
                    }[x],
                    horizontal=True,
                    label_visibility="collapsed",
                    key="ai_target_tier_tab",
                )

                if _tier_tab == "tier1":
                    if tier1:
                        for idx, c in enumerate(tier1):
                            col_card, col_actions = st.columns([5, 1])
                            with col_card:
                                _render_company_card(c, _vmap.get(c["name"]), _verdict_map.get(c["name"]))
                            with col_actions:
                                st.write("")  # spacing
                                if st.button("â†’ T2", key=f"t1to2_{idx}", help="Tier 2ë¡œ ì´ë™"):
                                    company = tier1.pop(idx)
                                    tier2.append(company)
                                    st.rerun()
                                if st.button("ì‚­ì œ", key=f"del_t1_{idx}", help="ëª©ë¡ì—ì„œ ì œê±°"):
                                    tier1.pop(idx)
                                    st.rerun()
                    else:
                        st.info("Tier 1 íšŒì‚¬ ì—†ìŒ")

                elif _tier_tab == "tier2":
                    if tier2:
                        for idx, c in enumerate(tier2):
                            col_card, col_actions = st.columns([5, 1])
                            with col_card:
                                _render_company_card(c, _vmap.get(c["name"]), _verdict_map.get(c["name"]))
                            with col_actions:
                                st.write("")  # spacing
                                if st.button("â†’ T1", key=f"t2to1_{idx}", help="Tier 1ìœ¼ë¡œ ì´ë™"):
                                    company = tier2.pop(idx)
                                    tier1.append(company)
                                    st.rerun()
                                if st.button("ì‚­ì œ", key=f"del_t2_{idx}", help="ëª©ë¡ì—ì„œ ì œê±°"):
                                    tier2.pop(idx)
                                    st.rerun()
                    else:
                        st.info("Tier 2 íšŒì‚¬ ì—†ìŒ")

                else:  # titles
                    dm = parsed.get("decision_makers", [])
                    eu = parsed.get("end_users", [])
                    if dm:
                        st.markdown("**ì˜ì‚¬ê²°ì •ì (Decision Makers):**")
                        for t in dm:
                            st.markdown(f"- {t}")
                    if eu:
                        st.markdown("**ì‹¤ì œ ì‚¬ìš©ì (End Users):**")
                        for t in eu:
                            st.markdown(f"- {t}")

                # â”€â”€ Verification Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if _verdict_map:
                    st.divider()
                    st.subheader("ê·¼ê±° êµì°¨ê²€ì¦ ê²°ê³¼")
                    st.caption("ì™¸ë¶€ ë°ì´í„°(ì›¹ + ClinicalTrials + PubMed) ìˆ˜ì§‘ í›„ Claudeê°€ AI ê·¼ê±°ì™€ ë¹„êµ ë¶„ì„")

                    total_v = len(_verdict_map)
                    confirmed = sum(1 for v in _verdict_map.values() if v.get("verdict") == "confirmed")
                    v_partial = sum(1 for v in _verdict_map.values() if v.get("verdict") == "partial")
                    unverified = sum(1 for v in _verdict_map.values() if v.get("verdict") == "unverified")
                    wrong = sum(1 for v in _verdict_map.values() if v.get("verdict") == "wrong")

                    vcol1, vcol2, vcol3, vcol4 = st.columns(4)
                    vcol1.metric("âœ… í™•ì¸ë¨", f"{confirmed}/{total_v}")
                    vcol2.metric("âš ï¸ ì¼ë¶€ í™•ì¸", f"{v_partial}/{total_v}")
                    vcol3.metric("â“ ë¯¸ê²€ì¦", f"{unverified}/{total_v}")
                    vcol4.metric("âŒ ë¶ˆì¼ì¹˜", f"{wrong}/{total_v}")

                    if wrong > 0:
                        st.error(f"{wrong}ê°œ íšŒì‚¬ì˜ AI ê·¼ê±°ê°€ ì™¸ë¶€ ë°ì´í„°ì™€ ë¶ˆì¼ì¹˜í•©ë‹ˆë‹¤. í•´ë‹¹ íšŒì‚¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    if unverified > 0:
                        st.warning(f"{unverified}ê°œ íšŒì‚¬ëŠ” ì™¸ë¶€ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê²€ì¦ ë¶ˆê°€í•©ë‹ˆë‹¤.")
                elif st.session_state.ai_target_verification:
                    st.divider()
                    st.subheader("ê·¼ê±° ê²€ì¦ ê²°ê³¼")
                    st.caption("ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (êµì°¨ê²€ì¦ ë¯¸ì™„ë£Œ)")

                    total_v = len(st.session_state.ai_target_verification)
                    verified = sum(1 for v in st.session_state.ai_target_verification
                                   if v.get("verification", {}).get("status") == "verified")
                    partial = sum(1 for v in st.session_state.ai_target_verification
                                  if v.get("verification", {}).get("status") == "partial")
                    no_data = sum(1 for v in st.session_state.ai_target_verification
                                  if v.get("verification", {}).get("status") == "no_data")

                    vcol1, vcol2, vcol3 = st.columns(3)
                    vcol1.metric("ê²€ì¦ë¨", f"{verified}/{total_v}")
                    vcol2.metric("ì¼ë¶€ í™•ì¸", f"{partial}/{total_v}")
                    vcol3.metric("ë°ì´í„° ì—†ìŒ", f"{no_data}/{total_v}")

                # â”€â”€ Export Results as Markdown â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.divider()
                st.subheader("ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")

                def _build_company_export_md():
                    lines = [f"# íƒ€ê²Ÿ íšŒì‚¬ ì¶”ì²œ ê²°ê³¼\n"]
                    lines.append(f"**ì œí’ˆ ìš”ì•½:** {parsed.get('product_summary', '')}\n")
                    _exp_analysis = parsed.get("analysis", "")
                    if _exp_analysis:
                        lines.append(f"## ë¶„ì„\n{_exp_analysis}\n")

                    for tier_label, tier_list, tier_name in [
                        ("Tier 1 (í•µì‹¬ íƒ€ê²Ÿ)", tier1, "tier1"),
                        ("Tier 2 (ì ì¬ì  íƒ€ê²Ÿ)", tier2, "tier2"),
                    ]:
                        lines.append(f"## {tier_label} â€” {len(tier_list)}ê°œ\n")
                        for i, c in enumerate(tier_list, 1):
                            c_name = c.get("name", "")
                            lines.append(f"### {i}. {c_name}")
                            if c.get("reason"):
                                lines.append(f"- **ìš”ì•½:** {c['reason']}")
                            if c.get("evidence"):
                                lines.append(f"- **ê·¼ê±°:** {c['evidence']}")
                            if c.get("tier_reason"):
                                lines.append(f"- **Tier ì‚°ì •:** {c['tier_reason']}")
                            # Add verdict if available
                            _v = _verdict_map.get(c_name, {})
                            if _v:
                                _emoji = {"confirmed": "âœ…", "partial": "âš ï¸", "unverified": "â“", "wrong": "âŒ"}.get(_v.get("verdict", ""), "")
                                lines.append(f"- **êµì°¨ê²€ì¦:** {_emoji} {_v.get('verdict', '')} â€” {_v.get('explanation', '')}")
                            lines.append("")

                    dm = parsed.get("decision_makers", [])
                    eu = parsed.get("end_users", [])
                    if dm or eu:
                        lines.append("## ì¶”ì²œ ì§ì¢…\n")
                        if dm:
                            lines.append(f"**ì˜ì‚¬ê²°ì •ì:** {', '.join(dm)}")
                        if eu:
                            lines.append(f"**ì‹¤ì œ ì‚¬ìš©ì:** {', '.join(eu)}")
                        lines.append("")

                    return "\n".join(lines)

                _export_md = _build_company_export_md()
                st.download_button(
                    "ğŸ“¥ Markdownìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°",
                    data=_export_md,
                    file_name="target_companies_result.md",
                    mime="text/markdown",
                    key="export_company_md",
                )

                # â”€â”€ Feedback Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.divider()
                st.subheader("í”¼ë“œë°±")
                st.caption("ê²°ê³¼ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì…ë ¥í•˜ë©´ AIê°€ ë°˜ì˜í•´ì„œ ì¬ì¶”ì²œí•©ë‹ˆë‹¤.")

                ai_feedback = st.text_area(
                    "í”¼ë“œë°± (ììœ  ì…ë ¥)",
                    height=100,
                    placeholder="ì˜ˆ: CROëŠ” ë¹¼ì¤˜, ë°”ì´ì˜¤í…ë§Œ ë‚¨ê²¨, ì¼ë³¸ íšŒì‚¬ë¥¼ ë” ì¶”ê°€í•´ì¤˜, Tier 2ì—ì„œ XXëŠ” Tier 1ìœ¼ë¡œ ì˜¬ë ¤ì¤˜",
                    key="ai_feedback",
                )

                _has_profile = bool(st.session_state.get("active_profile_id"))
                fcol1, fcol2, fcol3 = st.columns([2, 2, 1])
                with fcol1:
                    _fb_global = st.checkbox("ê¸€ë¡œë²Œ", value=True, key="fb_scope_global",
                                             help="ëª¨ë“  í”„ë¡œí•„ì— ê³µí†µ ì ìš©")
                    _fb_profile = st.checkbox(
                        "í”„ë¡œí•„ ì „ìš©", value=_has_profile, key="fb_scope_profile",
                        disabled=not _has_profile,
                        help="í™œì„± í”„ë¡œí•„ì—ì„œë§Œ ì ìš©",
                    )
                with fcol2:
                    if st.button("ğŸ”„ í”¼ë“œë°± ë°˜ì˜ ì¬ì¶”ì²œ", type="primary", disabled=not ai_feedback or st.session_state.get("agent_running")):
                        # Save feedback to DB â€” global and/or profile-specific
                        _active_pid = st.session_state.get("active_profile_id")
                        if _fb_global:
                            db.add_target_feedback(
                                ai_feedback,
                                product_summary=parsed.get("product_summary", ""),
                                profile_id=None,
                            )
                        if _fb_profile and _active_pid:
                            db.add_target_feedback(
                                ai_feedback,
                                product_summary=parsed.get("product_summary", ""),
                                profile_id=_active_pid,
                            )
                        prev_json = json.dumps(parsed, ensure_ascii=False)
                        full_desc = ai_product_desc or ""
                        if ai_target_hint:
                            full_desc += f"\n\ní¬ë§ ëŒ€ìƒ/ê´€ë ¨ ì§ì¢…: {ai_target_hint}"

                        _fb_run_pid = st.session_state.get("active_profile_id")

                        # Phase 1: save params and rerun to show overlay
                        st.session_state._pending_fb_rerun = {
                            "request": (
                                f"ì´ì „ ì¶”ì²œ ê²°ê³¼ì— ëŒ€í•œ ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •ëœ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ì¤˜.\n\n"
                                f"## ì œí’ˆ ì„¤ëª…\n{full_desc}\n\n"
                                f"## ì´ì „ ì¶”ì²œ ê²°ê³¼\n```json\n{prev_json}\n```\n\n"
                                f"## ì‚¬ìš©ì í”¼ë“œë°±\n{ai_feedback}\n\n"
                                f"í”¼ë“œë°±ì„ ì •í™•íˆ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •í•´ì¤˜. "
                                f"í•„ìš”í•˜ë©´ ì¶”ê°€ ì›¹ ë¦¬ì„œì¹˜ë¥¼ í•´ë„ ì¢‹ì•„. "
                                f"ìµœì¢… ê²°ê³¼ëŠ” ë°˜ë“œì‹œ save_resultsë¡œ ì €ì¥í•´ì¤˜."
                            ),
                            "feedback": db.get_combined_feedback_text(_fb_run_pid),
                        }
                        st.session_state.agent_running = True
                        st.rerun()

                # Phase 2: execute pending feedback re-recommendation
                if st.session_state.get("_pending_fb_rerun"):
                    _task = st.session_state.pop("_pending_fb_rerun")
                    try:
                        from agent import CompanyListingAgent

                        fb_tracker = AgentProgressTracker("agent1")
                        agent = CompanyListingAgent(
                            extra_feedback=_task["feedback"],
                            on_tool_call=fb_tracker.on_tool_call,
                            on_tool_result=fb_tracker.on_tool_result,
                        )
                        agent.run(_task["request"])

                        result_json = agent.result_json
                        if result_json:
                            st.session_state.ai_target_result = result_json
                        st.session_state.ai_target_parsed = None
                        st.session_state.ai_target_verification = None
                        st.session_state.ai_target_verdicts = {}
                        fb_tracker.complete("í”¼ë“œë°± ë°˜ì˜ ì™„ë£Œ!")
                    except Exception as e:
                        if 'fb_tracker' in dir():
                            fb_tracker.fail(f"ì¬ì¶”ì²œ ì‹¤íŒ¨: {e}")
                        else:
                            st.error(f"ì¬ì¶”ì²œ ì‹¤íŒ¨: {e}")
                    finally:
                        st.session_state.agent_running = False
                    st.rerun()
                with fcol2:
                    if st.button("ğŸ—‘ï¸ ê²°ê³¼ ì´ˆê¸°í™”"):
                        st.session_state.ai_target_result = None
                        st.session_state.ai_target_parsed = None
                        st.session_state.ai_target_verification = None
                        st.session_state.ai_target_verdicts = {}
                        st.session_state.agent_log = []
                        st.rerun()

                # â”€â”€ Save as Preset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.divider()
                st.subheader("í”„ë¦¬ì…‹ìœ¼ë¡œ ì €ì¥")
                st.caption("ì¶”ì²œ ê²°ê³¼ë¥¼ í”„ë¦¬ì…‹ìœ¼ë¡œ ì €ì¥í•˜ë©´ 'ì»¨íƒ ì„œì¹­' í˜ì´ì§€ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                rec = parsed.get("recommended_search_params", {})
                tier1_names = [c["name"] for c in parsed.get("tier1_companies", [])]
                tier2_names = [c["name"] for c in parsed.get("tier2_companies", [])]
                # Combine all recommended titles (decision_makers + end_users)
                _all_titles = parsed.get("decision_makers", []) + parsed.get("end_users", [])
                _all_titles_str = ", ".join(_all_titles) if _all_titles else rec.get("titles", "")

                save_scope = st.radio(
                    "ì €ì¥í•  íšŒì‚¬ ë²”ìœ„",
                    ["Tier 1 + Tier 2 ì „ì²´", "Tier 1ë§Œ", "Tier 2ë§Œ", "Tier 1 / Tier 2 ê°ê° (2ê°œ í”„ë¦¬ì…‹)"],
                    horizontal=True,
                    key="ai_save_scope",
                )

                if save_scope == "Tier 1 / Tier 2 ê°ê° (2ê°œ í”„ë¦¬ì…‹)":
                    _save_groups = [("_T1", tier1_names), ("_T2", tier2_names)]
                    companies_to_save = tier1_names + tier2_names  # for preview
                elif save_scope == "Tier 2ë§Œ":
                    _save_groups = [("", tier2_names)]
                    companies_to_save = tier2_names
                elif save_scope == "Tier 1ë§Œ":
                    _save_groups = [("", tier1_names)]
                    companies_to_save = tier1_names
                else:
                    _save_groups = [("", tier1_names + tier2_names)]
                    companies_to_save = tier1_names + tier2_names

                # Preview what will be saved
                with st.expander("ì €ì¥ë  í”„ë¦¬ì…‹ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    st.markdown(f"**ì‚°ì—…:** {rec.get('industry', '')}")
                    st.markdown(f"**ì§í•¨:** {_all_titles_str}")
                    st.markdown(f"**í‚¤ì›Œë“œ:** {rec.get('keywords', '')}")
                    if save_scope == "Tier 1 / Tier 2 ê°ê° (2ê°œ í”„ë¦¬ì…‹)":
                        st.markdown(f"**Tier 1 ({len(tier1_names)}ê°œ):** {', '.join(tier1_names[:10])}{'...' if len(tier1_names) > 10 else ''}")
                        st.markdown(f"**Tier 2 ({len(tier2_names)}ê°œ):** {', '.join(tier2_names[:10])}{'...' if len(tier2_names) > 10 else ''}")
                    else:
                        st.markdown(f"**íšŒì‚¬ ({len(companies_to_save)}ê°œ):** {', '.join(companies_to_save[:10])}{'...' if len(companies_to_save) > 10 else ''}")

                if save_scope == "Tier 1 / Tier 2 ê°ê° (2ê°œ í”„ë¦¬ì…‹)":
                    _ncol1, _ncol2 = st.columns(2)
                    with _ncol1:
                        preset_name_t1 = st.text_input(
                            "Tier 1 í”„ë¦¬ì…‹ ì´ë¦„",
                            value=f"AI_{datetime.now().strftime('%y%m%d')}_T1",
                            key="ai_preset_name_t1",
                        )
                    with _ncol2:
                        preset_name_t2 = st.text_input(
                            "Tier 2 í”„ë¦¬ì…‹ ì´ë¦„",
                            value=f"AI_{datetime.now().strftime('%y%m%d')}_T2",
                            key="ai_preset_name_t2",
                        )
                    # Override _save_groups with individual names
                    _save_groups = [(preset_name_t1, tier1_names), (preset_name_t2, tier2_names)]
                    _can_save = bool(preset_name_t1 and preset_name_t2)
                else:
                    preset_name = st.text_input(
                        "í”„ë¦¬ì…‹ ì´ë¦„",
                        value=f"AI_{datetime.now().strftime('%y%m%d')}",
                        key="ai_preset_name",
                    )
                    # Use preset_name directly as the full name
                    _save_groups = [(preset_name, c) for _, c in _save_groups]
                    _can_save = bool(preset_name)

                if st.button("ğŸ’¾ í”„ë¦¬ì…‹ ì €ì¥ â†’ ì»¨íƒ ì„œì¹­", type="primary", disabled=not _can_save):
                        for _name, _companies in _save_groups:
                            if not _companies:
                                continue
                            db.save_preset(
                                name=_name,
                                industry=rec.get("industry", ""),
                                titles=_all_titles_str,
                                locations=ai_region or "",
                                companies=", ".join(_companies),
                                keywords=rec.get("keywords", ""),
                                max_results=100,
                                feedback_hash=_get_feedback_hash(),
                                product_description=ai_product_desc or "",
                                target_hint=ai_target_hint or "",
                                target_region=ai_region or "",
                            )
                        _saved_names = ", ".join(f"'{n}'" for n, c in _save_groups if c)
                        st.session_state.ai_target_result = None
                        st.session_state.ai_target_parsed = None
                        st.session_state.ai_target_verification = None
                        st.session_state.ai_target_verdicts = {}
                        st.session_state.ai_web_context = ""
                        st.session_state.active_page = "ğŸ” ì»¨íƒ ì„œì¹­"
                        st.session_state.contact_search_mode = "manual"
                        st.session_state.prospect_step = "search"
                        st.success(f"í”„ë¦¬ì…‹ {_saved_names} ì €ì¥ ì™„ë£Œ! ì»¨íƒ ì„œì¹­ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                        st.rerun()
            else:
                # Couldn't parse JSON, show raw
                st.warning("JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ê²°ê³¼:")
                st.markdown(result_text[:3000])
                if len(result_text) > 3000:
                    st.caption("... (ì¶œë ¥ì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œ)")
                if st.button("ğŸ—‘ï¸ ê²°ê³¼ ì´ˆê¸°í™”"):
                    st.session_state.ai_target_result = None
                    st.session_state.ai_target_parsed = None
                    st.session_state.ai_target_verification = None
                    st.session_state.ai_target_verdicts = {}
                    st.session_state.ai_web_context = ""
                    st.rerun()

        # â”€â”€ Previous presets (for reference) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        st.subheader("ì €ì¥ëœ í”„ë¦¬ì…‹ ëª©ë¡")
        saved_presets = db.get_presets()
        current_fb_hash = _get_feedback_hash()
        if saved_presets:
            for sp in saved_presets:
                companies_preview = sp.get("companies", "")
                companies_count = len([c for c in companies_preview.split(",") if c.strip()]) if companies_preview else 0
                stale = sp.get("feedback_hash") and sp["feedback_hash"] != current_fb_hash
                stale_tag = " âš ï¸ _í”¼ë“œë°± ë³€ê²½ë¨_" if stale else ""
                has_product_desc = bool((sp.get("product_description") or "").strip())
                sp_col1, sp_col2, sp_col3 = st.columns([5, 1, 1])
                with sp_col1:
                    st.markdown(
                        f"- **{sp['name']}** â€” {sp.get('industry', '')} | "
                        f"ì§í•¨: {sp.get('titles', '')[:30]} | "
                        f"íšŒì‚¬: {companies_count}ê°œ{stale_tag}"
                    )
                with sp_col2:
                    regen_disabled = not has_product_desc
                    regen_help = "ì œí’ˆ ì„¤ëª… ë¯¸ì €ì¥ â€” ìƒˆ í”„ë¦¬ì…‹ë¶€í„° ì¬ìƒì„± ê°€ëŠ¥" if regen_disabled else "í˜„ì¬ í”¼ë“œë°±ìœ¼ë¡œ íƒ€ê²Ÿ ì¬íƒìƒ‰"
                    if st.button("ì¬ìƒì„±", key=f"regen_preset_{sp['id']}", disabled=regen_disabled or st.session_state.get("agent_running"), help=regen_help):
                        st.session_state._regen_preset = sp
                        st.session_state.agent_running = True
                        st.rerun()
                with sp_col3:
                    if st.button("ì‚­ì œ", key=f"del_preset_{sp['id']}"):
                        db.delete_preset(sp["id"])
                        st.rerun()

            # Phase 2: handle preset regeneration (overlay already visible)
            if st.session_state.get("_regen_preset") and st.session_state.get("agent_running"):
                rp = st.session_state._regen_preset
                st.info(f"í”„ë¦¬ì…‹ **{rp['name']}** ì¬ìƒì„± ì¤‘... (í”¼ë“œë°± ë°˜ì˜)")
                regen_desc = rp.get("product_description", "")
                regen_hint = rp.get("target_hint", "")
                regen_region = rp.get("target_region", "")

                full_desc = regen_desc
                if regen_hint:
                    full_desc += f"\n\ní¬ë§ ëŒ€ìƒ/ê´€ë ¨ ì§ì¢…: {regen_hint}"

                region_line = f"\nì§€ì—­ ì œí•œ: {regen_region}" if regen_region else ""

                existing_companies = [c.strip() for c in rp.get("companies", "").split(",") if c.strip()]

                _profile_id = st.session_state.get("active_profile_id")
                _profile_fb = db.get_combined_feedback_text(_profile_id)

                _ctx = build_campaign_context(st.session_state.get("active_profile"))
                _ctx_section = f"\n\n{_ctx}" if _ctx else ""

                agent_request = (
                    f"ì•„ë˜ ì œí’ˆì— ëŒ€í•´ íƒ€ê²Ÿ íšŒì‚¬ë¥¼ ì°¾ì•„ì¤˜.\n\n"
                    f"## ì œí’ˆ ì„¤ëª…\n{full_desc}"
                    f"{region_line}{_ctx_section}\n\n"
                    f"ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ë¡œ ì›¹ ë¦¬ì„œì¹˜ë¥¼ ìˆ˜í–‰í•œ ë’¤, "
                    f"ê²°ê³¼ë¥¼ Tier 1/Tier 2ë¡œ ë¶„ë¥˜í•˜ê³  save_resultsë¡œ ì €ì¥í•´ì¤˜."
                )

                try:
                    from agent import CompanyListingAgent

                    regen_tracker = AgentProgressTracker("agent1")
                    agent = CompanyListingAgent(
                        extra_feedback=_profile_fb,
                        on_tool_call=regen_tracker.on_tool_call,
                        on_tool_result=regen_tracker.on_tool_result,
                        on_text=regen_tracker.on_text,
                    )
                    agent.run(agent_request)

                    result_json = agent.result_json
                    if result_json:
                        st.session_state.ai_target_result = result_json
                    else:
                        st.session_state.ai_target_result = None

                    st.session_state.ai_target_parsed = None
                    st.session_state.ai_target_verification = None
                    st.session_state.ai_target_verdicts = {}
                    regen_tracker.complete("ì¬ìƒì„± ì™„ë£Œ!")

                    # Auto-verify
                    if st.session_state.ai_target_result:
                        _auto_verify(st.session_state.ai_target_result, feedback=_profile_fb)
                except Exception as e:
                    st.error(f"ì¬ìƒì„± ì‹¤íŒ¨: {e}")
                    import traceback
                    st.code(traceback.format_exc())
                finally:
                    st.session_state._regen_preset = None
                    st.session_state.agent_running = False
                st.rerun()
        else:
            st.info("ì €ì¥ëœ í”„ë¦¬ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. AI íƒ€ê²Ÿ ì¶”ì²œì„ ì‹¤í–‰í•´ì„œ í”„ë¦¬ì…‹ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.")

        # â”€â”€ Feedback Log Management â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        st.subheader("í”¼ë“œë°± ì´ë ¥ ê´€ë¦¬")

        _active_pid = st.session_state.get("active_profile_id")
        _active_profile_name = ""
        if _active_pid:
            _ap_data = db.get_campaign_profile(_active_pid)
            _active_profile_name = _ap_data["name"] if _ap_data else ""

        fb_tab_global, fb_tab_profile = st.tabs([
            "ê¸€ë¡œë²Œ (ëª¨ë“  í”„ë¡œí•„ ê³µí†µ)",
            f"í”„ë¡œí•„ ì „ìš© ({_active_profile_name})" if _active_profile_name else "í”„ë¡œí•„ ì „ìš© (ë¯¸ì„ íƒ)",
        ])

        with fb_tab_global:
            st.caption("ì—¬ê¸°ì— ëˆ„ì ëœ í”¼ë“œë°±ì€ **ëª¨ë“ ** íƒ€ê²Ÿ ì¶”ì²œ ì‹œ ìë™ ë°˜ì˜ë©ë‹ˆë‹¤.")
            # Read and parse file-based global feedback entries
            feedback_entries = []
            if _TARGET_FEEDBACK_PATH.exists():
                raw = _TARGET_FEEDBACK_PATH.read_text(encoding="utf-8")
                for line in raw.splitlines():
                    stripped = line.strip()
                    if stripped.startswith("- ["):
                        feedback_entries.append(stripped)

            # Also show DB-based global feedback
            db_global_fb = db.get_target_feedback(profile_id=None)

            if feedback_entries:
                st.markdown("**íŒŒì¼ ê¸°ë°˜ (ë ˆê±°ì‹œ)**")
                for i, entry in enumerate(feedback_entries):
                    col_text, col_del = st.columns([9, 1])
                    with col_text:
                        st.markdown(entry)
                    with col_del:
                        if st.button("x", key=f"del_fb_{i}"):
                            feedback_entries.pop(i)
                            _rewrite_feedback_log(feedback_entries)
                            st.rerun()

            if db_global_fb:
                for fb in db_global_fb:
                    col_text, col_del = st.columns([9, 1])
                    ts = fb["created_at"][:16] if fb.get("created_at") else ""
                    ps = f"({fb['product_summary']}) " if fb.get("product_summary") else ""
                    with col_text:
                        st.markdown(f"- [{ts}] {ps}{fb['feedback']}")
                    with col_del:
                        if st.button("x", key=f"del_dbfb_g_{fb['id']}"):
                            db.delete_target_feedback(fb["id"])
                            st.rerun()

            total_global = len(feedback_entries) + len(db_global_fb)
            if total_global:
                st.caption(f"ì´ {total_global}ê±´")
            else:
                st.info("ê¸€ë¡œë²Œ í”¼ë“œë°±ì´ ì—†ìŠµë‹ˆë‹¤.")

        with fb_tab_profile:
            if not _active_pid:
                st.warning("ìº í˜ì¸ í”„ë¡œí•„ì„ ë¨¼ì € í™œì„±í™”í•˜ì„¸ìš”. ì´ íƒ­ì€ í™œì„± í”„ë¡œí•„ ì „ìš© í”¼ë“œë°±ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.")
            else:
                st.caption(f"**{_active_profile_name}** í”„ë¡œí•„ì—ì„œ íƒ€ê²Ÿ ì¶”ì²œí•  ë•Œë§Œ ì ìš©ë˜ëŠ” í”¼ë“œë°±ì…ë‹ˆë‹¤.")
                profile_fb = db.get_target_feedback(profile_id=_active_pid)
                if profile_fb:
                    for fb in profile_fb:
                        col_text, col_del = st.columns([9, 1])
                        ts = fb["created_at"][:16] if fb.get("created_at") else ""
                        ps = f"({fb['product_summary']}) " if fb.get("product_summary") else ""
                        with col_text:
                            st.markdown(f"- [{ts}] {ps}{fb['feedback']}")
                        with col_del:
                            if st.button("x", key=f"del_dbfb_p_{fb['id']}"):
                                db.delete_target_feedback(fb["id"])
                                st.rerun()
                    st.caption(f"ì´ {len(profile_fb)}ê±´")
                else:
                    st.info(f"'{_active_profile_name}' í”„ë¡œí•„ ì „ìš© í”¼ë“œë°±ì´ ì—†ìŠµë‹ˆë‹¤.")

        # â”€â”€ Unified feedback input (below tabs) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("#### í”¼ë“œë°± ì¶”ê°€")
        manual_fb = st.text_input(
            "í”¼ë“œë°± ë‚´ìš©",
            placeholder="ì˜ˆ: CRO/CMO íšŒì‚¬ëŠ” í•­ìƒ ì œì™¸, ë°”ì´ì˜¤í…ë§Œ ë‚¨ê²¨ì¤˜",
            key="manual_fb_unified",
        )
        _uf_c1, _uf_c2, _uf_c3 = st.columns([1, 1, 1])
        with _uf_c1:
            _uf_global = st.checkbox("ê¸€ë¡œë²Œ (ëª¨ë“  í”„ë¡œí•„)", value=True, key="uf_scope_global")
        with _uf_c2:
            _uf_profile = st.checkbox(
                f"í”„ë¡œí•„ ì „ìš© ({_active_profile_name})" if _active_profile_name else "í”„ë¡œí•„ ì „ìš© (ë¯¸ì„ íƒ)",
                value=bool(_active_pid),
                key="uf_scope_profile",
                disabled=not _active_pid,
            )
        with _uf_c3:
            if st.button("ì¶”ê°€", key="add_fb_unified", disabled=not manual_fb or (not _uf_global and not _uf_profile)):
                if _uf_global:
                    db.add_target_feedback(manual_fb, product_summary="ìˆ˜ë™ ì…ë ¥", profile_id=None)
                if _uf_profile and _active_pid:
                    db.add_target_feedback(manual_fb, product_summary="ìˆ˜ë™ ì…ë ¥", profile_id=_active_pid)
                st.rerun()



    elif target_mode == "researcher":
        st.caption("ì œí’ˆ ì„¤ëª…ì„ ì…ë ¥í•˜ë©´ AIê°€ ì í•©í•œ í•™ìˆ  ì—°êµ¬ì/êµìˆ˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")

        if "ai_researcher_result" not in st.session_state:
            st.session_state.ai_researcher_result = None
        if "ai_researcher_parsed" not in st.session_state:
            st.session_state.ai_researcher_parsed = None
        if "ai_researcher_verification" not in st.session_state:
            st.session_state.ai_researcher_verification = None
        if "ai_researcher_verdicts" not in st.session_state:
            st.session_state.ai_researcher_verdicts = {}

        # â”€â”€ Input Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.subheader("ì œí’ˆ/ì„œë¹„ìŠ¤ ì •ë³´")

        _active_pid = st.session_state.get("active_profile_id")
        _run_profile_id = _active_pid

        # Build campaign context if profile active
        _r_campaign_ctx = ""
        if _active_pid:
            _r_campaign_ctx = build_campaign_context(st.session_state.get("active_profile"))
            if _r_campaign_ctx:
                with st.expander("í™œì„± í”„ë¡œí•„ ì»¨í…ìŠ¤íŠ¸ (ìë™ í¬í•¨)", expanded=False):
                    st.text(_r_campaign_ctx[:500])

        researcher_product_desc = st.text_area(
            "ì œí’ˆ/ì„œë¹„ìŠ¤ ì„¤ëª… (í•„ìˆ˜)",
            height=150,
            placeholder="ì˜ˆ: CNS dataset + ì—°êµ¬ ëª©ì ì„ ì…ë ¥í•˜ë©´ ì„ìƒì‹œí—˜ ì‹œë®¬ë ˆì´ì…˜ê³¼ ë°”ì´ì˜¤ë§ˆì»¤ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” AI co-scientist",
            key="researcher_product_desc",
        )

        _rc1, _rc2 = st.columns(2)
        with _rc1:
            researcher_areas = st.text_input(
                "íƒ€ê²Ÿ ì—°êµ¬ ë¶„ì•¼ (ì„ íƒ)",
                placeholder="ì˜ˆ: ì‹ ê²½ê³¼í•™, ì •ì‹ ì˜í•™, ë‡Œì „ì¦, ìˆ˜ë©´ ì—°êµ¬",
                key="researcher_areas",
            )
        with _rc2:
            researcher_region = st.text_input(
                "ì§€ì—­ ì œí•œ (ì„ íƒ)",
                placeholder="ì˜ˆ: Japan, US, Europe",
                key="researcher_region",
            )

        # â”€â”€ Execute Button â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.button("ğŸ¤– AI ì—°êµ¬ì ì¶”ì²œ ì‹¤í–‰", type="primary",
                      disabled=not researcher_product_desc or st.session_state.get("agent_running")):
            full_desc = researcher_product_desc
            if _r_campaign_ctx:
                full_desc = f"{_r_campaign_ctx}\n\n{researcher_product_desc}"
            if researcher_areas:
                full_desc += f"\n\níƒ€ê²Ÿ ì—°êµ¬ ë¶„ì•¼: {researcher_areas}"
            region_line = f"\nì§€ì—­ ì œí•œ: {researcher_region}" if researcher_region else ""

            agent_request = (
                f"ì•„ë˜ ì œí’ˆì— ì í•©í•œ í•™ìˆ  ì—°êµ¬ì/êµìˆ˜ë¥¼ ì°¾ì•„ì¤˜.\n\n"
                f"## ì œí’ˆ ì„¤ëª…\n{full_desc}{region_line}\n\n"
                f"ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ë¡œ ì›¹ ë¦¬ì„œì¹˜ë¥¼ ìˆ˜í–‰í•œ ë’¤, "
                f"ê²°ê³¼ë¥¼ Tier 1/Tier 2ë¡œ ë¶„ë¥˜í•˜ê³  JSONìœ¼ë¡œ ì¶œë ¥í•´ì¤˜."
            )

            st.session_state._pending_researcher_agent = {
                "request": agent_request,
                "feedback": db.get_combined_feedback_text(_run_profile_id),
            }
            st.session_state.agent_running = True
            st.rerun()

        # Phase 2: execute pending researcher agent
        if st.session_state.get("_pending_researcher_agent"):
            # Overlay
            st.markdown(
                '<div style="position:fixed;top:0;left:0;width:100vw;height:100vh;'
                'background:rgba(0,0,0,0.55);z-index:9999;display:flex;'
                'align-items:center;justify-content:center;">'
                '<div style="background:#1e1e2e;padding:2rem 3rem;border-radius:12px;'
                'color:white;text-align:center;font-size:1.2rem;">'
                'ğŸ”¬ AI ì—°êµ¬ì ì¶”ì²œ ì‹¤í–‰ ì¤‘...<br>'
                '<small style="color:#aaa;">ì›¹ ê²€ìƒ‰ â†’ ë¶„ì„ â†’ ì—°êµ¬ì ì¶”ì²œ (1~3ë¶„ ì†Œìš”)</small>'
                '</div></div>',
                unsafe_allow_html=True,
            )

            _task = st.session_state.pop("_pending_researcher_agent")
            try:
                from agent import ResearcherFinderAgent
                tracker = AgentProgressTracker("agent1")
                agent = ResearcherFinderAgent(
                    extra_feedback=_task["feedback"],
                    on_tool_call=tracker.on_tool_call,
                    on_tool_result=tracker.on_tool_result,
                    on_text=tracker.on_text,
                )
                agent.run(_task["request"])
                result_json = agent.result_json
                if result_json:
                    st.session_state.ai_researcher_result = result_json
                    st.session_state.ai_researcher_parsed = None
                    st.session_state.ai_researcher_verification = None
                    st.session_state.ai_researcher_verdicts = {}

                tracker.complete("ì—°êµ¬ì íƒìƒ‰ ì™„ë£Œ! ê·¼ê±° ê²€ì¦ ì‹œì‘...")

                # Auto-verify immediately after agent completes
                if st.session_state.ai_researcher_result:
                    _auto_verify_researchers(
                        st.session_state.ai_researcher_result,
                        feedback=_task["feedback"],
                    )
            except Exception as e:
                logger.error(f"ResearcherFinderAgent failed: {e}")
                st.error(f"AI ì—°êµ¬ì ì¶”ì²œ ì‹¤íŒ¨: {e}")
                import traceback
                st.code(traceback.format_exc())
            finally:
                st.session_state.agent_running = False
            st.rerun()

        # â”€â”€ Results Display â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.session_state.ai_researcher_result:
            # Parse JSON from result
            if st.session_state.ai_researcher_parsed is None:
                _raw = st.session_state.ai_researcher_result
                try:
                    _parsed = json.loads(_raw)
                except (json.JSONDecodeError, TypeError):
                    # Try to extract JSON from markdown code block
                    import re
                    _m = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", _raw, re.DOTALL)
                    if _m:
                        try:
                            _parsed = json.loads(_m.group(1))
                        except json.JSONDecodeError:
                            _parsed = None
                    else:
                        _parsed = None
                st.session_state.ai_researcher_parsed = _parsed

            parsed = st.session_state.ai_researcher_parsed

            if parsed:
                st.subheader("ì¶”ì²œ ê²°ê³¼")
                st.success(f"**{parsed.get('product_summary', '')}**")

                _analysis = parsed.get("analysis", "")
                if _analysis:
                    with st.expander("ì œí’ˆ-ì—°êµ¬ ì—°ê²° ë¶„ì„", expanded=False):
                        st.markdown(_analysis)

                tier1 = parsed.get("tier1_researchers", [])
                tier2 = parsed.get("tier2_researchers", [])

                # Build verification + verdict lookups
                _r_vmap = {}
                if st.session_state.ai_researcher_verification:
                    for rv in st.session_state.ai_researcher_verification:
                        _r_vmap[rv.get("name", "")] = rv
                _r_verdict_map = st.session_state.get("ai_researcher_verdicts", {})

                _tier_tab = st.radio(
                    "ê²°ê³¼ ë³´ê¸°",
                    ["tier1", "tier2", "areas"],
                    format_func=lambda x: {
                        "tier1": f"Tier 1 ({len(tier1)}ëª…)",
                        "tier2": f"Tier 2 ({len(tier2)}ëª…)",
                        "areas": "ì—°êµ¬ ë¶„ì•¼",
                    }[x],
                    horizontal=True,
                    label_visibility="collapsed",
                    key="researcher_tier_tab",
                )

                if _tier_tab == "tier1":
                    if tier1:
                        for idx, r in enumerate(tier1):
                            # Merge verification data into card
                            r_name = r.get("name", "")
                            r_with_v = {**r}
                            if r_name in _r_vmap:
                                r_with_v["verification"] = _r_vmap[r_name].get("verification", {})
                            col_card, col_actions = st.columns([5, 1])
                            with col_card:
                                _render_researcher_card(r_with_v, _r_verdict_map.get(r_name))
                            with col_actions:
                                st.write("")
                                if st.button("â†’ T2", key=f"r_t1to2_{idx}", help="Tier 2ë¡œ ì´ë™"):
                                    researcher = tier1.pop(idx)
                                    tier2.append(researcher)
                                    st.rerun()
                                if st.button("ì‚­ì œ", key=f"r_del_t1_{idx}", help="ëª©ë¡ì—ì„œ ì œê±°"):
                                    tier1.pop(idx)
                                    st.rerun()
                    else:
                        st.info("Tier 1 ì—°êµ¬ì ì—†ìŒ")

                elif _tier_tab == "tier2":
                    if tier2:
                        for idx, r in enumerate(tier2):
                            r_name = r.get("name", "")
                            r_with_v = {**r}
                            if r_name in _r_vmap:
                                r_with_v["verification"] = _r_vmap[r_name].get("verification", {})
                            col_card, col_actions = st.columns([5, 1])
                            with col_card:
                                _render_researcher_card(r_with_v, _r_verdict_map.get(r_name))
                            with col_actions:
                                st.write("")
                                if st.button("â†’ T1", key=f"r_t2to1_{idx}", help="Tier 1ìœ¼ë¡œ ì´ë™"):
                                    researcher = tier2.pop(idx)
                                    tier1.append(researcher)
                                    st.rerun()
                                if st.button("ì‚­ì œ", key=f"r_del_t2_{idx}", help="ëª©ë¡ì—ì„œ ì œê±°"):
                                    tier2.pop(idx)
                                    st.rerun()
                    else:
                        st.info("Tier 2 ì—°êµ¬ì ì—†ìŒ")

                else:  # areas
                    areas = parsed.get("target_research_areas", [])
                    if areas:
                        st.markdown("**íƒ€ê²Ÿ ì—°êµ¬ ë¶„ì•¼:**")
                        for a in areas:
                            st.markdown(f"- {a}")
                    else:
                        st.info("ì—°êµ¬ ë¶„ì•¼ ì •ë³´ ì—†ìŒ")

                # â”€â”€ Verification Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if _r_verdict_map:
                    st.divider()
                    st.subheader("ê·¼ê±° êµì°¨ê²€ì¦ ê²°ê³¼")
                    st.caption("ì™¸ë¶€ ë°ì´í„°(ì›¹ + PubMed + ClinicalTrials) ìˆ˜ì§‘ í›„ Claudeê°€ AI ê·¼ê±°ì™€ ë¹„êµ ë¶„ì„")

                    total_v = len(_r_verdict_map)
                    confirmed = sum(1 for v in _r_verdict_map.values() if v.get("verdict") == "confirmed")
                    v_partial = sum(1 for v in _r_verdict_map.values() if v.get("verdict") == "partial")
                    unverified = sum(1 for v in _r_verdict_map.values() if v.get("verdict") == "unverified")
                    wrong = sum(1 for v in _r_verdict_map.values() if v.get("verdict") == "wrong")

                    vcol1, vcol2, vcol3, vcol4 = st.columns(4)
                    vcol1.metric("âœ… í™•ì¸ë¨", confirmed)
                    vcol2.metric("âš ï¸ ì¼ë¶€ í™•ì¸", v_partial)
                    vcol3.metric("â“ ë¯¸ê²€ì¦", unverified)
                    vcol4.metric("âŒ ë¶ˆì¼ì¹˜", wrong)

                # â”€â”€ Export Results as Markdown â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.divider()
                st.subheader("ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")

                def _build_researcher_export_md():
                    lines = [f"# íƒ€ê²Ÿ ì—°êµ¬ì ì¶”ì²œ ê²°ê³¼\n"]
                    lines.append(f"**ì œí’ˆ ìš”ì•½:** {parsed.get('product_summary', '')}\n")
                    _exp_analysis = parsed.get("analysis", "")
                    if _exp_analysis:
                        lines.append(f"## ë¶„ì„\n{_exp_analysis}\n")

                    for tier_label, tier_list in [
                        ("Tier 1 (í•µì‹¬ íƒ€ê²Ÿ)", tier1),
                        ("Tier 2 (ì ì¬ì  íƒ€ê²Ÿ)", tier2),
                    ]:
                        lines.append(f"## {tier_label} â€” {len(tier_list)}ëª…\n")
                        for i, r in enumerate(tier_list, 1):
                            r_name = r.get("name", "")
                            r_inst = r.get("institution", "")
                            r_dept = r.get("department", "")
                            r_title = r.get("title", "")
                            header = f"### {i}. {r_name}"
                            if r_title:
                                header += f" â€” {r_title}"
                            if r_inst:
                                header += f", {r_inst}"
                                if r_dept:
                                    header += f" ({r_dept})"
                            lines.append(header)
                            if r.get("research_area"):
                                lines.append(f"- **ì—°êµ¬ ë¶„ì•¼:** {r['research_area']}")
                            if r.get("key_publications"):
                                lines.append(f"- **ì£¼ìš” ì—°êµ¬:** {r['key_publications']}")
                            if r.get("reason"):
                                lines.append(f"- **ìš”ì•½:** {r['reason']}")
                            if r.get("evidence"):
                                lines.append(f"- **ê·¼ê±°:** {r['evidence']}")
                            if r.get("tier_reason"):
                                lines.append(f"- **Tier ì‚°ì •:** {r['tier_reason']}")
                            if r.get("contact_clues"):
                                lines.append(f"- **ì—°ë½ì²˜ ë‹¨ì„œ:** {r['contact_clues']}")
                            # Add verdict if available
                            _v = _r_verdict_map.get(r_name, {})
                            if _v:
                                _emoji = {"confirmed": "âœ…", "partial": "âš ï¸", "unverified": "â“", "wrong": "âŒ"}.get(_v.get("verdict", ""), "")
                                lines.append(f"- **êµì°¨ê²€ì¦:** {_emoji} {_v.get('verdict', '')} â€” {_v.get('explanation', '')}")
                            lines.append("")

                    _areas = parsed.get("target_research_areas", [])
                    if _areas:
                        lines.append("## íƒ€ê²Ÿ ì—°êµ¬ ë¶„ì•¼\n")
                        for a in _areas:
                            lines.append(f"- {a}")
                        lines.append("")

                    return "\n".join(lines)

                _export_md = _build_researcher_export_md()
                st.download_button(
                    "ğŸ“¥ Markdownìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°",
                    data=_export_md,
                    file_name="target_researchers_result.md",
                    mime="text/markdown",
                    key="export_researcher_md",
                )

                # â”€â”€ Feedback Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.divider()
                st.subheader("í”¼ë“œë°± & ì¬ì¶”ì²œ")
                st.caption("í”¼ë“œë°±ì„ ì…ë ¥í•˜ë©´ ê¸°ì¡´ ê²°ê³¼ + í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì¬ì¶”ì²œí•©ë‹ˆë‹¤. (íƒ€ê²Ÿ í”¼ë“œë°± DB ê³µìœ )")

                _r_feedback_text = st.text_area(
                    "í”¼ë“œë°± ì…ë ¥",
                    placeholder="ì˜ˆ: ì¼ë³¸ ëŒ€í•™ ìœ„ì£¼ë¡œ ì¶”ì²œí•´ì¤˜, CNS ì„ìƒì‹œí—˜ PI ìœ„ì£¼ë¡œ",
                    key="researcher_feedback_text",
                    height=80,
                )

                if st.button("ğŸ”„ í”¼ë“œë°± ë°˜ì˜ ì¬ì¶”ì²œ", type="primary",
                             disabled=not _r_feedback_text or st.session_state.get("agent_running"),
                             key="researcher_re_recommend"):
                    # Build re-recommendation request with feedback
                    full_desc = researcher_product_desc or ""
                    if _r_campaign_ctx:
                        full_desc = f"{_r_campaign_ctx}\n\n{full_desc}"
                    if researcher_areas:
                        full_desc += f"\n\níƒ€ê²Ÿ ì—°êµ¬ ë¶„ì•¼: {researcher_areas}"
                    region_line = f"\nì§€ì—­ ì œí•œ: {researcher_region}" if researcher_region else ""

                    prev_result = st.session_state.ai_researcher_result
                    agent_request = (
                        f"ì•„ë˜ ì œí’ˆì— ì í•©í•œ í•™ìˆ  ì—°êµ¬ì/êµìˆ˜ë¥¼ ì°¾ì•„ì¤˜.\n\n"
                        f"## ì œí’ˆ ì„¤ëª…\n{full_desc}{region_line}\n\n"
                        f"## ì´ì „ ì¶”ì²œ ê²°ê³¼\n{prev_result}\n\n"
                        f"## ì‚¬ìš©ì í”¼ë“œë°± (ë°˜ë“œì‹œ ë°˜ì˜)\n{_r_feedback_text}\n\n"
                        f"ìœ„ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ê²°ê³¼ë¥¼ ìˆ˜ì •í•´ì¤˜."
                    )

                    # Save feedback to DB
                    db.add_target_feedback(
                        _r_feedback_text,
                        product_summary="ì—°êµ¬ì ì¶”ì²œ í”¼ë“œë°±",
                        profile_id=_run_profile_id,
                    )

                    st.session_state._pending_researcher_agent = {
                        "request": agent_request,
                        "feedback": db.get_combined_feedback_text(_run_profile_id),
                    }
                    st.session_state.agent_running = True
                    st.rerun()

                # â”€â”€ Save as Preset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.divider()
                st.subheader("í”„ë¦¬ì…‹ìœ¼ë¡œ ì €ì¥")
                st.caption("ì¶”ì²œ ê²°ê³¼ë¥¼ í”„ë¦¬ì…‹ìœ¼ë¡œ ì €ì¥í•˜ë©´ 'ì»¨íƒ ì„œì¹­' í˜ì´ì§€ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                rec = parsed.get("recommended_search_params", {})
                tier1_names = [f"{r['name']} ({r.get('institution', '')})" for r in tier1]
                tier2_names = [f"{r['name']} ({r.get('institution', '')})" for r in tier2]
                all_institutions = list(set(
                    r.get("institution", "") for r in tier1 + tier2 if r.get("institution")
                ))
                all_areas = parsed.get("target_research_areas", [])

                save_scope = st.radio(
                    "ì €ì¥í•  ë²”ìœ„",
                    ["Tier 1 + Tier 2 ì „ì²´", "Tier 1ë§Œ", "Tier 2ë§Œ", "Tier 1 / Tier 2 ê°ê° (2ê°œ í”„ë¦¬ì…‹)"],
                    horizontal=True,
                    key="researcher_save_scope",
                )

                if save_scope == "Tier 1 / Tier 2 ê°ê° (2ê°œ í”„ë¦¬ì…‹)":
                    _save_groups = [("_T1", tier1_names), ("_T2", tier2_names)]
                elif save_scope == "Tier 2ë§Œ":
                    _save_groups = [("", tier2_names)]
                elif save_scope == "Tier 1ë§Œ":
                    _save_groups = [("", tier1_names)]
                else:
                    _save_groups = [("", tier1_names + tier2_names)]

                # Preview
                with st.expander("ì €ì¥ë  í”„ë¦¬ì…‹ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    st.markdown(f"**ì—°êµ¬ ë¶„ì•¼:** {', '.join(all_areas)}")
                    st.markdown(f"**ê¸°ê´€:** {', '.join(all_institutions[:10])}")
                    st.markdown(f"**ê²€ìƒ‰ í‚¤ì›Œë“œ:** {rec.get('research_keywords', '')}")

                if save_scope == "Tier 1 / Tier 2 ê°ê° (2ê°œ í”„ë¦¬ì…‹)":
                    _nc1, _nc2 = st.columns(2)
                    with _nc1:
                        r_preset_name_t1 = st.text_input(
                            "Tier 1 í”„ë¦¬ì…‹ ì´ë¦„",
                            value=f"ì—°êµ¬ì_{datetime.now().strftime('%y%m%d')}_T1",
                            key="r_preset_name_t1",
                        )
                    with _nc2:
                        r_preset_name_t2 = st.text_input(
                            "Tier 2 í”„ë¦¬ì…‹ ì´ë¦„",
                            value=f"ì—°êµ¬ì_{datetime.now().strftime('%y%m%d')}_T2",
                            key="r_preset_name_t2",
                        )
                    _save_groups = [(r_preset_name_t1, tier1_names), (r_preset_name_t2, tier2_names)]
                    _r_can_save = bool(r_preset_name_t1 and r_preset_name_t2)
                else:
                    r_preset_name = st.text_input(
                        "í”„ë¦¬ì…‹ ì´ë¦„",
                        value=f"ì—°êµ¬ì_{datetime.now().strftime('%y%m%d')}",
                        key="r_preset_name",
                    )
                    _save_groups = [(r_preset_name, c) for _, c in _save_groups]
                    _r_can_save = bool(r_preset_name)

                if st.button("ğŸ’¾ í”„ë¦¬ì…‹ ì €ì¥ â†’ ì»¨íƒ ì„œì¹­", type="primary",
                             disabled=not _r_can_save, key="save_researcher_preset"):
                    for _name, _researchers in _save_groups:
                        if not _researchers:
                            continue
                        db.save_preset(
                            name=_name,
                            industry=", ".join(all_areas),
                            titles="Professor, Associate Professor, PI, Lab Director",
                            locations=researcher_region or "",
                            companies=", ".join(_researchers),
                            keywords=rec.get("research_keywords", ""),
                            max_results=100,
                            feedback_hash=_get_feedback_hash(),
                            product_description=researcher_product_desc or "",
                            target_hint=researcher_areas or "",
                            target_region=researcher_region or "",
                            preset_type="researcher",
                            institutions=", ".join(all_institutions),
                            research_areas=", ".join(all_areas),
                        )
                    _saved = ", ".join(f"'{n}'" for n, r in _save_groups if r)
                    st.session_state.ai_researcher_result = None
                    st.session_state.ai_researcher_parsed = None
                    st.session_state.ai_researcher_verification = None
                    st.session_state.ai_researcher_verdicts = {}
                    st.session_state.active_page = "ğŸ” ì»¨íƒ ì„œì¹­"
                    st.session_state.contact_search_mode = "manual"
                    st.session_state.prospect_step = "search"
                    st.success(f"í”„ë¦¬ì…‹ {_saved} ì €ì¥ ì™„ë£Œ! ì»¨íƒ ì„œì¹­ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                    st.rerun()

            else:
                # JSON parsing failed â€” show raw result
                st.warning("AI ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸:")
                st.text(st.session_state.ai_researcher_result[:3000])

            # â”€â”€ Reset button â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            st.divider()
            if st.button("ğŸ—‘ï¸ ê²°ê³¼ ì´ˆê¸°í™”", key="reset_researcher"):
                st.session_state.ai_researcher_result = None
                st.session_state.ai_researcher_parsed = None
                st.session_state.ai_researcher_verification = None
                st.session_state.ai_researcher_verdicts = {}
                st.rerun()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PAGE 1: Contact Search (ì»¨íƒ ì„œì¹­)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

elif page == "ğŸ” ì»¨íƒ ì„œì¹­":
    st.title("ì»¨íƒ ì„œì¹­")

    # â”€â”€ Mode selector â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "contact_search_mode" not in st.session_state:
        st.session_state.contact_search_mode = "agent"
    if "agent2_log" not in st.session_state:
        st.session_state.agent2_log = []
    if "agent2_result" not in st.session_state:
        st.session_state.agent2_result = None
    if "agent2_credits" not in st.session_state:
        st.session_state.agent2_credits = None
    if "agent2_search_id" not in st.session_state:
        st.session_state.agent2_search_id = None
    if "prospect_step" not in st.session_state:
        st.session_state.prospect_step = "search"
    if "prospect_search_id" not in st.session_state:
        st.session_state.prospect_search_id = None

    search_mode = st.radio(
        "ê²€ìƒ‰ ëª¨ë“œ",
        ["ğŸ¤– Agent ëª¨ë“œ (ìë™)", "ğŸ”§ ìˆ˜ë™ ëª¨ë“œ (6ë‹¨ê³„)"],
        horizontal=True,
        index=0 if st.session_state.contact_search_mode == "agent" else 1,
    )
    st.session_state.contact_search_mode = "agent" if "Agent" in search_mode else "manual"
    st.divider()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # AGENT MODE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if st.session_state.contact_search_mode == "agent":
        st.caption("AI Agentê°€ Findymail, Hunter.io, WHOIS, ì›¹ ê²€ìƒ‰ì„ ìë™ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ ì´ë©”ì¼ì„ ì°¾ìŠµë‹ˆë‹¤.")

        # â”€â”€ Input section with tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.subheader("íƒ€ê²Ÿ ì •ë³´ ì…ë ¥")
        input_tab1, input_tab2, input_tab3 = st.tabs(["âœï¸ ì§ì ‘ ì…ë ¥", "ğŸ¯ Agent 1 ê²°ê³¼ì—ì„œ", "ğŸ“‹ ì €ì¥ëœ í”„ë¦¬ì…‹ì—ì„œ"])

        agent2_request = ""

        with input_tab1:
            a2_companies = st.text_area(
                "íšŒì‚¬ ëª©ë¡ (ì¤„ë°”ê¿ˆ êµ¬ë¶„)",
                placeholder="Eisai\nShionogi\nDaiichi Sankyo",
                height=120,
                key="a2_companies_input",
            )
            a2c1, a2c2 = st.columns(2)
            with a2c1:
                a2_titles = st.text_input(
                    "íƒ€ê²Ÿ ì§í•¨ (ì½¤ë§ˆ êµ¬ë¶„)",
                    placeholder="VP BD, Director Licensing, Head of Research",
                    key="a2_titles_input",
                )
            with a2c2:
                a2_region = st.text_input(
                    "ì§€ì—­ (ì„ íƒ)",
                    placeholder="Japan, US, etc.",
                    key="a2_region_input",
                )

            if a2_companies.strip():
                companies = [c.strip() for c in a2_companies.strip().split("\n") if c.strip()]
                parts = [f"ë‹¤ìŒ {len(companies)}ê°œ íšŒì‚¬ì—ì„œ ì´ë©”ì¼ì„ ì°¾ì•„ì¤˜ (ì „ë¶€ ë¹ ì§ì—†ì´ ì²˜ë¦¬í•  ê²ƒ): {', '.join(companies)}"]
                if a2_titles.strip():
                    parts.append(f"íƒ€ê²Ÿ ì§í•¨: {a2_titles}")
                if a2_region.strip():
                    parts.append(f"ì§€ì—­: {a2_region}")
                agent2_request = "\n".join(parts)

        with input_tab2:
            if st.session_state.get("ai_target_parsed"):
                parsed = st.session_state.ai_target_parsed
                tier1 = parsed.get("tier1_companies", [])
                tier2 = parsed.get("tier2_companies", [])
                dm_titles = parsed.get("decision_makers", [])

                st.success(f"Agent 1 ê²°ê³¼: Tier 1 {len(tier1)}ê°œ, Tier 2 {len(tier2)}ê°œ íšŒì‚¬")

                use_tier1 = st.checkbox(f"Tier 1 ì‚¬ìš© ({len(tier1)}ê°œ)", value=True, key="a2_use_tier1")
                use_tier2 = st.checkbox(f"Tier 2 ì‚¬ìš© ({len(tier2)}ê°œ)", value=False, key="a2_use_tier2")

                if dm_titles:
                    st.caption(f"ì¶”ì²œ ì§í•¨: {', '.join(dm_titles[:8])}")

                selected_companies = []
                if use_tier1:
                    selected_companies.extend([c["name"] for c in tier1])
                if use_tier2:
                    selected_companies.extend([c["name"] for c in tier2])

                if selected_companies:
                    tier_label = []
                    if use_tier1:
                        tier_label.append(f"Tier 1 {len(tier1)}ê°œ")
                    if use_tier2:
                        tier_label.append(f"Tier 2 {len(tier2)}ê°œ")
                    parts = [
                        f"ë‹¤ìŒ {len(selected_companies)}ê°œ íšŒì‚¬ì—ì„œ ì´ë©”ì¼ì„ ì°¾ì•„ì¤˜ ({', '.join(tier_label)}, ì „ë¶€ ë¹ ì§ì—†ì´ ì²˜ë¦¬í•  ê²ƒ):",
                        ", ".join(selected_companies),
                    ]
                    if dm_titles:
                        parts.append(f"íƒ€ê²Ÿ ì§í•¨: {', '.join(dm_titles[:5])}")
                    agent2_request = "\n".join(parts)
            else:
                st.info("Agent 1 (íƒ€ê²Ÿ ë°œêµ´) ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íƒ€ê²Ÿ ë°œêµ´ì„ ì‹¤í–‰í•˜ê±°ë‚˜ 'ì§ì ‘ ì…ë ¥' íƒ­ì„ ì‚¬ìš©í•˜ì„¸ìš”.")

        with input_tab3:
            saved_presets = db.get_presets()
            if saved_presets:
                current_fb_hash = _get_feedback_hash()
                _ptype_icon = lambda sp: "ğŸ“" if sp.get("preset_type") == "researcher" else "ğŸ¢"
                preset_names = [f"{_ptype_icon(sp)} {sp['name']}" for sp in saved_presets]
                selected_preset_label = st.selectbox(
                    "í”„ë¦¬ì…‹ ì„ íƒ", preset_names, key="a2_preset_select"
                )
                _sel_idx = preset_names.index(selected_preset_label)
                sel = saved_presets[_sel_idx]

                # Warn if feedback changed since preset was saved
                if sel.get("feedback_hash") and sel["feedback_hash"] != current_fb_hash:
                    st.warning(
                        "ì´ í”„ë¦¬ì…‹ ì €ì¥ ì´í›„ í”¼ë“œë°±ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. "
                        "'ğŸ¯ íƒ€ê²Ÿ ë°œêµ´'ì—ì„œ ë‹¤ì‹œ ì¶”ì²œë°›ì•„ í”„ë¦¬ì…‹ì„ ê°±ì‹ í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                    )

                # Show preset summary
                _is_researcher_preset = sel.get("preset_type") == "researcher"
                info_parts = []
                if sel.get("companies"):
                    _label = "ì—°êµ¬ì" if _is_researcher_preset else "íšŒì‚¬"
                    info_parts.append(f"**{_label}**: {sel['companies']}")
                if sel.get("industry"):
                    _label = "ì—°êµ¬ ë¶„ì•¼" if _is_researcher_preset else "ì‚°ì—…"
                    info_parts.append(f"**{_label}**: {sel['industry']}")
                if sel.get("institutions") and _is_researcher_preset:
                    info_parts.append(f"**ê¸°ê´€**: {sel['institutions']}")
                if sel.get("titles"):
                    info_parts.append(f"**ì§í•¨**: {sel['titles']}")
                if sel.get("locations"):
                    info_parts.append(f"**ì§€ì—­**: {sel['locations']}")
                if sel.get("keywords"):
                    info_parts.append(f"**í‚¤ì›Œë“œ**: {sel['keywords']}")
                if info_parts:
                    st.markdown(" | ".join(info_parts))

                # Build agent request from preset
                companies_str = sel.get("companies") or ""
                if companies_str.strip():
                    companies_list = [c.strip() for c in companies_str.split(",") if c.strip()]
                    if _is_researcher_preset:
                        parts = [f"ë‹¤ìŒ {len(companies_list)}ëª…ì˜ ì—°êµ¬ì ì´ë©”ì¼ì„ ì°¾ì•„ì¤˜ (ì „ë¶€ ë¹ ì§ì—†ì´ ì²˜ë¦¬í•  ê²ƒ): {', '.join(companies_list)}"]
                    else:
                        parts = [f"ë‹¤ìŒ {len(companies_list)}ê°œ íšŒì‚¬ì—ì„œ ì´ë©”ì¼ì„ ì°¾ì•„ì¤˜ (ì „ë¶€ ë¹ ì§ì—†ì´ ì²˜ë¦¬í•  ê²ƒ): {', '.join(companies_list)}"]
                    if sel.get("titles"):
                        parts.append(f"íƒ€ê²Ÿ ì§í•¨: {sel['titles']}")
                    if sel.get("locations"):
                        parts.append(f"ì§€ì—­: {sel['locations']}")
                    if sel.get("keywords"):
                        parts.append(f"í‚¤ì›Œë“œ: {sel['keywords']}")
                    if sel.get("industry"):
                        _label = "ì—°êµ¬ ë¶„ì•¼" if _is_researcher_preset else "ì‚°ì—…"
                        parts.append(f"{_label}: {sel['industry']}")
                    if _is_researcher_preset:
                        if sel.get("institutions"):
                            parts.append(f"ì°¸ê³  ê¸°ê´€: {sel['institutions']}")
                        parts.append("ì´ ì‚¬ëŒë“¤ì€ í•™ìˆ  ì—°êµ¬ìì…ë‹ˆë‹¤. ëŒ€í•™/ì—°êµ¬ê¸°ê´€ ë„ë©”ì¸ì—ì„œ ì´ë©”ì¼ì„ ì°¾ì•„ì£¼ì„¸ìš”.")
                    agent2_request = "\n".join(parts)
                else:
                    st.warning("ì´ í”„ë¦¬ì…‹ì— ëŒ€ìƒ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ëŒ€ìƒì´ í¬í•¨ëœ í”„ë¦¬ì…‹ì„ ì„ íƒí•˜ê±°ë‚˜ 'ì§ì ‘ ì…ë ¥' íƒ­ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            else:
                st.info("ì €ì¥ëœ í”„ë¦¬ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. 'ğŸ¯ íƒ€ê²Ÿ ë°œêµ´' í˜ì´ì§€ì—ì„œ AI ì¶”ì²œ â†’ í”„ë¦¬ì…‹ ì €ì¥ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”.")

        # â”€â”€ Run Agent button â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        if st.button("ğŸ¤– ì´ë©”ì¼ ì°¾ê¸° Agent ì‹¤í–‰", type="primary", disabled=not agent2_request or st.session_state.get("agent_running")):
            # Phase 1: save params and rerun to show overlay
            st.session_state._pending_agent2 = {"request": agent2_request}
            st.session_state.agent_running = True
            st.rerun()

        # Phase 2: execute pending Agent 2 task (overlay already visible)
        if st.session_state.get("_pending_agent2"):
            _task = st.session_state.pop("_pending_agent2")
            try:
                from agent import EmailFinderAgent

                _a2_request = _task["request"]
                # Count companies from request
                _a2_lines = _a2_request.split("\n")
                _a2_company_count = 1
                for _line in _a2_lines:
                    _commas = _line.count(",")
                    if _commas >= 2:
                        _a2_company_count = max(_a2_company_count, _commas + 1)
                _a2_company_count = max(_a2_company_count, 1)

                tracker = AgentProgressTracker("agent2", total_items=_a2_company_count)

                agent = EmailFinderAgent(
                    num_companies=_a2_company_count,
                    on_tool_call=tracker.on_tool_call,
                    on_tool_result=tracker.on_tool_result,
                    on_text=tracker.on_text,
                )

                agent_output = agent.run(_a2_request)

                # Finalize: mark DB search as completed
                if agent._search_id and agent._accumulated_contacts:
                    import db as _db
                    _db.update_prospect_search(
                        agent._search_id,
                        status="completed",
                        total_found=len(agent._accumulated_contacts),
                        completed_at=time.strftime("%Y-%m-%dT%H:%M:%S"),
                    )

                st.session_state.agent2_log = tracker.tool_log
                st.session_state.agent2_credits = agent.credits_used
                st.session_state.agent2_search_id = agent._search_id

                if agent.result_json:
                    try:
                        result = json.loads(agent.result_json)
                        st.session_state.agent2_result = result
                        tracker.complete(f"{len(result.get('contacts', []))}ëª… ì—°ë½ì²˜ ë°œê²¬")
                    except json.JSONDecodeError:
                        st.session_state.agent2_result = None
                        tracker.fail("Agent ê²°ê³¼ JSON íŒŒì‹± ì‹¤íŒ¨")
                else:
                    tracker.complete("ì´ë©”ì¼ ê²€ìƒ‰ ì™„ë£Œ")
            except Exception as e:
                st.error(f"ì´ë©”ì¼ ì°¾ê¸° ì‹¤íŒ¨: {e}")
                import traceback
                st.code(traceback.format_exc())
            finally:
                st.session_state.agent_running = False
            st.rerun()

        # â”€â”€ Display results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.session_state.agent2_result:
            result = st.session_state.agent2_result
            contacts_raw = result.get("contacts", [])
            summary = result.get("search_summary", {})

            # Deduplicate by (email, company) â€” matches DB UNIQUE constraint
            seen = set()
            contacts = []
            for c in contacts_raw:
                email = (c.get("email") or "").strip().lower()
                company = (c.get("company") or "").strip().lower()
                name = (c.get("contact_name") or "").strip().lower()
                key = (email, company) if email else (name, company)
                if key not in seen:
                    seen.add(key)
                    contacts.append(c)

            dupes_removed = len(contacts_raw) - len(contacts)
            msg = f"âœ… {len(contacts)}ëª…ì˜ ì—°ë½ì²˜ ë°œê²¬"
            if dupes_removed > 0:
                msg += f" (ì¤‘ë³µ {dupes_removed}ê±´ ì œê±°)"
            st.success(msg)

            # Metrics
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("ì´ ì—°ë½ì²˜", len(contacts))
            m2.metric("ì´ë©”ì¼ í™•ë³´", sum(1 for c in contacts if c.get("email")))
            m3.metric("íšŒì‚¬ ìˆ˜", len(set(c.get("company", "") for c in contacts if c.get("company"))))
            credits = st.session_state.agent2_credits or {}
            m4.metric("í¬ë ˆë”§ ì‚¬ìš©", f"F:{credits.get('findymail', 0)} H:{credits.get('hunter', 0)}")

            # Contacts table
            if contacts:
                import pandas as pd
                df = pd.DataFrame(contacts)
                display_cols = [c for c in ["contact_name", "email", "email_confidence", "company", "title", "source", "location"] if c in df.columns]
                st.dataframe(df[display_cols], use_container_width=True, height=400)

                # Export
                st.divider()
                exp1, exp2 = st.columns(2)
                with exp1:
                    csv_data = df[display_cols].to_csv(index=False)
                    st.download_button(
                        "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                        csv_data,
                        f"contacts_{time.strftime('%y%m%d')}.csv",
                        "text/csv",
                    )
                with exp2:
                    if st.button("ğŸ“§ ì½œë“œë©”ì¼ ìº í˜ì¸ìœ¼ë¡œ ë³´ë‚´ê¸°"):
                        st.session_state.csv_data = csv_data
                        st.session_state.a3_from_agent2 = st.session_state.get("agent2_search_id")
                        st.session_state.active_page = "ğŸ“ ì½œë“œë©”ì¼"
                        st.rerun()

        # Agent activity log (full)
        if st.session_state.agent2_log:
            full_log = "\n".join(st.session_state.agent2_log)
            with st.expander(f"Agent í™œë™ ë¡œê·¸ ({len(st.session_state.agent2_log)}ê±´)", expanded=False):
                st.code(full_log, language=None)
                st.download_button(
                    "ğŸ“¥ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
                    full_log,
                    f"agent2_log_{time.strftime('%y%m%d_%H%M')}.txt",
                    "text/plain",
                    key="a2_log_download",
                )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MANUAL MODE (existing 6-step pipeline)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    else:
        st.caption("Findymail + Hunter.ioë¡œ ì ì¬ ê³ ê°ì˜ ì´ë©”ì¼ì„ ì°¾ê³ , AIë¡œ ì í•©ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.")

        # â”€â”€ Step indicator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        p_steps = ["â‘  ê²€ìƒ‰", "â‘¡ ê²°ê³¼", "â‘¢ ì´ë©”ì¼", "â‘£ ë¦¬ì„œì¹˜", "â‘¤ AI í‰ê°€", "â‘¥ ë‚´ë³´ë‚´ê¸°"]
        p_step_map = {"search": 0, "results": 1, "hunter": 2, "research": 3, "enrich": 4, "export": 5}
        p_current = p_step_map.get(st.session_state.prospect_step, 0)

        pcols = st.columns(6)
        for i, (col, label) in enumerate(zip(pcols, p_steps)):
            if i < p_current:
                col.success(label)
            elif i == p_current:
                col.info(label)
            else:
                col.markdown(f"<span style='color:gray'>{label}</span>", unsafe_allow_html=True)
        st.divider()

    # â”€â”€ Manual mode step logic (skipped in Agent mode) â”€â”€
    if st.session_state.contact_search_mode != "manual":
        pass  # Agent mode UI handled above

    elif st.session_state.prospect_step == "search":
        st.subheader("â‘  ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •")

        # Load saved presets from DB
        saved_presets = db.get_presets()
        SAVED_PRESETS = {}
        for sp in saved_presets:
            _icon = "ğŸ“" if sp.get("preset_type") == "researcher" else "ğŸ¢"
            _display_name = f"{_icon} {sp['name']}"
            SAVED_PRESETS[_display_name] = {
                "id": sp["id"],
                "industry": sp.get("industry") or "",
                "titles": sp.get("titles") or "",
                "locations": sp.get("locations") or "",
                "companies": sp.get("companies") or "",
                "keywords": sp.get("keywords") or "",
                "max_results": sp.get("max_results") or 100,
            }

        ALL_PRESETS = {"ì§ì ‘ ì„¤ì •": {}}
        ALL_PRESETS.update(SAVED_PRESETS)

        if not SAVED_PRESETS:
            st.info("í”„ë¦¬ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. 'ğŸ¯ íƒ€ê²Ÿ ë°œêµ´' í˜ì´ì§€ì—ì„œ AI ì¶”ì²œ â†’ í”„ë¦¬ì…‹ ì €ì¥ì„ ë¨¼ì € í•´ë³´ì„¸ìš”.")

        preset_col, save_col = st.columns([3, 1])
        with preset_col:
            preset = st.selectbox("í”„ë¦¬ì…‹", list(ALL_PRESETS.keys()))
        preset_vals = ALL_PRESETS.get(preset, {})

        # Delete button for saved presets
        with save_col:
            st.markdown("<br>", unsafe_allow_html=True)
            if preset in SAVED_PRESETS:
                if st.button("ğŸ—‘ï¸ ì‚­ì œ", key="delete_preset"):
                    db.delete_preset(SAVED_PRESETS[preset]["id"])
                    st.rerun()

        col1, col2 = st.columns(2)
        with col1:
            p_industry = st.text_input(
                "ì‚°ì—… (Industry)",
                value=preset_vals.get("industry", ""),
                placeholder="pharmaceutical, biotech, IT, etc.",
            )
            p_titles = st.text_input(
                "ì§í•¨ í‚¤ì›Œë“œ (ì½¤ë§ˆ êµ¬ë¶„)",
                value=preset_vals.get("titles", ""),
                placeholder="Director, VP, Head, Manager",
            )
            p_keywords = st.text_input(
                "ììœ  ê²€ìƒ‰ì–´",
                value=preset_vals.get("keywords", ""),
                placeholder="CNS, neuroscience, BD, licensing",
            )

        with col2:
            p_locations = st.text_input(
                "ì§€ì—­ (ì½¤ë§ˆ êµ¬ë¶„)",
                value=preset_vals.get("locations", ""),
                placeholder="Japan, Tokyo, US, etc.",
            )
            p_companies = st.text_input(
                "íŠ¹ì • íšŒì‚¬ (ì½¤ë§ˆ êµ¬ë¶„, ì„ íƒ)",
                value=preset_vals.get("companies", ""),
                placeholder="Shionogi, Eisai, Daiichi Sankyo",
            )
            p_keyword_filter = st.checkbox(
                "íšŒì‚¬ ì§€ì • ì‹œì—ë„ í‚¤ì›Œë“œ í•„í„° ì ìš©",
                value=False,
                help="íšŒì‚¬ë¥¼ ì§ì ‘ ì§€ì •í•˜ë©´ ì´ë¯¸ ê´€ë ¨ íšŒì‚¬ë§Œ ê²€ìƒ‰í•©ë‹ˆë‹¤. "
                     "í‚¤ì›Œë“œ í•„í„°ê¹Œì§€ ì ìš©í•˜ë©´ ì§í•¨ì— í‚¤ì›Œë“œê°€ ì—†ëŠ” ì‚¬ëŒì´ ì œì™¸ë˜ì–´ ê²°ê³¼ê°€ ë§¤ìš° ì ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            )
            p_max_results = st.slider(
                "ìµœëŒ€ ê²€ìƒ‰ ìˆ˜", 10, 500,
                value=preset_vals.get("max_results", 100),
                step=10,
            )

        # Save preset
        save_col1, save_col2 = st.columns([3, 1])
        with save_col1:
            new_preset_name = st.text_input(
                "í”„ë¦¬ì…‹ ì €ì¥",
                placeholder="í”„ë¦¬ì…‹ ì´ë¦„ì„ ì…ë ¥í•˜ë©´ í˜„ì¬ ì„¤ì •ì´ ì €ì¥ë©ë‹ˆë‹¤",
                label_visibility="collapsed",
            )
        with save_col2:
            if st.button("ğŸ’¾ í”„ë¦¬ì…‹ ì €ì¥", disabled=not new_preset_name):
                db.save_preset(
                    name=new_preset_name,
                    industry=p_industry,
                    titles=p_titles,
                    locations=p_locations,
                    companies=p_companies,
                    keywords=p_keywords,
                    max_results=p_max_results,
                    feedback_hash=_get_feedback_hash(),
                )
                st.success(f"í”„ë¦¬ì…‹ '{new_preset_name}' ì €ì¥ ì™„ë£Œ!")
                st.rerun()

        st.divider()

        p_search_name = st.text_input(
            "ê²€ìƒ‰ ì´ë¦„",
            value=f"Search_{datetime.now().strftime('%y%m%d')}",
        )

        # API key check
        if not FINDYMAIL_API_KEY:
            st.error("Findymail API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .envì— FINDYMAIL_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")

        # Search button
        if st.button("ğŸ” ì´ë©”ì¼ ê²€ìƒ‰ ì‹œì‘", type="primary", disabled=not FINDYMAIL_API_KEY):
            from findymail_client import FindymailClient

            titles_list = [t.strip() for t in p_titles.split(",") if t.strip()] if p_titles else None
            companies_list = [c.strip() for c in p_companies.split(",") if c.strip()] if p_companies else None

            search_params_json = json.dumps({
                "industry": p_industry or None,
                "titles": titles_list,
                "companies": companies_list,
            }, ensure_ascii=False)

            search_id = db.create_prospect_search(
                name=p_search_name,
                search_params=search_params_json,
                source="findymail",
            )
            db.update_prospect_search(search_id, status="searching")
            st.session_state.prospect_search_id = search_id

            fm = FindymailClient()
            total_found = 0

            try:
                if not companies_list:
                    st.error("íšŒì‚¬ë¥¼ ìµœì†Œ 1ê°œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    st.stop()

                # Build prospect list for Findymail batch search
                prospects_to_search = []
                for company in companies_list:
                    # Infer domain from known domains or company name
                    from hunter_client import _KNOWN_DOMAINS
                    domain = ""
                    for key, dom in _KNOWN_DOMAINS.items():
                        if key in company.lower():
                            domain = dom
                            break
                    if not domain:
                        # Try company name as domain
                        domain = company.lower().replace(" ", "") + ".com"

                    if titles_list:
                        for title in titles_list:
                            prospects_to_search.append({
                                "company": company,
                                "domain": domain,
                                "title_keyword": title,
                            })
                    else:
                        prospects_to_search.append({
                            "company": company,
                            "domain": domain,
                        })

                progress = st.progress(0, text="Findymailë¡œ ì´ë©”ì¼ ê²€ìƒ‰ ì¤‘...")
                total = len(prospects_to_search)

                for i, prospect in enumerate(prospects_to_search):
                    company = prospect["company"]
                    domain = prospect["domain"]
                    pct = min((i + 1) / max(total, 1), 0.95)
                    progress.progress(pct, text=f"ê²€ìƒ‰ ì¤‘: {company} ({i+1}/{total})")

                    try:
                        # Use Hunter domain search to find people at this company
                        if HUNTER_API_KEY:
                            from hunter_client import HunterClient
                            hunter = HunterClient()
                            domain_result = hunter.search_domain(domain, limit=5)
                            emails_data = domain_result.get("data", {}).get("emails", [])

                            for person in emails_data:
                                email = person.get("value", "")
                                name = f"{person.get('first_name', '')} {person.get('last_name', '')}".strip()
                                title = person.get("position", "")

                                if email and name:
                                    # Verify with Findymail for higher accuracy
                                    try:
                                        fm_result = fm.find_email(name, domain)
                                        verified_email = fm_result.get("email", email)
                                        is_verified = fm_result.get("verified", False)
                                    except Exception:
                                        verified_email = email
                                        is_verified = False

                                    db.add_prospect(
                                        search_id=search_id,
                                        contact_name=name,
                                        email=verified_email,
                                        company=company,
                                        title=title,
                                        email_confidence="verified" if is_verified else "high",
                                        source="findymail+hunter",
                                        source_data=json.dumps(person, ensure_ascii=False),
                                    )
                                    total_found += 1

                    except Exception as e:
                        logger.warning(f"Search failed for {company}: {e}")

                    db.update_prospect_search(search_id, total_found=total_found)

                progress.progress(1.0, text=f"ì™„ë£Œ! {total_found}ëª… ë°œê²¬")
                db.update_prospect_search(search_id, status="completed",
                                          completed_at=datetime.now().isoformat())
                st.session_state.prospect_step = "results"
                st.rerun()

            except Exception as e:
                db.update_prospect_search(search_id, status="completed",
                                          total_found=total_found,
                                          completed_at=datetime.now().isoformat())
                if total_found > 0:
                    st.warning(f"ê²€ìƒ‰ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. {total_found}ëª… ì €ì¥ë¨. ì´ì „ ê²€ìƒ‰ ê¸°ë¡ì—ì„œ ì—´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                logger.error(f"Findymail prospect search failed: {e}")

        # Previous searches
        st.divider()
        st.subheader("ì´ì „ ê²€ìƒ‰ ê¸°ë¡")
        # Session state for delete confirmation
        if "confirm_delete_search" not in st.session_state:
            st.session_state.confirm_delete_search = None

        prev_searches = db.get_prospect_searches()
        if prev_searches:
            for s in prev_searches[:10]:
                sid = s["id"]
                is_confirming = st.session_state.confirm_delete_search == sid

                if is_confirming:
                    # Confirmation row
                    st.warning(f"**{s['name']}** ({s['total_found']}ëª…) ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                    ccol1, ccol2 = st.columns(2)
                    if ccol1.button("ì‚­ì œ í™•ì¸", key=f"confirm_del_{sid}", type="primary"):
                        db.delete_prospect_search(sid)
                        st.session_state.confirm_delete_search = None
                        st.rerun()
                    if ccol2.button("ì·¨ì†Œ", key=f"cancel_del_{sid}"):
                        st.session_state.confirm_delete_search = None
                        st.rerun()
                else:
                    scol1, scol2, scol3, scol4 = st.columns([3, 1, 1, 1])
                    scol1.write(f"**{s['name']}** ({(s.get('created_at') or '')[:16]})")
                    scol2.write(f"{s['total_found']}ëª…")
                    if scol3.button("ì—´ê¸°", key=f"open_search_{sid}"):
                        st.session_state.prospect_search_id = sid
                        st.session_state.prospect_step = "results"
                        st.rerun()
                    if scol4.button("ğŸ—‘ï¸", key=f"del_search_{sid}"):
                        st.session_state.confirm_delete_search = sid
                        st.rerun()
        else:
            st.info("ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    # â”€â”€ STEP 2: Search Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif st.session_state.prospect_step == "results":
        st.subheader("â‘¡ ê²€ìƒ‰ ê²°ê³¼")
        search_id = st.session_state.prospect_search_id

        if not search_id:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            search_info = db.get_prospect_search(search_id)
            prospects = db.get_prospects(search_id=search_id)

            if search_info:
                st.caption(f"ê²€ìƒ‰: {search_info['name']} | ì´ {len(prospects)}ëª… ë°œê²¬")

            if prospects:
                import pandas as pd

                email_count = sum(1 for p in prospects if p.get("email"))
                no_email_count = len(prospects) - email_count
                m1, m2, m3 = st.columns(3)
                m1.metric("ì´ ì¸ì›", len(prospects))
                m2.metric("ì´ë©”ì¼ ìˆìŒ", email_count)
                m3.metric("ì´ë©”ì¼ ì—†ìŒ", no_email_count)

                df = pd.DataFrame(prospects)
                display_cols = ["contact_name", "company", "title", "email", "linkedin_url", "location"]
                display_cols = [c for c in display_cols if c in df.columns]
                st.dataframe(df[display_cols], width="stretch", hide_index=True)
            else:
                st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ì¡°ê±´ì„ ì¡°ì •í•´ë³´ì„¸ìš”.")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("â¬… ê²€ìƒ‰ ì¡°ê±´ìœ¼ë¡œ"):
                st.session_state.prospect_step = "search"
                st.rerun()
        with col2:
            if st.button("â¡ ì´ë©”ì¼ ì°¾ê¸°", type="primary", disabled=not prospects if search_id else True):
                st.session_state.prospect_step = "hunter"
                st.rerun()

    # â”€â”€ STEP 3: Hunter.io Email Lookup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif st.session_state.prospect_step == "hunter":
        st.subheader("â‘¢ ì´ë©”ì¼ ì°¾ê¸° (Hunter.io)")
        search_id = st.session_state.prospect_search_id
        prospects = db.get_prospects(search_id=search_id) if search_id else []

        has_email = sum(1 for p in prospects if p.get("email"))
        missing_email = len(prospects) - has_email
        m1, m2 = st.columns(2)
        m1.metric("ì´ë©”ì¼ ìˆìŒ", has_email)
        m2.metric("ì´ë©”ì¼ ì—†ìŒ", missing_email)

        if not HUNTER_API_KEY:
            st.warning("Hunter.io API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .envì— HUNTER_API_KEYë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì´ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("â¬… ê²€ìƒ‰ ê²°ê³¼ë¡œ"):
                st.session_state.prospect_step = "results"
                st.rerun()
        with col2:
            if st.button("ğŸ” Hunter.io ì´ë©”ì¼ ì°¾ê¸°", type="primary",
                         disabled=not HUNTER_API_KEY or missing_email == 0):
                with st.spinner(f"Hunter.ioì—ì„œ {missing_email}ëª…ì˜ ì´ë©”ì¼ ê²€ìƒ‰ ì¤‘..."):
                    try:
                        from hunter_client import HunterClient
                        hunter = HunterClient()
                        missing_prospects = db.get_prospects_missing_email(search_id)
                        results = hunter.batch_find_emails(missing_prospects,
                                                          all_prospects=prospects)
                        for hr in results:
                            db.update_prospect(hr["prospect_id"],
                                email=hr["email"],
                                email_confidence=hr["confidence"],
                                hunter_email=hr["email"],
                                hunter_confidence=hr.get("hunter_score", 0),
                                source="findymail+hunter",
                            )
                        st.success(f"Hunter.io: {len(results)}ê°œ ì´ë©”ì¼ ë°œê²¬!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"Hunter.io ì‹¤íŒ¨: {e}")
        with col3:
            if st.button("â­ ê±´ë„ˆë›°ê¸° â†’ ë¦¬ì„œì¹˜"):
                st.session_state.prospect_step = "research"
                st.rerun()

        # Show updated prospect table
        prospects = db.get_prospects(search_id=search_id) if search_id else []
        if prospects:
            import pandas as pd
            df = pd.DataFrame(prospects)
            display_cols = ["contact_name", "company", "title", "email", "email_confidence", "source"]
            display_cols = [c for c in display_cols if c in df.columns]
            st.dataframe(df[display_cols], width="stretch", hide_index=True)

        if st.button("â¡ ì—…ê³„ ë¦¬ì„œì¹˜ë¡œ", type="primary"):
            st.session_state.prospect_step = "research"
            st.rerun()

    # â”€â”€ STEP 4: Industry Research â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif st.session_state.prospect_step == "research":
        st.subheader("â‘£ ì—…ê³„ ë¦¬ì„œì¹˜ (ClinicalTrials + PubMed)")
        search_id = st.session_state.prospect_search_id
        prospects = db.get_prospects(search_id=search_id) if search_id else []

        has_research = sum(1 for p in prospects if p.get("research_context"))

        if has_research > 0:
            st.success(f"{has_research}ëª…ì— ëŒ€í•œ ë¦¬ì„œì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        else:
            therapeutic_area = st.text_input(
                "ì¹˜ë£Œ ì˜ì—­ (PubMed ê²€ìƒ‰ í‚¤ì›Œë“œ, ì„ íƒ)",
                placeholder="CNS, oncology, immunology ë“±",
            )

        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("â¬… ì´ë©”ì¼ ì°¾ê¸°ë¡œ"):
                st.session_state.prospect_step = "hunter"
                st.rerun()
        with col2:
            if has_research == 0:
                if st.button("ğŸ”¬ ë¦¬ì„œì¹˜ ì‹¤í–‰", type="primary"):
                    with st.spinner("ClinicalTrials.gov + PubMed ê²€ìƒ‰ ì¤‘..."):
                        try:
                            from research_client import ResearchClient
                            research = ResearchClient()
                            unique_companies = list(set(
                                p["company"] for p in prospects if p.get("company")
                            ))
                            for company in unique_companies[:20]:
                                ctx = research.get_company_research_context(
                                    company=company,
                                    therapeutic_area=therapeutic_area if 'therapeutic_area' in dir() else None,
                                )
                                for p in prospects:
                                    if p.get("company", "").lower() == company.lower():
                                        db.update_prospect(p["id"],
                                            research_context=json.dumps(ctx, ensure_ascii=False, default=str)
                                        )
                            st.success("ë¦¬ì„œì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
                            st.rerun()
                        except Exception as e:
                            st.error(f"ë¦¬ì„œì¹˜ ì‹¤íŒ¨: {e}")
        with col3:
            if st.button("â­ ê±´ë„ˆë›°ê¸° â†’ AI í‰ê°€"):
                st.session_state.prospect_step = "enrich"
                st.rerun()

        # Show research summaries per company
        prospects = db.get_prospects(search_id=search_id) if search_id else []
        shown_companies = set()
        for p in prospects:
            if p.get("research_context") and p["company"] not in shown_companies:
                shown_companies.add(p["company"])
                ctx = json.loads(p["research_context"])
                with st.expander(f"ğŸ“Š {p['company']}", expanded=False):
                    st.markdown(ctx.get("summary", ""))
                    if ctx.get("active_trials"):
                        st.caption(f"Active trials: {len(ctx['active_trials'])}")
                    if ctx.get("recent_publications"):
                        st.caption(f"Recent publications: {len(ctx['recent_publications'])}")

        if st.button("â¡ AI ì¸ë¦¬ì¹˜ë¨¼íŠ¸ë¡œ", type="primary", key="research_next"):
            st.session_state.prospect_step = "enrich"
            st.rerun()

    # â”€â”€ STEP 5: AI Enrichment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif st.session_state.prospect_step == "enrich":
        st.subheader("â‘¤ AI ì¸ë¦¬ì¹˜ë¨¼íŠ¸")
        search_id = st.session_state.prospect_search_id
        search_info = db.get_prospect_search(search_id) if search_id else None
        prospects = db.get_prospects(search_id=search_id) if search_id else []

        # Check if already enriched
        enriched_count = sum(1 for p in prospects if p.get("status") == "enriched")
        if enriched_count > 0:
            st.success(f"{enriched_count}/{len(prospects)}ëª… ì¸ë¦¬ì¹˜ë¨¼íŠ¸ ì™„ë£Œ")
        else:
            with st.spinner("Claudeê°€ ì´ë©”ì¼ ì¶”ë¡  + ì í•©ë„ í‰ê°€ ì¤‘... (1~2ë¶„ ì†Œìš”)"):
                try:
                    from claude_client import ClaudeClient
                    claude = ClaudeClient()

                    search_params = json.loads(search_info["search_params"]) if search_info else {}

                    existing_emails = [
                        {"email": p["email"], "company": p["company"]}
                        for p in prospects if p.get("email")
                    ]

                    # Build research_context from prospect data
                    research_context_data = []
                    seen_companies = set()
                    for p in prospects:
                        if p.get("research_context") and p["company"] not in seen_companies:
                            seen_companies.add(p["company"])
                            research_context_data.append(json.loads(p["research_context"]))

                    enriched_text = claude.enrich_prospects(
                        prospects_json=json.dumps(
                            [{"name": p["contact_name"], "email": p["email"],
                              "company": p["company"], "title": p["title"],
                              "linkedin": p.get("linkedin_url", ""),
                              "location": p.get("location", "")}
                             for p in prospects],
                            ensure_ascii=False,
                        ),
                        search_criteria=search_params,
                        existing_emails_for_pattern=existing_emails,
                        research_context=research_context_data if research_context_data else None,
                    )

                    # Apply enrichment
                    from main import _apply_enrichment
                    _apply_enrichment(search_id, enriched_text)
                    db.update_prospect_search(search_id, total_enriched=len(prospects))
                    st.rerun()
                except Exception as e:
                    st.error(f"ì¸ë¦¬ì¹˜ë¨¼íŠ¸ ì‹¤íŒ¨: {e}")
                    logger.error(f"Enrichment failed: {e}")

        # Show enriched results
        prospects = db.get_prospects(search_id=search_id) if search_id else []
        if prospects:
            import pandas as pd

            df = pd.DataFrame(prospects)
            display_cols = ["contact_name", "company", "title", "email", "email_confidence",
                            "location"]
            display_cols = [c for c in display_cols if c in df.columns]
            st.dataframe(
                df[display_cols],
                width="stretch",
                hide_index=True,
            )

        col1, col2 = st.columns(2)
        with col1:
            if st.button("â¬… ë¦¬ì„œì¹˜ë¡œ"):
                st.session_state.prospect_step = "research"
                st.rerun()
        with col2:
            if st.button("â¡ ë‚´ë³´ë‚´ê¸°", type="primary"):
                st.session_state.prospect_step = "export"
                st.rerun()

    # â”€â”€ STEP 6: Export â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif st.session_state.prospect_step == "export":
        st.subheader("â‘¥ ë‚´ë³´ë‚´ê¸°")
        search_id = st.session_state.prospect_search_id
        search_info = db.get_prospect_search(search_id) if search_id else None
        search_name = (search_info["name"] if search_info else "prospects").strip().replace(" ", "_")

        # Email verification section
        if HUNTER_API_KEY:
            unverified = db.get_unverified_prospects(search_id) if search_id else []
            if unverified:
                st.warning(f"{len(unverified)}ê°œì˜ ì´ë©”ì¼ì´ ì•„ì§ ê²€ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                if st.button("âœ… ì´ë©”ì¼ ê²€ì¦ ì‹¤í–‰ (Hunter.io)"):
                    with st.spinner("ì´ë©”ì¼ ê²€ì¦ ì¤‘..."):
                        try:
                            from hunter_client import HunterClient
                            hunter = HunterClient()
                            emails = [p["email"] for p in unverified if p.get("email")]
                            results = hunter.batch_verify_emails(emails)
                            for p in unverified:
                                if p["email"] in results:
                                    vr = results[p["email"]]
                                    db.update_prospect(p["id"],
                                        verification_status=vr["status"],
                                        verification_score=vr.get("score", 0),
                                    )
                                    db.add_email_verification(
                                        prospect_id=p["id"],
                                        email=p["email"],
                                        status=vr["status"],
                                        score=vr.get("score", 0),
                                    )
                            st.rerun()
                        except Exception as e:
                            st.error(f"ì´ë©”ì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            else:
                # Show verification summary
                all_p = db.get_prospects(search_id=search_id) if search_id else []
                v_counts: dict = {}
                for p in all_p:
                    vs = p.get("verification_status") or "pending"
                    v_counts[vs] = v_counts.get(vs, 0) + 1
                if any(k != "pending" for k in v_counts):
                    vcols = st.columns(4)
                    vcols[0].metric("Deliverable", v_counts.get("deliverable", 0))
                    vcols[1].metric("Risky", v_counts.get("risky", 0))
                    vcols[2].metric("Undeliverable", v_counts.get("undeliverable", 0))
                    vcols[3].metric("Unknown", v_counts.get("unknown", 0) + v_counts.get("pending", 0))

        st.divider()

        prospects = db.get_prospects(search_id=search_id) if search_id else []
        prospects_with_email = [p for p in prospects if p.get("email")
                                and p.get("verification_status") != "undeliverable"]

        st.metric("ë‚´ë³´ë‚´ê¸° ëŒ€ìƒ", f"{len(prospects_with_email)}ëª… (ì´ë©”ì¼ ìˆëŠ” ê±´, undeliverable ì œì™¸)")

        if prospects_with_email:
            import pandas as pd

            df = pd.DataFrame(prospects_with_email)
            display_cols = ["contact_name", "email", "company", "title", "email_confidence", "verification_status"]
            display_cols = [c for c in display_cols if c in df.columns]
            st.dataframe(df[display_cols], width="stretch", hide_index=True)

        st.divider()

        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("â¬… AI í‰ê°€ë¡œ"):
                st.session_state.prospect_step = "enrich"
                st.rerun()
        with col2:
            csv_content = db.export_prospects_to_csv(search_id) if search_id else ""
            if csv_content.strip():
                today = datetime.now().strftime("%y%m%d")
                st.download_button(
                    "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_content,
                    file_name=f"{search_name}_{today}.csv",
                    mime="text/csv",
                )
        with col3:
            if st.button("ğŸ“§ ì½œë“œë©”ì¼ ìº í˜ì¸ìœ¼ë¡œ", type="primary", disabled=not csv_content.strip()):
                st.session_state.csv_data = csv_content
                st.session_state.step = "input"
                st.session_state.active_page = "ğŸ“ ì½œë“œë©”ì¼"
                # Reset prospect state
                st.session_state.prospect_step = "search"
                st.rerun()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PAGE 2: Cold Email (ì½œë“œë©”ì¼)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

elif page == "ğŸ“ ì½œë“œë©”ì¼":
    st.title("ì½œë“œë©”ì¼ ìƒì„±")

    # â”€â”€ Mode selector â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "coldmail_mode" not in st.session_state:
        st.session_state.coldmail_mode = "agent"
    if "agent3_log" not in st.session_state:
        st.session_state.agent3_log = []
    if "agent3_drafts" not in st.session_state:
        st.session_state.agent3_drafts = None
    if "agent3_csv" not in st.session_state:
        st.session_state.agent3_csv = None
    if "agent3_campaign_id" not in st.session_state:
        st.session_state.agent3_campaign_id = None

    # Auto-switch to agent mode when coming from Agent 2
    _from_agent2 = st.session_state.get("a3_from_agent2")
    if _from_agent2 or st.session_state.get("csv_data"):
        st.session_state.coldmail_mode = "agent"

    coldmail_mode_sel = st.radio(
        "ì‘ì„± ëª¨ë“œ",
        ["ğŸ¤– Agent ëª¨ë“œ (ìë™ ë¦¬ì„œì¹˜ + ì‘ì„±)", "ğŸ”§ ìˆ˜ë™ ëª¨ë“œ (5ë‹¨ê³„)"],
        horizontal=True,
        index=0 if st.session_state.coldmail_mode == "agent" else 1,
    )
    st.session_state.coldmail_mode = "agent" if "Agent" in coldmail_mode_sel else "manual"
    st.divider()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # AGENT MODE (ColdMailAgent)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if st.session_state.coldmail_mode == "agent":
        st.caption("AI Agentê°€ ê° íšŒì‚¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì›¹ ë¦¬ì„œì¹˜í•œ í›„, ê°œì¸í™”ëœ ì½œë“œë©”ì¼ì„ ìë™ ì‘ì„±í•©ë‹ˆë‹¤.")

        # Show active profile info
        _active_prof = st.session_state.get("active_profile")
        if _active_prof:
            st.info(
                f"í™œì„± í”„ë¡œí•„: **{_active_prof['name']}** â€” "
                f"{_active_prof.get('product_name', '')} Â· "
                f"{_active_prof.get('sales_goal', '')} Â· "
                f"{_active_prof.get('language', 'ja')}"
            )
        else:
            st.warning("ìº í˜ì¸ í”„ë¡œí•„ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'âš™ï¸ ìº í˜ì¸ ì„¤ì •'ì—ì„œ í”„ë¡œí•„ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")

        # â”€â”€ Input section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.subheader("ìº í˜ì¸ ì„¤ì •")

        a3col1, a3col2 = st.columns(2)

        with a3col1:
            # Language
            a3_lang = st.selectbox("ì–¸ì–´", ["en (ì˜ì–´)", "ja (ì¼ë³¸ì–´)"], index=0, key="a3_lang")
            a3_language_code = a3_lang.split(" ")[0]

        with a3col2:
            # CTA type
            a3_cta = st.selectbox(
                "CTA ìœ í˜•",
                [
                    "ìë™ ì„ íƒ",
                    "ë‹´ë‹¹ì ì¶”ì²œ ìš”ì²­ (ê¸°ë³¸)",
                    "15ë¶„ ëŒ€í™” ìš”ì²­ (íƒìƒ‰í˜•)",
                    "í”¼ë“œë°±/ì˜ê²¬ ìš”ì²­ (Design Partner)",
                    "ìë£Œ/ì¸ì‚¬ì´íŠ¸ ê³µìœ  ì œì•ˆ",
                    "Zoom/Web ë¯¸íŒ… ì œì•ˆ",
                    "ì§ì ‘ ì…ë ¥",
                ],
                index=0,
                key="a3_cta",
            )
            a3_cta_text = "" if a3_cta == "ìë™ ì„ íƒ" else a3_cta
            if a3_cta == "ì§ì ‘ ì…ë ¥":
                a3_cta_text = st.text_input("CTA ë‚´ìš©", key="a3_cta_custom")

            a3_visit = st.text_input(
                "ë°©ë¬¸ ì¼ì • (ìˆìœ¼ë©´ ì…ë ¥)",
                placeholder="ì˜ˆ: 2æœˆ16æ—¥ã€œ17æ—¥ã«è¨ªæ—¥äºˆå®š",
                key="a3_visit",
            )

        a3_extra = st.text_area(
            "ì¶”ê°€ ì§€ì‹œì‚¬í•­ (ì„ íƒ)",
            placeholder="ì˜ˆ: í†¤ì€ casualë¡œ, ë³¸ë¬¸ 5ì¤„ ì´ë‚´, íŠ¹ì • ë‰´ìŠ¤ ë°˜ë“œì‹œ ì–¸ê¸‰ ë“±",
            height=80,
            key="a3_extra",
        )

        # â”€â”€ Prospect source â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.subheader("ì—°ë½ì²˜ ì†ŒìŠ¤")

        a3_csv_text = None
        a3_search_id = None

        # Auto-detect: Agent 2 â†’ Agent 3 handoff
        _from_agent2_sid = st.session_state.get("a3_from_agent2")

        # Agent 2 â†’ Agent 3 handoff: csv_dataê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        _a2_csv = st.session_state.get("csv_data", "")
        if _from_agent2_sid and _a2_csv and _a2_csv.strip():
            # CSV ë°ì´í„°ì—ì„œ ë¡œë“œ (DB search_id ì œí•œ ì—†ì´ ì „ì²´ ê²°ê³¼)
            _a2_rows = parse_csv_string(_a2_csv)
            _a2_with_email = [r for r in _a2_rows if r.get("email")]
            st.success(
                f"Agent 2 ê²°ê³¼ ìë™ ì—°ê²°ë¨: "
                f"ì´ {len(_a2_rows)}ëª…, ì´ë©”ì¼ {len(_a2_with_email)}ëª…"
            )
            a3_csv_text = _a2_csv

            if _a2_with_email:
                import pandas as pd
                df = pd.DataFrame(_a2_with_email)
                display_cols = [c for c in ["contact_name", "email", "company", "title"] if c in df.columns]
                st.dataframe(df[display_cols], use_container_width=True, height=300, hide_index=True)

            if st.button("ë‹¤ë¥¸ ì†ŒìŠ¤ ì‚¬ìš©í•˜ê¸°"):
                st.session_state.a3_from_agent2 = None
                st.session_state.csv_data = ""
                st.rerun()
        elif _from_agent2_sid:
            # CSV ì—†ìœ¼ë©´ DB fallback
            _a2_prospects = db.get_prospects(search_id=_from_agent2_sid)
            _a2_with_email = [p for p in _a2_prospects if p.get("email")]
            st.success(
                f"Agent 2 ê²°ê³¼ (search_id={_from_agent2_sid}): "
                f"ì´ {len(_a2_prospects)}ëª…, ì´ë©”ì¼ {len(_a2_with_email)}ëª…"
            )
            a3_search_id = _from_agent2_sid

            if _a2_with_email:
                import pandas as pd
                df = pd.DataFrame(_a2_with_email)
                display_cols = [c for c in ["contact_name", "email", "company", "title"] if c in df.columns]
                st.dataframe(df[display_cols], use_container_width=True, height=300, hide_index=True)

            if st.button("ë‹¤ë¥¸ ì†ŒìŠ¤ ì‚¬ìš©í•˜ê¸°"):
                st.session_state.a3_from_agent2 = None
                st.rerun()
        else:
            # Manual source selection
            a3_src_tab1, a3_src_tab2, a3_src_tab3 = st.tabs(
                ["ğŸ“„ CSV ì—…ë¡œë“œ", "ğŸ” Agent 2 ê²°ê³¼ì—ì„œ", "ğŸ“‹ ê¸°ì¡´ CSV ë°ì´í„° ì‚¬ìš©"]
            )

            with a3_src_tab1:
                a3_uploaded = st.file_uploader(
                    "ì—°ë½ì²˜ CSV (contact_name, email, company, title í•„ìˆ˜)",
                    type=["csv"],
                    key="a3_csv_upload",
                )
                if a3_uploaded:
                    a3_bytes = a3_uploaded.read()
                    try:
                        a3_csv_text = a3_bytes.decode("utf-8-sig")
                    except UnicodeDecodeError:
                        a3_csv_text = a3_bytes.decode("utf-8")

                    rows = parse_csv_string(a3_csv_text)
                    if rows:
                        st.success(f"{len(rows)}ëª… ë¡œë“œë¨")
                        import pandas as pd
                        st.dataframe(pd.DataFrame(rows), width="stretch", hide_index=True)

            with a3_src_tab2:
                # Load from DB prospect searches
                searches = db.get_prospect_searches()
                completed_searches = [s for s in searches if s.get("status") == "completed"]
                if completed_searches:
                    search_options = {
                        f"{s['name']} ({s['total_found']}ëª…, {s['created_at'][:10]})": s["id"]
                        for s in completed_searches
                    }
                    selected_search = st.selectbox(
                        "ê²€ìƒ‰ ê²°ê³¼ ì„ íƒ",
                        list(search_options.keys()),
                        key="a3_search_select",
                    )
                    a3_search_id = search_options[selected_search]

                    prospects = db.get_prospects(search_id=a3_search_id)
                    email_prospects = [p for p in prospects if p.get("email")]
                    st.info(f"ì´ {len(prospects)}ëª… ì¤‘ ì´ë©”ì¼ ìˆëŠ” ì—°ë½ì²˜: {len(email_prospects)}ëª…")
                    if email_prospects:
                        import pandas as pd
                        df = pd.DataFrame(email_prospects)
                        display_cols = [c for c in ["contact_name", "email", "company", "title"] if c in df.columns]
                        st.dataframe(df[display_cols], width="stretch", hide_index=True)
                else:
                    st.info("ì™„ë£Œëœ ì»¨íƒ ê²€ìƒ‰ì´ ì—†ìŠµë‹ˆë‹¤. Agent 2 ë˜ëŠ” ìˆ˜ë™ ê²€ìƒ‰ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

            with a3_src_tab3:
                if st.session_state.csv_data:
                    rows = parse_csv_string(st.session_state.csv_data)
                    if rows:
                        st.success(f"ê¸°ì¡´ CSV ë°ì´í„°: {len(rows)}ëª…")
                        import pandas as pd
                        st.dataframe(pd.DataFrame(rows), width="stretch", hide_index=True)
                        a3_csv_text = st.session_state.csv_data
                else:
                    st.info("ê¸°ì¡´ CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì»¨íƒ ì„œì¹­ ê²°ê³¼ì—ì„œ 'ì½œë“œë©”ì¼ ìº í˜ì¸ìœ¼ë¡œ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

        # â”€â”€ Run button â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        can_run_a3 = a3_csv_text is not None or a3_search_id is not None

        if st.button(
            "ğŸ¤– ì½œë“œë©”ì¼ Agent ì‹¤í–‰",
            type="primary",
            disabled=not can_run_a3 or st.session_state.get("agent_running"),
            use_container_width=True,
        ):
            # Build extra instructions
            a3_inst_parts = []
            if a3_cta_text:
                a3_inst_parts.append(f"CTA: {a3_cta_text}")
            if a3_visit:
                a3_inst_parts.append(f"ë°©ë¬¸ ì¼ì •: {a3_visit}")
            if a3_extra:
                a3_inst_parts.append(a3_extra)
            a3_full_instructions = "\n".join(a3_inst_parts)

            # Build user request
            if a3_search_id:
                a3_user_request = (
                    f"ì½œë“œë©”ì¼ ì‘ì„±í•´ì¤˜.\n"
                    f"ì—°ë½ì²˜ëŠ” DB search_id={a3_search_id}ì—ì„œ ë¡œë“œí•´ì¤˜.\n"
                    f"ì–¸ì–´: {a3_language_code}\n"
                )
            else:
                a3_user_request = (
                    f"ì½œë“œë©”ì¼ ì‘ì„±í•´ì¤˜.\n"
                    f"ì–¸ì–´: {a3_language_code}\n"
                    f"\n## CSV ë°ì´í„°\n```\n{a3_csv_text}\n```"
                )

            if a3_full_instructions:
                a3_user_request += f"\n\n## ì¶”ê°€ ì§€ì‹œì‚¬í•­\n{a3_full_instructions}"

            # Inject campaign context from active profile
            _a3_ctx = build_campaign_context(st.session_state.get("active_profile"))
            if _a3_ctx:
                a3_user_request += f"\n\n{_a3_ctx}"

            # Reset state
            st.session_state.agent3_log = []
            st.session_state.agent3_drafts = None
            st.session_state.agent3_csv = None
            st.session_state.agent3_campaign_id = None
            st.session_state.a3_from_agent2 = None

            # Estimate total contacts for progress
            _a3_total = 0
            if a3_csv_text:
                _a3_total = max(a3_csv_text.count("\n") - 1, 1)
            elif a3_search_id:
                _a3_prospects = db.get_prospects(a3_search_id)
                _a3_total = len([p for p in _a3_prospects if p.get("email")])

            # Build sender profile markdown from active sender
            _sender_md = ""
            _active_sender = st.session_state.get("active_sender")
            if _active_sender:
                _sender_md = db.render_sender_profile_md(_active_sender)

            # Phase 1: save params and rerun to show overlay
            st.session_state._pending_agent3 = {
                "request": a3_user_request,
                "language": a3_language_code,
                "cta_type": a3_cta_text,
                "extra_instructions": a3_full_instructions,
                "campaign_context": _a3_ctx,
                "sender_profile_md": _sender_md,
                "profile_id": st.session_state.get("active_profile_id"),
                "total_items": max(_a3_total, 1),
            }
            st.session_state.agent_running = True
            st.rerun()

        # Phase 2: execute pending Agent 3 task (overlay already visible)
        if st.session_state.get("_pending_agent3"):
            _task = st.session_state.pop("_pending_agent3")
            tracker = AgentProgressTracker("agent3", total_items=_task["total_items"])
            try:
                from agent import ColdMailAgent

                agent = ColdMailAgent(
                    language=_task["language"],
                    cta_type=_task["cta_type"],
                    extra_instructions=_task["extra_instructions"],
                    campaign_context=_task["campaign_context"],
                    sender_profile_md=_task["sender_profile_md"],
                    profile_id=_task.get("profile_id"),
                    on_tool_call=tracker.on_tool_call,
                    on_tool_result=tracker.on_tool_result,
                    on_text=tracker.on_text,
                )

                result_text = agent.run(_task["request"])

                st.session_state.agent3_log = tracker.tool_log
                st.session_state.agent3_drafts = agent.draft_emails
                st.session_state.agent3_csv = agent.csv_content
                st.session_state.agent3_campaign_id = agent.campaign_id

                tracker.complete(
                    f"{len(agent.draft_emails)}ê°œ ì´ë©”ì¼ ìƒì„±"
                    + (f" (ìº í˜ì¸ ID: {agent.campaign_id})" if agent.campaign_id else "")
                )

            except Exception as e:
                tracker.fail(f"Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                logger.error(f"ColdMailAgent failed: {e}")
            finally:
                st.session_state.agent_running = False
            st.rerun()

        # â”€â”€ Results display â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.session_state.agent3_drafts:
            st.subheader(f"ìƒì„±ëœ ì´ë©”ì¼ ({len(st.session_state.agent3_drafts)}ê°œ)")

            for i, draft in enumerate(st.session_state.agent3_drafts):
                with st.expander(
                    f"ğŸ“§ {draft.get('contact_name', 'N/A')} ({draft.get('company', 'N/A')}) â€” {draft.get('subject', '')}",
                    expanded=(i == 0),
                ):
                    mcol1, mcol2 = st.columns([1, 3])
                    with mcol1:
                        st.markdown(f"**To:** {draft.get('email', '')}")
                        st.markdown(f"**Framework:** {draft.get('framework', 'N/A')}")
                    with mcol2:
                        if draft.get("rationale"):
                            st.caption(f"ì „ëµ: {draft['rationale']}")

                    st.markdown(f"**Subject:** {draft.get('subject', '')}")
                    st.divider()
                    body = draft.get("body", "")
                    st.markdown(body, unsafe_allow_html=True)

            # â”€â”€ Action buttons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            st.divider()
            acol1, acol2, acol3 = st.columns(3)

            with acol1:
                if st.session_state.agent3_csv:
                    today = datetime.now().strftime("%y%m%d")
                    st.download_button(
                        "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state.agent3_csv,
                        file_name=f"coldmails_{today}.csv",
                        mime="text/csv",
                    )

            with acol2:
                if st.session_state.agent3_campaign_id:
                    if st.button("ğŸ“¤ Google Sheets ì—…ë¡œë“œ"):
                        try:
                            from agent import ColdMailAgent
                            # Create a minimal agent just for upload
                            agent = ColdMailAgent(language=a3_language_code)
                            agent._campaign_id = st.session_state.agent3_campaign_id
                            agent._csv_content = st.session_state.agent3_csv
                            result = agent._upload_sheets()
                            st.success(result)
                        except Exception as e:
                            st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

            with acol3:
                if st.session_state.agent3_campaign_id:
                    campaign = db.get_campaign(st.session_state.agent3_campaign_id)
                    if campaign and campaign.get("spreadsheet_id"):
                        st.info("ğŸ“Š ìº í˜ì¸ í˜„í™©ì—ì„œ ë°œì†¡")
                    else:
                        st.caption("Sheets ì—…ë¡œë“œ í›„ ë°œì†¡ ê°€ëŠ¥")

        # â”€â”€ Agent log (full) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.session_state.agent3_log:
            full_log3 = "\n".join(st.session_state.agent3_log)
            with st.expander(f"Agent í™œë™ ë¡œê·¸ ({len(st.session_state.agent3_log)}ê±´)", expanded=False):
                st.code(full_log3, language=None)
                st.download_button(
                    "ğŸ“¥ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
                    full_log3,
                    f"agent3_log_{time.strftime('%y%m%d_%H%M')}.txt",
                    "text/plain",
                    key="a3_log_download",
                )

        # â”€â”€ Email Writing Feedback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        with st.expander("ğŸ“ ë©”ì¼ ì‘ì„± í”¼ë“œë°± ê´€ë¦¬", expanded=False):
            # Build profile list for selector
            _all_profiles = db.get_campaign_profiles()
            _profile_options = {"ğŸŒ ê¸€ë¡œë²Œ (ëª¨ë“  í”„ë¡œí•„ ê³µí†µ)": None}
            for p in _all_profiles:
                _profile_options[f"ğŸ“‹ {p['name']}"] = p["id"]

            # Show existing feedback â€” global + all profiles
            _global_fb = db.get_email_feedback(profile_id=None)
            if _global_fb:
                st.markdown("**ğŸŒ ê¸€ë¡œë²Œ í”¼ë“œë°±** (ëª¨ë“  í”„ë¡œí•„ ê³µí†µ)")
                for fb in _global_fb:
                    fcol1, fcol2 = st.columns([9, 1])
                    fcol1.markdown(f"- `{fb['created_at'][:16]}` {fb['feedback']}")
                    if fcol2.button("ğŸ—‘ï¸", key=f"del_efb_g_{fb['id']}"):
                        db.delete_email_feedback(fb["id"])
                        st.rerun()

            for p in _all_profiles:
                _pfb = db.get_email_feedback(profile_id=p["id"])
                if _pfb:
                    st.markdown(f"**ğŸ“‹ {p['name']}**")
                    for fb in _pfb:
                        fcol1, fcol2 = st.columns([9, 1])
                        fcol1.markdown(f"- `{fb['created_at'][:16]}` {fb['feedback']}")
                        if fcol2.button("ğŸ—‘ï¸", key=f"del_efb_p_{fb['id']}"):
                            db.delete_email_feedback(fb["id"])
                            st.rerun()

            if not _global_fb and not any(db.get_email_feedback(profile_id=p["id"]) for p in _all_profiles):
                st.caption("ì €ì¥ëœ í”¼ë“œë°±ì´ ì—†ìŠµë‹ˆë‹¤.")

            # Add new feedback
            st.markdown("---")
            _efb_target = st.selectbox(
                "í”¼ë“œë°± ì €ì¥ ëŒ€ìƒ",
                list(_profile_options.keys()),
                key="efb_target_profile",
            )
            _efb_target_pid = _profile_options[_efb_target]

            _new_efb = st.text_area(
                "ìƒˆ í”¼ë“œë°± ì…ë ¥",
                placeholder="ì˜ˆ: Subjectì—ì„œ ã€Œã®ã€ íƒˆë½ ê¸ˆì§€, ë³¸ë¬¸ 5ì¤„ ì´ë‚´ë¡œ ë“±",
                height=80,
                key="new_email_feedback",
            )
            if st.button("ğŸ’¾ í”¼ë“œë°± ì €ì¥", disabled=not _new_efb):
                db.add_email_feedback(_new_efb, profile_id=_efb_target_pid)
                _saved_label = _efb_target.replace("ğŸŒ ", "").replace("ğŸ“‹ ", "")
                st.success(f"'{_saved_label}' í”¼ë“œë°± ì €ì¥ ì™„ë£Œ")
                st.rerun()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MANUAL MODE (existing 5-step pipeline)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    else:
        # â”€â”€ Step indicator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        steps = ["â‘  ì…ë ¥", "â‘¡ ìƒì„±", "â‘¢ ê²€ìˆ˜", "â‘£ ë¯¸ë¦¬ë³´ê¸°/ì €ì¥"]
        step_map = {"input": 0, "generate": 1, "review": 2, "preview": 3}
        current_step = step_map.get(st.session_state.step, 0)

        cols = st.columns(4)
        for i, (col, label) in enumerate(zip(cols, steps)):
            if i < current_step:
                col.success(label)
            elif i == current_step:
                col.info(label)
            else:
                col.empty()
                col.markdown(f"<span style='color:gray'>{label}</span>", unsafe_allow_html=True)

        st.divider()

    # â”€â”€ Manual mode step logic (skipped in Agent mode) â”€â”€
    if st.session_state.coldmail_mode != "manual":
        pass

    elif st.session_state.step == "input":
        st.subheader("â‘  ê¸°ë³¸ ì„¤ì •")

        col1, col2 = st.columns(2)

        with col1:
            # Language
            language = st.selectbox("ì–¸ì–´", ["ja (ì¼ë³¸ì–´)", "en (ì˜ì–´)"], index=0)
            language_code = language.split(" ")[0]

        with col2:
            # CTA type
            cta_type = st.selectbox(
                "CTA (Call To Action) ìœ í˜•",
                [
                    "ë°©ë¬¸ ë¯¸íŒ… ì œì•ˆ",
                    "Zoom/Web ë¯¸íŒ… ì œì•ˆ",
                    "ìë£Œ(PDF) ì†¡ë¶€ ì œì•ˆ",
                    "ë°©ë¬¸ + Zoom ì„ íƒì§€ ì œê³µ",
                    "ì§ì ‘ ì…ë ¥",
                ],
                index=3,
            )

            if cta_type == "ì§ì ‘ ì…ë ¥":
                cta_custom = st.text_input("CTA ë‚´ìš©ì„ ì§ì ‘ ì…ë ¥í•´ì£¼ì„¸ìš”")
            else:
                cta_custom = ""

            # Visit schedule
            visit_schedule = st.text_input(
                "ë°©ë¬¸ ì¼ì • (ìˆìœ¼ë©´ ì…ë ¥)",
                placeholder="ì˜ˆ: 2æœˆ16æ—¥ã€œ17æ—¥ã«è¨ªæ—¥äºˆå®š",
            )

        st.subheader("â‘¡ CSV ì—…ë¡œë“œ")
        st.caption("í•„ìˆ˜ ì»¬ëŸ¼: contact_name, email, company, title")

        uploaded_file = st.file_uploader(
            "ì—°ë½ì²˜ CSV íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”",
            type=["csv"],
            help="contact_name, email, company, title ì»¬ëŸ¼ì´ í¬í•¨ëœ CSV",
        )

        if uploaded_file:
            csv_bytes = uploaded_file.read()
            # Try UTF-8-SIG first, fallback to UTF-8
            try:
                csv_text = csv_bytes.decode("utf-8-sig")
            except UnicodeDecodeError:
                csv_text = csv_bytes.decode("utf-8")

            rows = parse_csv_string(csv_text)
            st.session_state.csv_data = csv_text

            if rows:
                st.success(f"{len(rows)}ëª…ì˜ ì—°ë½ì²˜ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                # Preview table
                import pandas as pd
                df = pd.DataFrame(rows)
                display_cols = [c for c in ["contact_name", "email", "company", "title"] if c in df.columns]
                if display_cols:
                    st.dataframe(df[display_cols], width="stretch")
                else:
                    st.dataframe(df, width="stretch")
            else:
                st.warning("CSVì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.subheader("â‘¢ ì¶”ê°€ ì§€ì‹œì‚¬í•­")
        extra_instructions = st.text_area(
            "Claudeì—ê²Œ ì „ë‹¬í•  ì¶”ê°€ ì§€ì‹œì‚¬í•­ (ì„ íƒ)",
            placeholder="ì˜ˆ: ì²« ë¬¸ì¥ì— ìƒëŒ€ íšŒì‚¬ì˜ ìµœê·¼ ë‰´ìŠ¤ë¥¼ ì–¸ê¸‰í•´ì¤˜, ë³¸ë¬¸ì€ ì§§ê²Œ 5ì¤„ ì´ë‚´ë¡œ ì‘ì„±í•´ì¤˜ ë“±",
            height=100,
        )

        # â”€â”€ Generate Button â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()

        can_generate = (
            st.session_state.csv_data is not None
            and len(st.session_state.csv_data.strip()) > 0
        )

        if st.button("ğŸš€ ë©”ì¼ ìƒì„± ì‹œì‘", type="primary", disabled=not can_generate, width="stretch"):
            # Build extra instructions string
            instructions_parts = []

            # CTA instruction
            cta_map = {
                "ë°©ë¬¸ ë¯¸íŒ… ì œì•ˆ": "CTA: ì§ì ‘ ë°©ë¬¸ ë¯¸íŒ…ì„ ì œì•ˆí•˜ì„¸ìš”.",
                "Zoom/Web ë¯¸íŒ… ì œì•ˆ": "CTA: Zoom/ì›¹ ë¯¸íŒ…ì„ ì œì•ˆí•˜ì„¸ìš”.",
                "ìë£Œ(PDF) ì†¡ë¶€ ì œì•ˆ": "CTA: PDF ìë£Œ ì†¡ë¶€ë¥¼ ì œì•ˆí•˜ì„¸ìš”.",
                "ë°©ë¬¸ + Zoom ì„ íƒì§€ ì œê³µ": "CTA: ì§ì ‘ ë°©ë¬¸ ë˜ëŠ” Zoom ë¯¸íŒ… ì¤‘ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ ì œì•ˆí•˜ì„¸ìš”.",
            }
            if cta_type in cta_map:
                instructions_parts.append(cta_map[cta_type])
            elif cta_custom:
                instructions_parts.append(f"CTA: {cta_custom}")

            if visit_schedule:
                instructions_parts.append(f"ë°©ë¬¸ ì¼ì •: {visit_schedule}")

            if extra_instructions:
                instructions_parts.append(extra_instructions)

            full_instructions = "\n".join(instructions_parts)

            # Generate
            with st.spinner("Claudeê°€ ë©”ì¼ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... (1~2ë¶„ ì†Œìš”)"):
                try:
                    from claude_client import ClaudeClient
                    claude = ClaudeClient()
                    _manual_profile_id = st.session_state.get("active_profile_id")
                    _manual_feedback = db.get_combined_email_feedback_text(_manual_profile_id)
                    result = claude.generate_coldmail(
                        csv_content=st.session_state.csv_data,
                        language=language_code,
                        extra_instructions=full_instructions,
                        feedback_text=_manual_feedback,
                    )

                    st.session_state.generated_md = result
                    csv_block = extract_csv_block(result)
                    st.session_state.generated_csv = csv_block

                    # Save files
                    today = datetime.now().strftime("%y%m%d")
                    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
                    md_path = OUTPUT_DIR / f"coldmails_{today}.md"
                    md_path.write_text(result, encoding="utf-8")

                    if csv_block:
                        csv_path = OUTPUT_DIR / f"{today}final.csv"
                        csv_path.write_text(csv_block, encoding="utf-8-sig")

                    st.session_state.step = "generate"
                    st.rerun()

                except Exception as e:
                    st.error(f"ìƒì„± ì‹¤íŒ¨: {e}")
                    logger.error(f"Generation failed: {e}")

    # â”€â”€ STEP 2: Generation Result â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif st.session_state.step == "generate":
        st.subheader("â‘¡ ìƒì„± ê²°ê³¼")

        if st.session_state.generated_md:
            with st.expander("Claude ì›ë³¸ ì¶œë ¥ (Markdown)", expanded=False):
                st.markdown(st.session_state.generated_md[:5000])
                if len(st.session_state.generated_md) > 5000:
                    st.caption("... (ì¶œë ¥ì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œ)")

        if st.session_state.generated_csv:
            st.success("CSV ë¸”ë¡ì´ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
            rows = parse_csv_string(st.session_state.generated_csv)
            if rows:
                import pandas as pd
                df = pd.DataFrame(rows)
                st.dataframe(df, width="stretch")
        else:
            st.warning("CSV ë¸”ë¡ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ì¶œë ¥ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("â¬… ë‹¤ì‹œ ì…ë ¥í•˜ê¸°"):
                st.session_state.step = "input"
                st.rerun()
        with col2:
            if st.button("ğŸ” ê²€ìˆ˜í•˜ê¸° (Review)", type="primary"):
                st.session_state.step = "review"
                st.rerun()
        with col3:
            if st.button("â­ ê²€ìˆ˜ ê±´ë„ˆë›°ê¸° â†’ ë¯¸ë¦¬ë³´ê¸°"):
                st.session_state.step = "preview"
                st.rerun()

    # â”€â”€ STEP 3: Review â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif st.session_state.step == "review":
        st.subheader("â‘¢ ë©”ì¼ ê²€ìˆ˜ (Review)")

        if st.session_state.review_result:
            st.markdown(st.session_state.review_result[:8000])
            if len(st.session_state.review_result) > 8000:
                st.caption("... (ê²€ìˆ˜ ê²°ê³¼ê°€ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œ)")
        else:
            with st.spinner("Claudeê°€ ë©”ì¼ì„ ê²€ìˆ˜ ì¤‘ì…ë‹ˆë‹¤... (1~2ë¶„ ì†Œìš”)"):
                try:
                    from claude_client import ClaudeClient
                    claude = ClaudeClient()
                    content = st.session_state.generated_md or ""
                    result = claude.review(content, auto_fix=True)
                    st.session_state.review_result = result

                    # Save review report
                    today = datetime.now().strftime("%Y%m%d")
                    report_path = OUTPUT_DIR / f"review_{today}.md"
                    report_path.write_text(result, encoding="utf-8")

                    st.rerun()
                except Exception as e:
                    st.error(f"ê²€ìˆ˜ ì‹¤íŒ¨: {e}")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("â¬… ìƒì„± ê²°ê³¼ë¡œ ëŒì•„ê°€ê¸°"):
                st.session_state.step = "generate"
                st.rerun()
        with col2:
            if st.button("â¡ ë¯¸ë¦¬ë³´ê¸°", type="primary"):
                st.session_state.step = "preview"
                st.rerun()

    # â”€â”€ STEP 4: Preview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif st.session_state.step == "preview":
        st.subheader("â‘£ ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°")

        if not st.session_state.generated_csv:
            st.warning("ìƒì„±ëœ CSVê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë©”ì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            if st.button("â¬… ì…ë ¥ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
                st.session_state.step = "input"
                st.rerun()
        else:
            rows = parse_csv_string(st.session_state.generated_csv)

            if rows:
                for i, row in enumerate(rows):
                    with st.expander(
                        f"ğŸ“§ {row.get('contact_name', 'N/A')} ({row.get('company', 'N/A')}) â€” {row.get('subject', '')}",
                        expanded=(i == 0),
                    ):
                        st.markdown(f"**To:** {row.get('email', '')}")
                        st.markdown(f"**Subject:** {row.get('subject', '')}")
                        st.divider()
                        # Render body (HTML with <br> tags)
                        body = row.get("body", "")
                        st.markdown(body, unsafe_allow_html=True)

            st.divider()
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("â¬… ê²€ìˆ˜ë¡œ ëŒì•„ê°€ê¸°"):
                    st.session_state.step = "review"
                    st.rerun()
            with col2:
                # Download CSV
                today = datetime.now().strftime("%y%m%d")
                st.download_button(
                    "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                    data=st.session_state.generated_csv,
                    file_name=f"{today}final.csv",
                    mime="text/csv",
                )
            with col3:
                if st.button("ğŸ’¾ ìº í˜ì¸ìœ¼ë¡œ ì €ì¥", type="primary"):
                    with st.spinner("ì €ì¥ ì¤‘..."):
                        try:
                            today = datetime.now().strftime("%y%m%d")
                            campaign_name = f"ColdMail_{today}"
                            csv_path = OUTPUT_DIR / f"{today}final.csv"
                            csv_path.write_text(
                                st.session_state.generated_csv,
                                encoding="utf-8-sig",
                            )
                            campaign_id = db.create_campaign(campaign_name, str(csv_path))
                            st.success(f"ìº í˜ì¸ '{campaign_name}' ì €ì¥ ì™„ë£Œ (ID: {campaign_id}). ğŸ“Š ìº í˜ì¸ í˜„í™©ì—ì„œ ë°œì†¡í•˜ì„¸ìš”.")

                            st.session_state.step = "input"
                            st.session_state.generated_md = None
                            st.session_state.generated_csv = None
                            st.session_state.review_result = None
                        except Exception as e:
                            st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PAGE 3: Campaign Status Dashboard (GMass Live)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

elif page == "ğŸ“Š ìº í˜ì¸ í˜„í™©":
    st.title("ìº í˜ì¸ í˜„í™©")

    import pandas as pd

    # â”€â”€ ë°œì†¡ ëŒ€ê¸° ìº í˜ì¸ (DB draft campaigns) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _draft_campaigns = []
    try:
        conn = db.get_connection()
        _draft_rows = conn.execute(
            "SELECT * FROM campaigns WHERE status = 'draft' ORDER BY id DESC"
        ).fetchall()
        conn.close()
        _draft_campaigns = [dict(r) for r in _draft_rows]
    except Exception:
        pass

    if _draft_campaigns:
        st.subheader("ğŸ“ ë°œì†¡ ëŒ€ê¸° ìº í˜ì¸")
        for dc in _draft_campaigns:
            dc_id = dc["id"]
            dc_name = dc.get("name", f"ìº í˜ì¸ #{dc_id}")
            dc_created = (dc.get("created_at") or "")[:16]
            dc_has_sheet = bool(dc.get("spreadsheet_id"))

            with st.expander(f"{dc_name} (ID: {dc_id}) â€” {dc_created}", expanded=True):
                # Show CSV preview if available
                csv_path = dc.get("csv_path", "")
                if csv_path and Path(csv_path).exists():
                    try:
                        csv_df = pd.read_csv(csv_path, encoding="utf-8-sig")
                        st.dataframe(csv_df, hide_index=True)
                        st.caption(f"{len(csv_df)}ëª… Â· CSV: {csv_path}")
                    except Exception:
                        st.caption(f"CSV: {csv_path}")

                sc1, sc2, sc3 = st.columns(3)

                with sc1:
                    if not dc_has_sheet:
                        if st.button("ğŸ“¤ Google Sheets ì—…ë¡œë“œ", key=f"sheet_upload_{dc_id}"):
                            with st.spinner("ì—…ë¡œë“œ ì¤‘..."):
                                try:
                                    from agent import ColdMailAgent
                                    agent = ColdMailAgent()
                                    agent._campaign_id = dc_id
                                    if csv_path and Path(csv_path).exists():
                                        agent._csv_content = Path(csv_path).read_text(encoding="utf-8-sig")
                                    result = agent._upload_sheets()
                                    st.success(result)
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
                    else:
                        st.success("Sheets ì—…ë¡œë“œ ì™„ë£Œ")

                with sc2:
                    if dc_has_sheet:
                        if st.button("ğŸš€ GMass ë°œì†¡", key=f"gmass_send_{dc_id}", type="primary"):
                            st.warning("ì‹¤ì œ ì´ë©”ì¼ì´ ë°œì†¡ë©ë‹ˆë‹¤!")
                            try:
                                from agent import ColdMailAgent
                                agent = ColdMailAgent()
                                agent._campaign_id = dc_id
                                result = agent._send_gmass()
                                st.success(result)
                                st.balloons()
                                st.rerun()
                            except Exception as e:
                                st.error(f"ë°œì†¡ ì‹¤íŒ¨: {e}")
                    else:
                        st.caption("Sheets ì—…ë¡œë“œ í›„ ë°œì†¡ ê°€ëŠ¥")

                with sc3:
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"del_draft_{dc_id}"):
                        db.update_campaign(dc_id, status="cancelled")
                        st.rerun()

        st.divider()

    # â”€â”€ GMass ë°œì†¡ ì™„ë£Œ ìº í˜ì¸ (Live) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ğŸ“Š ë°œì†¡ëœ ìº í˜ì¸ (GMass)")

    # Load GMass campaigns directly from API
    try:
        from gmass_client import GMassClient
        gmass = GMassClient()
        gmass_campaigns = gmass.get_campaigns()
    except Exception as e:
        st.error(f"GMass API ì—°ê²° ì‹¤íŒ¨: {e}")
        gmass_campaigns = []

    if not gmass_campaigns:
        st.info("GMassì— ìº í˜ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # Filter to campaigns with recipients > 0
        active_campaigns = [c for c in gmass_campaigns if c.get("statistics", {}).get("recipients", 0) > 0]
        other_campaigns = [c for c in gmass_campaigns if c.get("statistics", {}).get("recipients", 0) == 0]

        if not active_campaigns:
            st.info("ë°œì†¡ëœ ìº í˜ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        for campaign in active_campaigns:
            cid = str(campaign.get("campaignId", ""))
            stats = campaign.get("statistics", {})
            recipients_count = stats.get("recipients", 0)
            opens_count = stats.get("opens", 0)
            replies_count = stats.get("replies", 0)
            bounces_count = stats.get("bounces", 0)
            blocks_count = stats.get("blocks", 0)
            unsubs_count = stats.get("unsubscribes", 0)
            clicks_count = stats.get("clicks", 0)
            open_rate = f"{opens_count / recipients_count * 100:.1f}%" if recipients_count else "0%"
            status = campaign.get("status", "N/A")
            sent_time = campaign.get("creationTime", "")[:16].replace("T", " ")

            with st.expander(
                f"Campaign {cid} â€” {recipients_count}ëª… | Open {open_rate} | Replies {replies_count}",
                expanded=(campaign == active_campaigns[0]),
            ):
                # â”€â”€ Summary metrics (like GMass dashboard) â”€â”€
                st.caption(f"Sent: {sent_time} | Status: {status} | From: {campaign.get('fromLine', '')}")

                m1, m2, m3, m4, m5, m6 = st.columns(6)
                m1.metric("Recipients", recipients_count)
                m2.metric("Opens", f"{opens_count} ({open_rate})")
                m3.metric("Replies", f"{replies_count} ({replies_count/recipients_count*100:.1f}%)" if recipients_count else "0")
                m4.metric("Bounces", f"{bounces_count} ({bounces_count/recipients_count*100:.1f}%)" if recipients_count else "0")
                m5.metric("Blocks", blocks_count)
                m6.metric("Unsubscribes", unsubs_count)

                st.divider()

                # â”€â”€ Detail tabs â”€â”€
                tab_opens, tab_replies, tab_bounces, tab_all = st.tabs(
                    ["Opens", "Replies", "Bounces/Blocks", "All Recipients"]
                )

                with tab_opens:
                    if opens_count > 0:
                        try:
                            opens_data = gmass.get_campaign_opens(cid)
                            if opens_data:
                                df_opens = pd.DataFrame(opens_data)
                                df_opens = df_opens.rename(columns={
                                    "emailAddress": "Email",
                                    "openCount": "Open Count",
                                    "lastOpenTime": "Last Open",
                                })
                                display_cols = [c for c in ["Email", "Open Count", "Last Open"] if c in df_opens.columns]
                                df_opens = df_opens[display_cols].sort_values("Open Count", ascending=False)
                                # Format time
                                if "Last Open" in df_opens.columns:
                                    df_opens["Last Open"] = df_opens["Last Open"].str[:16].str.replace("T", " ")
                                st.dataframe(df_opens, width="stretch", hide_index=True)
                            else:
                                st.info("ì˜¤í”ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        except Exception as e:
                            st.error(f"Opens ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    else:
                        st.info("ì•„ì§ ì˜¤í”ˆí•œ ìˆ˜ì‹ ìê°€ ì—†ìŠµë‹ˆë‹¤.")

                with tab_replies:
                    if replies_count > 0:
                        try:
                            replies_data = gmass.get_campaign_replies(cid)
                            if replies_data:
                                # Fetch actual reply content from Gmail IMAP
                                reply_emails_list = [r.get("emailAddress", "") for r in replies_data]
                                gmail_replies = {}
                                try:
                                    from gmail_reader import GmailReader
                                    reader = GmailReader()
                                    gmail_replies = reader.find_all_replies(reply_emails_list)
                                except Exception as gmail_err:
                                    st.caption(f"Gmail IMAP ì—°ê²° ì•ˆ ë¨ (ë‹µì¥ ì›ë¬¸ ì¡°íšŒ ë¶ˆê°€): {gmail_err}")

                                for ridx, reply in enumerate(replies_data):
                                    reply_email = reply.get("emailAddress", "")
                                    reply_time = reply.get("replyTime", "")[:16].replace("T", " ")
                                    already_replied = reply.get("alreadyReplied", False)

                                    st.markdown(f"### {reply_email}")
                                    st.caption(f"Reply time: {reply_time}" + (" | (ë‹µì¥ ì™„ë£Œ)" if already_replied else ""))

                                    # Show reply content from Gmail
                                    gmail_data = gmail_replies.get(reply_email)
                                    if gmail_data:
                                        st.markdown(f"**Subject:** {gmail_data.get('subject', '')}")
                                        with st.expander("ë‹µì¥ ì›ë¬¸ ë³´ê¸°", expanded=True):
                                            st.text(gmail_data.get("body", "(ë³¸ë¬¸ ì—†ìŒ)"))

                                    if st.button(
                                        "âœï¸ ë‹µì¥ ì‘ì„±",
                                        key=f"reply_btn_{cid}_{ridx}",
                                    ):
                                        original_body = _find_sent_email_body(reply_email)
                                        reply_body_text = gmail_data.get("body", "") if gmail_data else ""
                                        st.session_state.reply_context = {
                                            "email": reply_email,
                                            "original_body": original_body,
                                            "reply_body": reply_body_text,
                                            "reply_subject": gmail_data.get("subject", "") if gmail_data else "",
                                            "campaign_id": cid,
                                        }
                                        st.session_state.active_page = "ğŸ’¬ ë‹µì¥ ì‘ì„±"
                                        st.rerun()

                                    if ridx < len(replies_data) - 1:
                                        st.divider()
                            else:
                                st.info("ë‹µì¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        except Exception as e:
                            st.error(f"Replies ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    else:
                        st.info("ì•„ì§ ë‹µì¥ì´ ì—†ìŠµë‹ˆë‹¤.")

                with tab_bounces:
                    if bounces_count > 0 or blocks_count > 0:
                        try:
                            if bounces_count > 0:
                                st.markdown("**Bounces:**")
                                bounces_data = gmass.get_campaign_bounces(cid)
                                if bounces_data:
                                    for b in bounces_data:
                                        st.markdown(f"- `{b.get('emailAddress', '')}` â€” {b.get('bounceTime', '')[:16]}")

                            if blocks_count > 0:
                                st.markdown("**Blocks:**")
                                blocks_data = gmass.get_campaign_blocks(cid)
                                if blocks_data:
                                    for b in blocks_data:
                                        st.markdown(f"- `{b.get('emailAddress', '')}` â€” Security policy rejection")
                        except Exception as e:
                            st.error(f"Bounce/Block ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    else:
                        st.info("ë°”ìš´ìŠ¤/ì°¨ë‹¨ ì—†ìŒ.")

                with tab_all:
                    try:
                        all_recipients = gmass.get_campaign_recipients(cid)
                        if all_recipients:
                            df_all = pd.DataFrame(all_recipients)
                            df_all = df_all.rename(columns={
                                "emailAddress": "Email",
                                "sentTime": "Sent Time",
                            })
                            display_cols = [c for c in ["Email", "Sent Time"] if c in df_all.columns]
                            df_all = df_all[display_cols]
                            if "Sent Time" in df_all.columns:
                                df_all["Sent Time"] = df_all["Sent Time"].str[:16].str.replace("T", " ")

                            # Merge open status
                            try:
                                opens_data = gmass.get_campaign_opens(cid)
                                open_emails = {o["emailAddress"]: o.get("openCount", 0) for o in opens_data} if opens_data else {}
                            except Exception:
                                open_emails = {}
                            try:
                                replies_data = gmass.get_campaign_replies(cid)
                                reply_emails = {r["emailAddress"] for r in replies_data} if replies_data else set()
                            except Exception:
                                reply_emails = set()
                            try:
                                bounce_data = gmass.get_campaign_bounces(cid)
                                bounce_emails = {b["emailAddress"] for b in bounce_data} if bounce_data else set()
                            except Exception:
                                bounce_emails = set()
                            try:
                                block_data = gmass.get_campaign_blocks(cid)
                                block_emails = {b["emailAddress"] for b in block_data} if block_data else set()
                            except Exception:
                                block_emails = set()

                            def get_status(email):
                                if email in reply_emails:
                                    return "Replied"
                                if email in bounce_emails:
                                    return "Bounced"
                                if email in block_emails:
                                    return "Blocked"
                                if email in open_emails:
                                    return f"Opened ({open_emails[email]}x)"
                                return "Sent"

                            df_all["Status"] = df_all["Email"].apply(get_status)
                            st.dataframe(df_all, width="stretch", hide_index=True)
                        else:
                            st.info("ìˆ˜ì‹ ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"Recipients ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # Show empty campaigns in a collapsed section
        if other_campaigns:
            with st.expander(f"ê¸°íƒ€ ìº í˜ì¸ ({len(other_campaigns)}ê°œ â€” recipients=0)", expanded=False):
                for c in other_campaigns:
                    cid = c.get("campaignId", "")
                    st.caption(f"ID: {cid} | Subject: {c.get('subject', 'N/A')} | {c.get('creationTime', '')[:16]}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PAGE 4: Reply Composer
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

elif page == "ğŸ’¬ ë‹µì¥ ì‘ì„±":
    st.title("ë¹„ì¦ˆë‹ˆìŠ¤ ë©”ì¼ ë‹µì¥ ì‘ì„±")
    st.caption("ë°›ì€ ë©”ì¼ì— ëŒ€í•œ ì¼ë³¸ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ ë‹µì¥ì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤.")

    # Check if we came from campaign replies tab
    ctx = st.session_state.reply_context
    prefill_reply = ""
    if ctx:
        st.info(f"**{ctx['email']}** ì— ëŒ€í•œ ë‹µì¥ì„ ì‘ì„±í•©ë‹ˆë‹¤.")
        if ctx.get("reply_subject"):
            st.caption(f"Subject: {ctx['reply_subject']}")
        if ctx.get("original_body"):
            with st.expander("ìš°ë¦¬ê°€ ë³´ë‚¸ ì›ë³¸ ë©”ì¼", expanded=False):
                original_html = ctx["original_body"].replace("<br>", "\n")
                st.text(original_html)
        if ctx.get("reply_body"):
            prefill_reply = ctx["reply_body"]
        # Clear button
        if st.button("ì´ˆê¸°í™” (ë‹¤ë¥¸ ë©”ì¼ì— ë‹µì¥)"):
            st.session_state.reply_context = None
            st.rerun()

    received_mail = st.text_area(
        "ë°›ì€ ë©”ì¼ ì›ë¬¸",
        height=200,
        value=prefill_reply,
        placeholder="ìƒëŒ€ë°©ì´ ë³´ë‚¸ ë©”ì¼ ì „ë¬¸ì„ ë¶™ì—¬ë„£ì–´ì£¼ì„¸ìš”...",
        help="ìº í˜ì¸ í˜„í™© â†’ Repliesì—ì„œ 'ë‹µì¥ ì‘ì„±' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.",
    )

    intent = st.text_area(
        "ë‹µì¥ì— ë‹´ì„ ìš”ì§€/ì˜ë„ (í•œêµ­ì–´ ê°€ëŠ¥)",
        height=100,
        placeholder="ì˜ˆ: ê²€í†  ê°ì‚¬, Zoomë„ ê°€ëŠ¥, ìë£Œ PDFë¡œ ë³´ë‚´ê² ë‹¤ ë“±",
    )

    col1, col2, col3 = st.columns(3)
    with col1:
        reply_lang = st.selectbox("ì–¸ì–´", ["ì¼ë³¸ì–´", "ì˜ì–´", "í˜¼í•©"], index=0, key="reply_lang")
    with col2:
        reply_tone = st.selectbox("í†¤", ["ë§¤ìš° ì •ì¤‘", "ì •ì¤‘", "ìºì£¼ì–¼"], index=1, key="reply_tone")
    with col3:
        reply_length = st.selectbox("ê¸¸ì´", ["ì§§ê²Œ", "ë³´í†µ", "ê¸¸ê²Œ"], index=1, key="reply_length")

    meeting_option = st.text_input(
        "ë¯¸íŒ… ì˜µì…˜ (ì„ íƒ)",
        placeholder="ì˜ˆ: Web(Zoom) ìš°ì„ , ëŒ€ë©´ë„ ê°€ëŠ¥",
    )

    if st.button("âœï¸ ë‹µì¥ ìƒì„±", type="primary", disabled=not (received_mail and intent)):
        with st.spinner("Claudeê°€ ë‹µì¥ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                from claude_client import ClaudeClient
                claude = ClaudeClient()

                # Build the reply skill prompt
                skill_text = (DATA_DIR.parent / ".claude" / "skills" / "japan" / "reply" / "SKILL.md").read_text(encoding="utf-8")

                constraints = (
                    f"ì–¸ì–´: {reply_lang}\n"
                    f"í†¤: {reply_tone}\n"
                    f"ê¸¸ì´: {reply_length}\n"
                )
                if meeting_option:
                    constraints += f"ë¯¸íŒ… ì˜µì…˜: {meeting_option}\n"

                # Include original sent email as context if available
                original_context = ""
                if ctx and ctx.get("original_body"):
                    original_context = (
                        f"\n\n## ì°¸ê³ : ìš°ë¦¬ê°€ ë³´ë‚¸ ì›ë³¸ ë©”ì¼\n"
                        f"<<<\n{ctx['original_body']}\n>>>\n"
                    )

                user_prompt = (
                    f"1) ìƒëŒ€ ë©”ì¼ ì›ë¬¸:\n<<<\n{received_mail}\n>>>\n\n"
                    f"2) ë‹µì¥ì— ë‹´ê³  ì‹¶ì€ ìš”ì§€:\n{intent}\n\n"
                    f"3) ì œì•½/ì„ í˜¸:\n{constraints}\n"
                    f"4) ì„œëª…: ê¸°ì¡´ ì„œëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©\n"
                    f"{original_context}"
                )

                result = claude._call(skill_text, user_prompt)

                st.divider()
                st.subheader("ìƒì„±ëœ ë‹µì¥")
                st.markdown(result)

                # Copy-friendly text area
                with st.expander("ë³µì‚¬ìš© í…ìŠ¤íŠ¸"):
                    st.text_area("", value=result, height=300, key="reply_copy")

            except Exception as e:
                st.error(f"ë‹µì¥ ìƒì„± ì‹¤íŒ¨: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PAGE 5: Skills List
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

elif page == "ğŸ“š ìŠ¤í‚¬ ëª©ë¡":
    st.title("ìŠ¤í‚¬ ê´€ë¦¬")

    # â”€â”€ Sender Profile Management â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.expander("ğŸ‘¤ ë°œì‹ ì í”„ë¡œí•„ ê´€ë¦¬", expanded=False):
        sender_profiles = db.get_sender_profiles()

        # Show existing profiles
        if sender_profiles:
            st.markdown("**ì €ì¥ëœ ë°œì‹ ì í”„ë¡œí•„**")
            for sp in sender_profiles:
                sp_col1, sp_col2, sp_col3 = st.columns([4, 1, 1])
                with sp_col1:
                    is_active_sp = st.session_state.get("active_sender_id") == sp["id"]
                    sp_label = f"{'âœ… ' if is_active_sp else ''}{sp['name']}"
                    sp_detail = f"{sp.get('name_en', '')} | {sp.get('company_en', '')} | {sp.get('email', '')}"
                    st.markdown(f"**{sp_label}**  \n{sp_detail}")
                with sp_col2:
                    if st.button("ì‚¬ìš©", key=f"use_sender_{sp['id']}"):
                        st.session_state.active_sender_id = sp["id"]
                        st.session_state.active_sender = sp
                        st.rerun()
                with sp_col3:
                    if st.button("ì‚­ì œ", key=f"del_sender_{sp['id']}"):
                        db.delete_sender_profile(sp["id"])
                        if st.session_state.get("active_sender_id") == sp["id"]:
                            st.session_state.active_sender_id = None
                            st.session_state.active_sender = None
                        st.rerun()
            st.divider()

        # Create new sender profile form
        st.markdown("**ìƒˆ ë°œì‹ ì í”„ë¡œí•„ ì¶”ê°€**")

        # Import from sender_profile.md
        sp_md_path = DATA_DIR / "sender_profile.md"
        if sp_md_path.exists():
            if st.button("ğŸ“¥ sender_profile.mdì—ì„œ ê°€ì ¸ì˜¤ê¸°", key="import_sender_md"):
                md_text = sp_md_path.read_text(encoding="utf-8")
                # Parse fields
                field_map = {
                    "ì´ë¦„ (ì˜ë¬¸)": "name_en", "ì´ë¦„ (ì¼ë³¸ì–´)": "name_ja",
                    "ì§í•¨ (ì˜ë¬¸)": "title_en", "ì§í•¨ (ì¼ë³¸ì–´)": "title_ja",
                    "íšŒì‚¬ëª… (ì˜ë¬¸)": "company_en", "íšŒì‚¬ëª… (ì¼ë³¸ì–´)": "company_ja",
                    "ì´ë©”ì¼": "email", "ì „í™”ë²ˆí˜¸": "phone",
                }
                parsed = {}
                for label, key in field_map.items():
                    m = re.search(rf"\*\*{re.escape(label)}\*\*:\s*(.+)", md_text)
                    if m:
                        parsed[key] = m.group(1).strip()
                # Parse signature blocks
                sig_blocks = re.findall(r"## ì„œëª… \((.+?)\)\s*\n+```\n(.*?)```", md_text, re.DOTALL)
                for sig_label, sig_body in sig_blocks:
                    if "ì¼ë³¸ì–´" in sig_label:
                        parsed["signature_ja"] = sig_body.strip()
                    elif "ì˜ë¬¸" in sig_label:
                        parsed["signature_en"] = sig_body.strip()
                # Build profile name from company + name
                pname = f"{parsed.get('name_en', '')} ({parsed.get('company_en', '')})".strip()
                if not pname or pname == "()":
                    pname = "Imported Profile"
                try:
                    new_id = db.save_sender_profile(
                        name=pname,
                        name_en=parsed.get("name_en", ""),
                        name_ja=parsed.get("name_ja", ""),
                        title_en=parsed.get("title_en", ""),
                        title_ja=parsed.get("title_ja", ""),
                        company_en=parsed.get("company_en", ""),
                        company_ja=parsed.get("company_ja", ""),
                        email=parsed.get("email", ""),
                        phone=parsed.get("phone", ""),
                        signature_ja=parsed.get("signature_ja", ""),
                        signature_en=parsed.get("signature_en", ""),
                    )
                    st.session_state.active_sender_id = new_id
                    st.session_state.active_sender = db.get_sender_profile(new_id)
                    st.success(f"'{pname}' í”„ë¡œí•„ì„ ê°€ì ¸ì™€ì„œ ì €ì¥í–ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                except Exception as e:
                    st.error(f"ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

        with st.form("sender_profile_form", clear_on_submit=True):
            sp_profile_name = st.text_input("í”„ë¡œí•„ ì´ë¦„ *", placeholder="ì˜ˆ: ë¥˜ì„ìˆ˜ (RISORIUS)")

            sp_c1, sp_c2 = st.columns(2)
            with sp_c1:
                sp_name_en = st.text_input("ì´ë¦„ (ì˜ë¬¸)", placeholder="Imsoo Ryoo")
                sp_title_en = st.text_input("ì§í•¨ (ì˜ë¬¸)", placeholder="Co-Founder & AI Engineer")
                sp_company_en = st.text_input("íšŒì‚¬ëª… (ì˜ë¬¸)", placeholder="RISORIUS")
            with sp_c2:
                sp_name_ja = st.text_input("ì´ë¦„ (ì¼ë³¸ì–´)", placeholder="ãƒªãƒ¥ãƒ»ã‚¤ãƒ ã‚¹")
                sp_title_ja = st.text_input("ì§í•¨ (ì¼ë³¸ì–´)", placeholder="å…±åŒå‰µæ¥­è€… å…¼ AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢")
                sp_company_ja = st.text_input("íšŒì‚¬ëª… (ì¼ë³¸ì–´)", placeholder="ãƒªã‚½ãƒªã‚¦ã‚¹")

            sp_c3, sp_c4 = st.columns(2)
            with sp_c3:
                sp_email = st.text_input("ì´ë©”ì¼", placeholder="leiris@risorious.com")
            with sp_c4:
                sp_phone = st.text_input("ì „í™”ë²ˆí˜¸", placeholder="+82-10-9592-2268")

            sp_sig_ja = st.text_area(
                "ì„œëª… (ì¼ë³¸ì–´ ë©”ì¼ìš©)",
                placeholder="ãƒªãƒ¥ãƒ»ã‚¤ãƒ ã‚¹\nå…±åŒå‰µæ¥­è€… å…¼ AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢\nãƒªã‚½ãƒªã‚¦ã‚¹\nEmail: leiris@risorious.com",
                height=100,
            )
            sp_sig_en = st.text_area(
                "ì„œëª… (ì˜ë¬¸ ë©”ì¼ìš©)",
                placeholder="Imsoo Ryoo\nCo-Founder & AI Engineer\nRISORIUS\nEmail: leiris@risorious.com",
                height=100,
            )
            sp_extra = st.text_input("ì¶”ê°€ ì •ë³´ (ì„ íƒ)", placeholder="ì˜ˆ: LinkedIn URL, ê¸°íƒ€")

            sp_submitted = st.form_submit_button("ğŸ’¾ ë°œì‹ ì í”„ë¡œí•„ ì €ì¥", use_container_width=True)
            if sp_submitted:
                if not sp_profile_name.strip():
                    st.error("í”„ë¡œí•„ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                elif not sp_name_en.strip() and not sp_name_ja.strip():
                    st.error("ì´ë¦„ (ì˜ë¬¸ ë˜ëŠ” ì¼ë³¸ì–´)ì„ ìµœì†Œ í•˜ë‚˜ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    new_sp_id = db.save_sender_profile(
                        name=sp_profile_name.strip(),
                        name_en=sp_name_en.strip(),
                        name_ja=sp_name_ja.strip(),
                        title_en=sp_title_en.strip(),
                        title_ja=sp_title_ja.strip(),
                        company_en=sp_company_en.strip(),
                        company_ja=sp_company_ja.strip(),
                        email=sp_email.strip(),
                        phone=sp_phone.strip(),
                        signature_ja=sp_sig_ja.strip(),
                        signature_en=sp_sig_en.strip(),
                        extra_info=sp_extra.strip(),
                    )
                    st.session_state.active_sender_id = new_sp_id
                    new_sp = db.get_sender_profile(new_sp_id)
                    st.session_state.active_sender = new_sp
                    st.success(f"ë°œì‹ ì í”„ë¡œí•„ '{sp_profile_name}' ì €ì¥ ì™„ë£Œ! ìë™ìœ¼ë¡œ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()

    st.divider()

    # Load skills from .claude/skills directory
    skills_dir = PROJECT_ROOT / ".claude" / "skills"

    if not skills_dir.exists():
        st.warning("ìŠ¤í‚¬ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info(f"ì˜ˆìƒ ê²½ë¡œ: {skills_dir}")
    else:
        # Collect all files organized by folder
        folder_files = {}

        # Define folder display names
        folder_names = {
            "_global": "ğŸŒ ì „ì—­ (Global)",
            "japan": "ğŸ‡¯ğŸ‡µ ì¼ë³¸ (Japan)",
            "shared": "ğŸ”— ê³µìš© (Shared)",
        }

        # Scan folders
        for folder in skills_dir.iterdir():
            if not folder.is_dir():
                continue

            folder_key = folder.name
            if folder_key not in folder_names:
                continue

            folder_files[folder_key] = []

            # Skills in this folder
            for skill_path in folder.rglob("SKILL.md"):
                skill_name = skill_path.parent.name
                if skill_name.startswith("_"):
                    continue
                content = skill_path.read_text(encoding="utf-8")
                desc_match = re.search(r'description:\s*["\'](.+?)["\']', content)
                description = desc_match.group(1) if desc_match else ""
                folder_files[folder_key].append({
                    "type": "skill",
                    "name": f"/{skill_name}",
                    "description": description,
                    "path": skill_path,
                })

            # Common/global files in _common subfolder or direct .md files
            common_subdir = folder / "_common"
            if common_subdir.exists():
                for common_file in common_subdir.glob("*.md"):
                    folder_files[folder_key].append({
                        "type": "common",
                        "name": common_file.name,
                        "description": "ê³µí†µ ê·œì¹™",
                        "path": common_file,
                    })

            # Direct .md files in folder (like SENDER_PROFILE.md in _global)
            for md_file in folder.glob("*.md"):
                folder_files[folder_key].append({
                    "type": "config",
                    "name": md_file.name,
                    "description": "ì„¤ì • íŒŒì¼",
                    "path": md_file,
                })

            # Sort files in folder
            folder_files[folder_key].sort(key=lambda x: (0 if x["type"] == "skill" else 1, x["name"]))

        # Build flat list for selection with folder prefixes
        all_files = []
        for folder_key in ["_global", "japan", "shared"]:
            if folder_key in folder_files:
                for f in folder_files[folder_key]:
                    f["folder"] = folder_key
                    f["display_name"] = f"{f['name']}"
                    all_files.append(f)

        # File selector
        col1, col2 = st.columns([1, 3])

        with col1:
            st.subheader("íŒŒì¼ ëª©ë¡")

            for folder_key in ["_global", "japan", "shared"]:
                if folder_key not in folder_files or not folder_files[folder_key]:
                    continue

                st.markdown(f"**{folder_names[folder_key]}**")

                for f in folder_files[folder_key]:
                    icon = "ğŸ“" if f["type"] == "skill" else ("ğŸ“‹" if f["type"] == "common" else "âš™ï¸")
                    btn_key = f"btn_{folder_key}_{f['name']}"
                    if st.button(f"{icon} {f['name']}", key=btn_key, use_container_width=True):
                        st.session_state.selected_skill = f"{folder_key}::{f['name']}"

                st.markdown("")  # spacing

            # Initialize selected skill
            if "selected_skill" not in st.session_state and all_files:
                first = all_files[0]
                st.session_state.selected_skill = f"{first['folder']}::{first['name']}"

        with col2:
            if st.session_state.get("selected_skill"):
                # Parse folder::name
                parts = st.session_state.selected_skill.split("::", 1)
                if len(parts) == 2:
                    sel_folder, sel_name = parts
                    selected = next(
                        (f for f in all_files if f["folder"] == sel_folder and f["name"] == sel_name),
                        None
                    )
                else:
                    selected = None

                if selected:
                    folder_label = folder_names.get(selected["folder"], selected["folder"])
                    st.subheader(f"{selected['name']}")
                    st.caption(f"{folder_label} | {selected['description']}")

                    content = selected["path"].read_text(encoding="utf-8")

                    # Mode selector: ë³´ê¸° / ì§ì ‘ í¸ì§‘ / AI ìˆ˜ì •
                    mode = st.radio(
                        "ëª¨ë“œ",
                        ["ğŸ“– ë³´ê¸°", "âœï¸ ì§ì ‘ í¸ì§‘", "ğŸ¤– AI ìˆ˜ì •"],
                        horizontal=True,
                        key="skill_mode"
                    )

                    if mode == "ğŸ“– ë³´ê¸°":
                        # Display as markdown
                        st.markdown(content)

                    elif mode == "âœï¸ ì§ì ‘ í¸ì§‘":
                        new_content = st.text_area(
                            "ë‚´ìš© í¸ì§‘",
                            value=content,
                            height=500,
                            key=f"edit_{selected['folder']}_{selected['name']}"
                        )

                        if st.button("ğŸ’¾ ì €ì¥", type="primary"):
                            try:
                                selected["path"].write_text(new_content, encoding="utf-8")
                                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                st.rerun()
                            except Exception as e:
                                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

                    elif mode == "ğŸ¤– AI ìˆ˜ì •":
                        st.markdown("**í”¼ë“œë°±ì„ ì…ë ¥í•˜ë©´ Claudeê°€ ìŠ¤í‚¬ íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.**")

                        # Show current content in expander
                        with st.expander("í˜„ì¬ ë‚´ìš© ë³´ê¸°", expanded=False):
                            st.markdown(content)

                        # Feedback input
                        feedback = st.text_area(
                            "ìˆ˜ì • ìš”ì²­ (í”¼ë“œë°±)",
                            height=100,
                            placeholder="ì˜ˆ: CTA ê¸°ë³¸ê°’ì„ 'ìë£Œ ì†¡ë¶€ ì œì•ˆ'ìœ¼ë¡œ ë³€ê²½í•´ì¤˜, ìƒˆë¡œìš´ ê·œì¹™ ì¶”ê°€í•´ì¤˜: ~, ì´ ë¶€ë¶„ ì‚­ì œí•´ì¤˜ ë“±",
                            key="skill_feedback"
                        )

                        # Session state for preview
                        preview_key = f"preview_{selected['folder']}_{selected['name']}"
                        if preview_key not in st.session_state:
                            st.session_state[preview_key] = None

                        col_gen, col_clear = st.columns([1, 1])

                        with col_gen:
                            if st.button("ğŸ”„ ë¯¸ë¦¬ë³´ê¸° ìƒì„±", type="primary", disabled=not feedback):
                                with st.spinner("Claudeê°€ ìˆ˜ì • ì¤‘..."):
                                    try:
                                        from claude_client import ClaudeClient
                                        claude = ClaudeClient()
                                        modified = claude.edit_skill(content, feedback)
                                        st.session_state[preview_key] = modified
                                        st.rerun()
                                    except Exception as e:
                                        st.error(f"ìˆ˜ì • ì‹¤íŒ¨: {e}")

                        with col_clear:
                            if st.session_state[preview_key] and st.button("ğŸ—‘ï¸ ë¯¸ë¦¬ë³´ê¸° ì·¨ì†Œ"):
                                st.session_state[preview_key] = None
                                st.rerun()

                        # Show preview with diff
                        if st.session_state[preview_key]:
                            st.divider()
                            st.markdown("### ìˆ˜ì • ë¯¸ë¦¬ë³´ê¸°")

                            modified_content = st.session_state[preview_key]

                            # Show diff
                            import difflib
                            original_lines = content.splitlines(keepends=True)
                            modified_lines = modified_content.splitlines(keepends=True)

                            diff = list(difflib.unified_diff(
                                original_lines,
                                modified_lines,
                                fromfile="ì›ë³¸",
                                tofile="ìˆ˜ì •ë³¸",
                                lineterm=""
                            ))

                            if diff:
                                # Format diff for display
                                diff_text = []
                                for line in diff:
                                    if line.startswith("+") and not line.startswith("+++"):
                                        diff_text.append(f"ğŸŸ¢ {line}")
                                    elif line.startswith("-") and not line.startswith("---"):
                                        diff_text.append(f"ğŸ”´ {line}")
                                    elif line.startswith("@@"):
                                        diff_text.append(f"ğŸ“ {line}")

                                with st.expander("ë³€ê²½ ì‚¬í•­ (Diff)", expanded=True):
                                    st.code("\n".join(diff_text[:100]), language="diff")
                                    if len(diff_text) > 100:
                                        st.caption("... (ë³€ê²½ ì‚¬í•­ì´ ë§ì•„ ì¼ë¶€ë§Œ í‘œì‹œ)")

                            # Full preview
                            with st.expander("ìˆ˜ì •ëœ ì „ì²´ ë‚´ìš©", expanded=False):
                                st.text_area(
                                    "ìˆ˜ì •ë³¸",
                                    value=modified_content,
                                    height=400,
                                    key="preview_content",
                                    disabled=True
                                )

                            # Apply button
                            col_apply, col_reject = st.columns([1, 1])
                            with col_apply:
                                if st.button("âœ… ì ìš©í•˜ê¸°", type="primary"):
                                    try:
                                        selected["path"].write_text(modified_content, encoding="utf-8")
                                        st.session_state[preview_key] = None
                                        st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                        st.rerun()
                                    except Exception as e:
                                        st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

                            with col_reject:
                                if st.button("âŒ ì·¨ì†Œ"):
                                    st.session_state[preview_key] = None
                                    st.rerun()


# â”€â”€ Footer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.divider()
st.sidebar.caption("RISORIUS Cold Email System v1.0")
st.sidebar.caption(f"Output dir: {OUTPUT_DIR}")
